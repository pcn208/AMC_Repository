{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1c492bd-d631-478e-9383-52d27b353f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torchinfo import summary\n",
    "from typing import Tuple, Optional\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
    "# from sklearn.metrics import confusion_matrix, classification_report,f1_score,accuracy_score\n",
    "from tqdm import tqdm, trange\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import time\n",
    "import pywt\n",
    "import math\n",
    "from collections import deque\n",
    "import psutil\n",
    "import os\n",
    "from scipy import signal\n",
    "from scipy.fft import fft, fftfreq\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f57e9fa-df68-4adf-b36c-fbec4f944cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Emergency GPU cleanup...\n",
      "‚úÖ GPU memory cleared. Available: 0.00 GB\n",
      "‚úÖ Cleanup complete!\n"
     ]
    }
   ],
   "source": [
    "def emergency_gpu_cleanup():\n",
    "    \"\"\"Emergency GPU memory cleanup\"\"\"\n",
    "    import torch\n",
    "    import gc\n",
    "    \n",
    "    print(\"üßπ Emergency GPU cleanup...\")\n",
    "    \n",
    "    # Clear all variables\n",
    "    for name in list(globals().keys()):\n",
    "        if not name.startswith('_'):\n",
    "            del globals()[name]\n",
    "    \n",
    "    # Garbage collect\n",
    "    gc.collect()\n",
    "    \n",
    "    # Clear CUDA cache if available\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "        print(f\"‚úÖ GPU memory cleared. Available: {torch.cuda.memory_reserved() / 1e9:.2f} GB\")\n",
    "    \n",
    "    print(\"‚úÖ Cleanup complete!\")\n",
    "\n",
    "emergency_gpu_cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf44e400-bf48-48e0-8171-cb46e10643ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Focused 1D Experiment Setup:\n",
      "   Modulations: ['8PSK', '16QAM']\n",
      "   SNR levels: [-6, 6, 18]\n",
      "   Feature method: wavelet_coeffs\n",
      "   Target length: 1024\n",
      "   Output directory: Dataset_Wavelet/focused_experiment_1d_iq_raw\n"
     ]
    }
   ],
   "source": [
    "FILE_PATH = \"C:\\\\workarea\\\\CNN model\\\\dataset\\\\radioml2018\\\\versions\\\\2\\\\GOLD_XYZ_OSC.0001_1024.hdf5\"\n",
    "JSON_PATH = 'C:\\\\workarea\\\\CNN model\\\\dataset\\\\radioml2018\\\\versions\\\\2\\\\classes-fixed.json' \n",
    "\n",
    "# Focused experiment setup\n",
    "TARGET_MODULATIONS = ['8PSK', '16QAM'\n",
    "                    #   ,'16APSK'\n",
    "                     ]  # Only 2 modulations\n",
    "TARGET_SNRS = [-6, 6, 18]  # Low, Medium, High SNR\n",
    "\n",
    "# Processing options\n",
    "FEATURE_METHOD = 'wavelet_coeffs'  # Options: 'amplitude_phase', 'iq_raw', 'fft_features', 'wavelet_coeffs', 'statistical'\n",
    "OUTPUT_DIR = 'Dataset_Wavelet/focused_experiment_1d_iq_raw'\n",
    "TRAIN_RATIO = 0.75\n",
    "VALID_RATIO = 0.25\n",
    "\n",
    "# Feature extraction settings\n",
    "TARGET_LENGTH = 1024  # Standard 1D feature length (reduced from 1024 for efficiency)\n",
    "NUM_FFT_BINS = 256   # Number of FFT frequency bins to keep\n",
    "NUM_WAVELET_LEVELS = 6  # Wavelet decomposition levels\n",
    "\n",
    "print(f\"üéØ Focused 1D Experiment Setup:\")\n",
    "print(f\"   Modulations: {TARGET_MODULATIONS}\")\n",
    "print(f\"   SNR levels: {TARGET_SNRS}\")\n",
    "print(f\"   Feature method: {FEATURE_METHOD}\")\n",
    "print(f\"   Target length: {TARGET_LENGTH}\")\n",
    "print(f\"   Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afd9837a-042f-49cb-ba0b-6dc78c5cfcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_filter_data():\n",
    "    \"\"\"Load RadioML data and filter for target modulations and SNRs.\"\"\"\n",
    "    \n",
    "    print(\"üìÇ Loading and filtering RadioML data...\")\n",
    "    \n",
    "    # Load files\n",
    "    h5_file = h5py.File(FILE_PATH, 'r')\n",
    "    with open(JSON_PATH, 'r') as f:\n",
    "        modulation_classes = json.load(f)\n",
    "    \n",
    "    # Load arrays\n",
    "    X = h5_file['X']  # Shape: (samples, 1024, 2)\n",
    "    Y = np.argmax(h5_file['Y'], axis=1)  # Labels\n",
    "    Z = h5_file['Z'][:, 0]  # SNRs\n",
    "    \n",
    "    print(f\"   Original dataset: {X.shape[0]} samples\")\n",
    "    \n",
    "    # Get target modulation indices\n",
    "    target_mod_indices = [modulation_classes.index(mod) for mod in TARGET_MODULATIONS]\n",
    "    print(f\"   Target modulation indices: {dict(zip(TARGET_MODULATIONS, target_mod_indices))}\")\n",
    "    \n",
    "    # Filter for target modulations and SNRs\n",
    "    mask = np.zeros(len(Y), dtype=bool)\n",
    "    \n",
    "    for mod_idx in target_mod_indices:\n",
    "        for snr in TARGET_SNRS:\n",
    "            condition = (Y == mod_idx) & (Z == snr)\n",
    "            mask |= condition\n",
    "            count = np.sum(condition)\n",
    "            mod_name = TARGET_MODULATIONS[target_mod_indices.index(mod_idx)]\n",
    "            print(f\"   {mod_name} at {snr}dB: {count} samples\")\n",
    "    \n",
    "    # Apply filter\n",
    "    X_filtered = X[mask]\n",
    "    Y_filtered = Y[mask]\n",
    "    Z_filtered = Z[mask]\n",
    "    \n",
    "    # Remap labels to 0, 1\n",
    "    label_mapping = {}\n",
    "    for new_label, old_label in enumerate(target_mod_indices):\n",
    "        Y_filtered[Y_filtered == old_label] = new_label\n",
    "        label_mapping[old_label] = new_label\n",
    "    \n",
    "    print(f\"‚úÖ Filtered dataset: {X_filtered.shape[0]} samples\")\n",
    "    print(f\"   Label mapping: {label_mapping}\")\n",
    "    \n",
    "    h5_file.close()\n",
    "    return X_filtered, Y_filtered, Z_filtered, label_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f46a58-d5bd-4787-af05-3cb6587d6cb5",
   "metadata": {},
   "source": [
    "### **Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a46a927-af63-4484-ad53-d764b22983c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_amplitude_phase_features(i_signal, q_signal):\n",
    "    \"\"\"Extract amplitude and phase as 1D time series.\"\"\"\n",
    "    \n",
    "    # Calculate amplitude and phase\n",
    "    amplitude = np.sqrt(i_signal**2 + q_signal**2)\n",
    "    phase = np.arctan2(q_signal, i_signal)\n",
    "    \n",
    "    # Unwrap phase to avoid discontinuities\n",
    "    phase_unwrapped = np.unwrap(phase)\n",
    "    \n",
    "    # Resize to target length\n",
    "    amplitude_resized = resize_to_target_length(amplitude)\n",
    "    phase_resized = resize_to_target_length(phase_unwrapped)\n",
    "    \n",
    "    return amplitude_resized.astype(np.float32), phase_resized.astype(np.float32)\n",
    "\n",
    "def extract_iq_raw_features(i_signal, q_signal):\n",
    "    \"\"\"Simple I/Q channel features (minimal processing).\"\"\"\n",
    "    \n",
    "    # Just resize the raw I/Q signals\n",
    "    i_resized = resize_to_target_length(i_signal)\n",
    "    q_resized = resize_to_target_length(q_signal)\n",
    "    \n",
    "    return i_resized.astype(np.float32), q_resized.astype(np.float32)\n",
    "\n",
    "def extract_fft_features(i_signal, q_signal):\n",
    "    \"\"\"Extract FFT magnitude and phase as 1D features.\"\"\"\n",
    "    \n",
    "    # Combine I/Q into complex signal\n",
    "    complex_signal = i_signal + 1j * q_signal\n",
    "    \n",
    "    # Compute FFT\n",
    "    fft_result = fft(complex_signal)\n",
    "    \n",
    "    # Extract magnitude and phase\n",
    "    magnitude = np.abs(fft_result)\n",
    "    phase = np.angle(fft_result)\n",
    "    \n",
    "    # Take only the first half (positive frequencies)\n",
    "    half_length = len(magnitude) // 2\n",
    "    magnitude = magnitude[:half_length]\n",
    "    phase = phase[:half_length]\n",
    "    \n",
    "    # Resize to target length\n",
    "    magnitude_resized = resize_to_target_length(magnitude)\n",
    "    phase_resized = resize_to_target_length(phase)\n",
    "    \n",
    "    return magnitude_resized.astype(np.float32), phase_resized.astype(np.float32)\n",
    "\n",
    "def extract_wavelet_coeffs(i_signal, q_signal):\n",
    "    \"\"\"Extract 1D wavelet coefficients.\"\"\"\n",
    "    \n",
    "    # Apply DWT to I and Q channels\n",
    "    wavelet = 'db4'\n",
    "    \n",
    "    # Multi-level wavelet decomposition\n",
    "    coeffs_i = pywt.wavedec(i_signal, wavelet, level=NUM_WAVELET_LEVELS)\n",
    "    coeffs_q = pywt.wavedec(q_signal, wavelet, level=NUM_WAVELET_LEVELS)\n",
    "    \n",
    "    # Concatenate all coefficients into 1D arrays\n",
    "    i_features = np.concatenate(coeffs_i)\n",
    "    q_features = np.concatenate(coeffs_q)\n",
    "    \n",
    "    # Resize to target length\n",
    "    i_resized = resize_to_target_length(i_features)\n",
    "    q_resized = resize_to_target_length(q_features)\n",
    "    \n",
    "    return i_resized.astype(np.float32), q_resized.astype(np.float32)\n",
    "\n",
    "def extract_statistical_features(i_signal, q_signal):\n",
    "    \"\"\"Extract statistical features using sliding windows.\"\"\"\n",
    "    \n",
    "    # Window size for statistical calculations\n",
    "    window_size = 64\n",
    "    hop_size = 32\n",
    "    \n",
    "    # Calculate sliding window statistics\n",
    "    i_stats = []\n",
    "    q_stats = []\n",
    "    \n",
    "    for start in range(0, len(i_signal) - window_size + 1, hop_size):\n",
    "        end = start + window_size\n",
    "        \n",
    "        i_window = i_signal[start:end]\n",
    "        q_window = q_signal[start:end]\n",
    "        \n",
    "        # Statistical features for each window\n",
    "        i_stats.extend([\n",
    "            np.mean(i_window), np.std(i_window), \n",
    "            np.var(i_window), np.max(i_window), np.min(i_window),\n",
    "            np.median(i_window), np.ptp(i_window)  # peak-to-peak\n",
    "        ])\n",
    "        \n",
    "        q_stats.extend([\n",
    "            np.mean(q_window), np.std(q_window),\n",
    "            np.var(q_window), np.max(q_window), np.min(q_window),\n",
    "            np.median(q_window), np.ptp(q_window)\n",
    "        ])\n",
    "    \n",
    "    i_stats = np.array(i_stats)\n",
    "    q_stats = np.array(q_stats)\n",
    "    \n",
    "    # Resize to target length\n",
    "    i_resized = resize_to_target_length(i_stats)\n",
    "    q_resized = resize_to_target_length(q_stats)\n",
    "    \n",
    "    return i_resized.astype(np.float32), q_resized.astype(np.float32)\n",
    "\n",
    "def safe_decode_attr(attr):\n",
    "    \"\"\"Safely decode HDF5 attribute (handles both string and bytes).\"\"\"\n",
    "    if isinstance(attr, bytes):\n",
    "        return attr.decode('utf-8')\n",
    "    return str(attr)\n",
    "\n",
    "def resize_to_target_length(signal_1d):\n",
    "    \"\"\"Resize 1D signal to target length using interpolation.\"\"\"\n",
    "    \n",
    "    current_length = len(signal_1d)\n",
    "    \n",
    "    if current_length == TARGET_LENGTH:\n",
    "        return signal_1d\n",
    "    \n",
    "    # Create interpolation indices\n",
    "    old_indices = np.linspace(0, current_length - 1, current_length)\n",
    "    new_indices = np.linspace(0, current_length - 1, TARGET_LENGTH)\n",
    "    \n",
    "    # Interpolate\n",
    "    resized = np.interp(new_indices, old_indices, signal_1d)\n",
    "    \n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "360d7a8f-dc4b-4df9-8e39-168be54b1bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_focused_dataset():\n",
    "    \"\"\"Main preprocessing pipeline for focused 1D experiment.\"\"\"\n",
    "    \n",
    "    # Create output directory\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    \n",
    "    # Load and filter data\n",
    "    X_filtered, Y_filtered, Z_filtered, label_mapping = load_and_filter_data()\n",
    "    \n",
    "    total_samples = len(X_filtered)\n",
    "    print(f\"\\nüåä Processing {total_samples} samples with {FEATURE_METHOD} method...\")\n",
    "    \n",
    "    # Select feature extraction method\n",
    "    if FEATURE_METHOD == 'amplitude_phase':\n",
    "        extract_features = extract_amplitude_phase_features\n",
    "        feature_names = ['amplitude', 'phase']\n",
    "    elif FEATURE_METHOD == 'iq_raw':\n",
    "        extract_features = extract_iq_raw_features\n",
    "        feature_names = ['i_channel', 'q_channel']\n",
    "    elif FEATURE_METHOD == 'fft_features':\n",
    "        extract_features = extract_fft_features\n",
    "        feature_names = ['fft_magnitude', 'fft_phase']\n",
    "    elif FEATURE_METHOD == 'wavelet_coeffs':\n",
    "        extract_features = extract_wavelet_coeffs\n",
    "        feature_names = ['i_wavelets', 'q_wavelets']\n",
    "    elif FEATURE_METHOD == 'statistical':\n",
    "        extract_features = extract_statistical_features\n",
    "        feature_names = ['i_statistics', 'q_statistics']\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown feature method: {FEATURE_METHOD}\")\n",
    "    \n",
    "    # Process all samples\n",
    "    start_time = time.time()\n",
    "    \n",
    "    feature1_list = []\n",
    "    feature2_list = []\n",
    "    labels_list = []\n",
    "    snrs_list = []\n",
    "    \n",
    "    for i in tqdm(range(total_samples), desc=\"Processing samples\"):\n",
    "        # Extract I/Q signals\n",
    "        i_signal = X_filtered[i, :, 0]\n",
    "        q_signal = X_filtered[i, :, 1]\n",
    "        \n",
    "        # Apply feature extraction\n",
    "        feature1, feature2 = extract_features(i_signal, q_signal)\n",
    "        \n",
    "        # Store results\n",
    "        feature1_list.append(feature1)\n",
    "        feature2_list.append(feature2)\n",
    "        labels_list.append(Y_filtered[i])\n",
    "        snrs_list.append(Z_filtered[i])\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    features1 = np.array(feature1_list)\n",
    "    features2 = np.array(feature2_list)\n",
    "    labels = np.array(labels_list)\n",
    "    snrs = np.array(snrs_list)\n",
    "    \n",
    "    processing_time = time.time() - start_time\n",
    "    print(f\"‚úÖ Processing complete in {processing_time/60:.1f} minutes\")\n",
    "    print(f\"   Features shape: {features1.shape}, {features2.shape}\")\n",
    "    print(f\"   Speed: {total_samples/processing_time:.1f} samples/second\")\n",
    "    \n",
    "    # Create train/valid splits\n",
    "    create_train_valid_splits(features1, features2, labels, snrs, feature_names)\n",
    "    \n",
    "    return features1, features2, labels, snrs\n",
    "\n",
    "def create_train_valid_splits(features1, features2, labels, snrs, feature_names):\n",
    "    \"\"\"Create train/validation splits and save to HDF5.\"\"\"\n",
    "    \n",
    "    print(f\"\\nüìä Creating train/validation splits...\")\n",
    "    \n",
    "    # Stratified split to maintain modulation/SNR balance\n",
    "    train_indices = []\n",
    "    valid_indices = []\n",
    "    \n",
    "    # Split by modulation and SNR combination\n",
    "    for mod_label in [0, 1]:  # 8PSK=0, 16QAM=1\n",
    "        for snr in TARGET_SNRS:\n",
    "            # Find samples for this combination\n",
    "            mask = (labels == mod_label) & (snrs == snr)\n",
    "            indices = np.where(mask)[0]\n",
    "            \n",
    "            # Shuffle and split\n",
    "            np.random.shuffle(indices)\n",
    "            split_point = int(TRAIN_RATIO * len(indices))\n",
    "            \n",
    "            train_indices.extend(indices[:split_point])\n",
    "            valid_indices.extend(indices[split_point:])\n",
    "    \n",
    "    train_indices = np.array(train_indices)\n",
    "    valid_indices = np.array(valid_indices)\n",
    "    \n",
    "    print(f\"   Train samples: {len(train_indices)}\")\n",
    "    print(f\"   Valid samples: {len(valid_indices)}\")\n",
    "    \n",
    "    # Save train split\n",
    "    save_split('train', train_indices, features1, features2, labels, snrs, feature_names)\n",
    "    \n",
    "    # Save validation split\n",
    "    save_split('valid', valid_indices, features1, features2, labels, snrs, feature_names)\n",
    "\n",
    "def save_split(split_name, indices, features1, features2, labels, snrs, feature_names):\n",
    "    \"\"\"Save a data split to HDF5 file.\"\"\"\n",
    "    \n",
    "    output_file = os.path.join(OUTPUT_DIR, f'{split_name}_{FEATURE_METHOD}.h5')\n",
    "    \n",
    "    with h5py.File(output_file, 'w') as f:\n",
    "        # Save features\n",
    "        f.create_dataset('feature1', data=features1[indices], compression='gzip')\n",
    "        f.create_dataset('feature2', data=features2[indices], compression='gzip')\n",
    "        f.create_dataset('labels', data=labels[indices])\n",
    "        f.create_dataset('snrs', data=snrs[indices])\n",
    "        \n",
    "        # Save metadata\n",
    "        f.attrs['num_samples'] = len(indices)\n",
    "        f.attrs['feature_method'] = FEATURE_METHOD\n",
    "        f.attrs['feature1_name'] = feature_names[0]\n",
    "        f.attrs['feature2_name'] = feature_names[1]\n",
    "        f.attrs['modulations'] = TARGET_MODULATIONS\n",
    "        f.attrs['target_snrs'] = TARGET_SNRS\n",
    "        f.attrs['num_classes'] = 2\n",
    "        f.attrs['feature_length'] = TARGET_LENGTH\n",
    "        f.attrs['is_1d'] = True\n",
    "    \n",
    "    file_size = os.path.getsize(output_file) / (1024**2)  # MB\n",
    "    print(f\"   {split_name}: {output_file} ({file_size:.1f} MB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63d3dd42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: c:\\workarea\\CNN model\\notebook\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "print(\"Current Directory:\", current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6e6a865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h5py in c:\\users\\n208\\.conda\\envs\\amc_env\\lib\\site-packages (3.14.0)\n",
      "Requirement already satisfied: numpy>=1.19.3 in c:\\users\\n208\\.conda\\envs\\amc_env\\lib\\site-packages (from h5py) (2.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install h5py\n",
    "import h5py\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31b306bf-46e6-4afb-ab75-fd6b02c6c929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading and filtering RadioML data...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m features1, features2, labels, snrs = \u001b[43mpreprocess_focused_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mpreprocess_focused_dataset\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      5\u001b[39m os.makedirs(OUTPUT_DIR, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Load and filter data\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m X_filtered, Y_filtered, Z_filtered, label_mapping = \u001b[43mload_and_filter_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m total_samples = \u001b[38;5;28mlen\u001b[39m(X_filtered)\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müåä Processing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m samples with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFEATURE_METHOD\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m method...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mload_and_filter_data\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Load arrays\u001b[39;00m\n\u001b[32m     12\u001b[39m X = h5_file[\u001b[33m'\u001b[39m\u001b[33mX\u001b[39m\u001b[33m'\u001b[39m]  \u001b[38;5;66;03m# Shape: (samples, 1024, 2)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m Y = \u001b[43mnp\u001b[49m.argmax(h5_file[\u001b[33m'\u001b[39m\u001b[33mY\u001b[39m\u001b[33m'\u001b[39m], axis=\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# Labels\u001b[39;00m\n\u001b[32m     14\u001b[39m Z = h5_file[\u001b[33m'\u001b[39m\u001b[33mZ\u001b[39m\u001b[33m'\u001b[39m][:, \u001b[32m0\u001b[39m]  \u001b[38;5;66;03m# SNRs\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   Original dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX.shape[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m samples\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "features1, features2, labels, snrs = preprocess_focused_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0d4308-5422-4d2f-9044-5f7e781eafc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_1d_samples():\n",
    "    \"\"\"Visualize sample 1D features to verify processing.\"\"\"\n",
    "    \n",
    "    print(f\"\\nüîç Visualizing sample 1D features...\")\n",
    "    \n",
    "    # Load train data\n",
    "    train_file = os.path.join(OUTPUT_DIR, f'train_{FEATURE_METHOD}.h5')\n",
    "    \n",
    "    with h5py.File(train_file, 'r') as f:\n",
    "        features1 = f['feature1'][:6]  # First 6 samples\n",
    "        features2 = f['feature2'][:6]\n",
    "        labels = f['labels'][:6]\n",
    "        snrs = f['snrs'][:6]\n",
    "        \n",
    "        # Handle string attributes safely\n",
    "        feature1_name = safe_decode_attr(f.attrs['feature1_name'])\n",
    "        feature2_name = safe_decode_attr(f.attrs['feature2_name'])\n",
    "    \n",
    "    # Plot samples\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(15, 10))\n",
    "    fig.suptitle(f'Sample 1D Features: {FEATURE_METHOD}', fontsize=16)\n",
    "    \n",
    "    for i in range(6):\n",
    "        row = i // 2\n",
    "        col = i % 2\n",
    "        \n",
    "        # Plot both features for each sample\n",
    "        x_axis = np.arange(len(features1[i]))\n",
    "        \n",
    "        axes[row, col].plot(x_axis, features1[i], label=feature1_name, alpha=0.8, linewidth=1)\n",
    "        axes[row, col].plot(x_axis, features2[i], label=feature2_name, alpha=0.8, linewidth=1)\n",
    "        \n",
    "        mod_name = TARGET_MODULATIONS[labels[i]]\n",
    "        axes[row, col].set_title(f'{mod_name} at {snrs[i]:.0f}dB')\n",
    "        axes[row, col].set_xlabel('Sample Index')\n",
    "        axes[row, col].set_ylabel('Amplitude')\n",
    "        axes[row, col].legend()\n",
    "        axes[row, col].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, f'sample_1d_features_{FEATURE_METHOD}.png'), dpi=150)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"‚úÖ Sample 1D visualization saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3667f86-0b0a-484d-8db2-b49c9c758b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_1d_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dd191e-dd96-4587-b198-a926218267ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_statistics():\n",
    "    \"\"\"Plot feature statistics and distributions.\"\"\"\n",
    "    \n",
    "    print(f\"\\nüìà Analyzing feature statistics...\")\n",
    "    \n",
    "    train_file = os.path.join(OUTPUT_DIR, f'train_{FEATURE_METHOD}.h5')\n",
    "    \n",
    "    with h5py.File(train_file, 'r') as f:\n",
    "        features1 = f['feature1'][:]\n",
    "        features2 = f['feature2'][:]\n",
    "        labels = f['labels'][:]\n",
    "        \n",
    "        # Handle string attributes safely\n",
    "        feature1_name = safe_decode_attr(f.attrs['feature1_name'])\n",
    "        feature2_name = safe_decode_attr(f.attrs['feature2_name'])\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    \n",
    "    # Feature 1 statistics by modulation\n",
    "    for mod_idx, mod_name in enumerate(TARGET_MODULATIONS):\n",
    "        mask = (labels == mod_idx)\n",
    "        feature_subset = features1[mask]\n",
    "        \n",
    "        # Mean and std across samples\n",
    "        mean_values = np.mean(feature_subset, axis=0)\n",
    "        std_values = np.std(feature_subset, axis=0)\n",
    "        \n",
    "        x = np.arange(len(mean_values))\n",
    "        axes[0, 0].plot(x, mean_values, label=f'{mod_name} mean', alpha=0.8)\n",
    "        axes[0, 0].fill_between(x, mean_values - std_values, mean_values + std_values, alpha=0.2)\n",
    "    \n",
    "    axes[0, 0].set_title(f'{feature1_name} - Mean ¬± Std by Modulation')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Feature 2 statistics by modulation\n",
    "    for mod_idx, mod_name in enumerate(TARGET_MODULATIONS):\n",
    "        mask = (labels == mod_idx)\n",
    "        feature_subset = features2[mask]\n",
    "        \n",
    "        mean_values = np.mean(feature_subset, axis=0)\n",
    "        std_values = np.std(feature_subset, axis=0)\n",
    "        \n",
    "        x = np.arange(len(mean_values))\n",
    "        axes[0, 1].plot(x, mean_values, label=f'{mod_name} mean', alpha=0.8)\n",
    "        axes[0, 1].fill_between(x, mean_values - std_values, mean_values + std_values, alpha=0.2)\n",
    "    \n",
    "    axes[0, 1].set_title(f'{feature2_name} - Mean ¬± Std by Modulation')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Distribution histograms\n",
    "    for mod_idx, mod_name in enumerate(TARGET_MODULATIONS):\n",
    "        mask = (labels == mod_idx)\n",
    "        \n",
    "        # Feature 1 distribution\n",
    "        f1_flat = features1[mask].flatten()\n",
    "        axes[1, 0].hist(f1_flat, bins=50, alpha=0.5, label=f'{mod_name}', density=True)\n",
    "        \n",
    "        # Feature 2 distribution\n",
    "        f2_flat = features2[mask].flatten()\n",
    "        axes[1, 1].hist(f2_flat, bins=50, alpha=0.5, label=f'{mod_name}', density=True)\n",
    "    \n",
    "    axes[1, 0].set_title(f'{feature1_name} - Value Distribution')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].set_xlabel('Feature Value')\n",
    "    axes[1, 0].set_ylabel('Density')\n",
    "    \n",
    "    axes[1, 1].set_title(f'{feature2_name} - Value Distribution')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].set_xlabel('Feature Value')\n",
    "    axes[1, 1].set_ylabel('Density')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, f'feature_statistics_{FEATURE_METHOD}.png'), dpi=150)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"‚úÖ Feature statistics plot saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d3c6f2-b9f0-48b7-a9b9-30cfb068745f",
   "metadata": {},
   "outputs": [],
   "source": [
    "   plot_feature_statistics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680e4aa9-c473-4f53-af9a-4b832925a852",
   "metadata": {},
   "source": [
    "### **TRAINING CODE START HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43efb9fe-afac-45ef-bdc3-d3b1a9b89770",
   "metadata": {},
   "source": [
    "## CONFIGURATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50769994-3184-460e-be50-ef6bacba21ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.0015\n",
    "NUM_EPOCHS = 50\n",
    "PATIENCE = 10  # Early stopping patience\n",
    "MIN_DELTA = 0.001  # Minimum improvement for early stopping\n",
    "\n",
    "# Model configuration\n",
    "DROPOUT_RATE = 0.3\n",
    "NUM_CLASSES = len(TARGET_MODULATIONS)  # 8PSK vs 16QAM\n",
    "\n",
    "# Data paths\n",
    "DATA_DIR = OUTPUT_DIR  # Adjust path as needed\n",
    "#FEATURE_METHOD = 'amplitude_phase'  # Change based on your preprocessing\n",
    "\n",
    "# Output paths\n",
    "RESULTS_DIR = './training_results'\n",
    "MODEL_SAVE_PATH = os.path.join(RESULTS_DIR, f'best_model_{FEATURE_METHOD}.pth')\n",
    "PLOTS_DIR = os.path.join(RESULTS_DIR, 'plots')\n",
    "\n",
    "# Device configuration\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üöÄ Using device: {DEVICE}\")\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "os.makedirs(PLOTS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a1c534-6fd0-4000-a058-f6d250f5d721",
   "metadata": {},
   "source": [
    "- **1D MODEL ARCHITECTURES (Adapted from My 2D model)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64477663-2bd1-4238-a3f4-b48474abec35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Enhanced CNN Branches with Deeper Layers\n",
    "class CNN1D_Shallow(nn.Module):\n",
    "    \"\"\"Enhanced shallow branch with more layers\"\"\"\n",
    "    def __init__(self, input_size, dropout_rate=0.3):\n",
    "        super().__init__()\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 64, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv1d(64, 64, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.LeakyReLU(0.1),\n",
    "        )\n",
    "        \n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv1d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "        )\n",
    "        \n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, 1, seq_len)\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.conv_block2(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        return x  # Keep temporal dimension\n",
    "\n",
    "class CNN1D_Deep(nn.Module):\n",
    "    \"\"\"Enhanced deep branch with more layers\"\"\"\n",
    "    def __init__(self, input_size, dropout_rate=0.3):\n",
    "        super().__init__()\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 64, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv1d(64, 64, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.LeakyReLU(0.1),\n",
    "        )\n",
    "        \n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv1d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "        )\n",
    "        \n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            nn.Conv1d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv1d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "        )\n",
    "        \n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.conv_block2(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.conv_block3(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        return x  # Keep temporal dimension\n",
    "\n",
    "# Cell 2: Fixed LSTM Integration\n",
    "class DiagramModel1D(nn.Module):\n",
    "    \"\"\"1D model with proper LSTM integration\"\"\"\n",
    "    def __init__(self, input_size, num_classes, dropout_rate=0.4):\n",
    "        super().__init__()\n",
    "        self.cnn1 = CNN1D_Shallow(input_size, dropout_rate)\n",
    "        self.cnn2 = CNN1D_Deep(input_size, dropout_rate)\n",
    "        \n",
    "        # Calculate output channels after CNN processing\n",
    "        self.shallow_out_channels = 128\n",
    "        self.deep_out_channels = 256\n",
    "        \n",
    "        # LSTM input size (shallow + deep channels)\n",
    "        lstm_input_size = self.shallow_out_channels + self.deep_out_channels\n",
    "        \n",
    "        # Bidirectional LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=lstm_input_size,\n",
    "            hidden_size=256,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout_rate\n",
    "        )\n",
    "        \n",
    "        # Attention mechanism\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(512, 128),  # 256*2 (bidirectional)\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.dim() == 2:\n",
    "            x = x.unsqueeze(1)\n",
    "            \n",
    "        # Process through both branches\n",
    "        shallow_out = self.cnn1(x)  # (batch, 128, seq_len/4)\n",
    "        deep_out = self.cnn2(x)     # (batch, 256, seq_len/8)\n",
    "        \n",
    "        # Adjust sequence lengths using adaptive pooling\n",
    "        target_length = min(shallow_out.size(2), deep_out.size(2))\n",
    "        shallow_out = F.adaptive_avg_pool1d(shallow_out, target_length)\n",
    "        deep_out = F.adaptive_avg_pool1d(deep_out, target_length)\n",
    "        \n",
    "        # Concatenate along channel dimension\n",
    "        fused = torch.cat((shallow_out, deep_out), dim=1)  # (batch, 384, seq_len)\n",
    "        \n",
    "        # Permute for LSTM: (batch, seq_len, features)\n",
    "        lstm_input = fused.permute(0, 2, 1)\n",
    "        \n",
    "        # LSTM processing\n",
    "        lstm_out, _ = self.lstm(lstm_input)  # (batch, seq_len, 512)\n",
    "        \n",
    "        # Attention mechanism\n",
    "        attention_weights = self.attention(lstm_out)  # (batch, seq_len, 1)\n",
    "        context_vector = torch.sum(attention_weights * lstm_out, dim=1)  # (batch, 512)\n",
    "        \n",
    "        # Classification\n",
    "        output = self.classifier(context_vector)\n",
    "        return output\n",
    "\n",
    "# Cell 3: Dual-Channel Processing Model\n",
    "class DiagramIQModel1D(nn.Module):\n",
    "    \"\"\"1D model for I/Q dual-channel processing\"\"\"\n",
    "    def __init__(self, input_size, num_classes, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.feature1_branch = DiagramModel1D(input_size, num_classes, dropout_rate)\n",
    "        self.feature2_branch = DiagramModel1D(input_size, num_classes, dropout_rate)\n",
    "        \n",
    "        # Feature fusion\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(num_classes * 2, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, feature1, feature2):\n",
    "        out1 = self.feature1_branch(feature1)\n",
    "        out2 = self.feature2_branch(feature2)\n",
    "        \n",
    "        # Concatenate and fuse\n",
    "        combined = torch.cat([out1, out2], dim=1)\n",
    "        output = self.fusion(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e5192a-2135-4124-9cde-020b2c532957",
   "metadata": {},
   "source": [
    "## DATASET CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ff870c-9b6b-4766-8096-9a1b101d4b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RadioMLDataset(Dataset):\n",
    "    \"\"\"Dataset class for RadioML 1D preprocessed data\"\"\"\n",
    "    \n",
    "    def __init__(self, hdf5_path):\n",
    "        self.hdf5_path = hdf5_path\n",
    "        \n",
    "        with h5py.File(hdf5_path, 'r') as f:\n",
    "            self.feature1 = f['feature1'][:]\n",
    "            self.feature2 = f['feature2'][:]\n",
    "            self.labels = f['labels'][:]\n",
    "            self.snrs = f['snrs'][:]\n",
    "            \n",
    "            # Load metadata\n",
    "            self.num_samples = f.attrs['num_samples']\n",
    "            self.feature_method = f.attrs['feature_method']\n",
    "            if isinstance(self.feature_method, bytes):\n",
    "                self.feature_method = self.feature_method.decode('utf-8')\n",
    "                \n",
    "            self.feature_length = f.attrs.get('feature_length', self.feature1.shape[1])\n",
    "        \n",
    "        print(f\"üìä Loaded dataset: {self.num_samples} samples\")\n",
    "        print(f\"   Feature method: {self.feature_method}\")\n",
    "        print(f\"   Feature shapes: {self.feature1.shape}, {self.feature2.shape}\")\n",
    "        \n",
    "        # Class distribution\n",
    "        unique, counts = np.unique(self.labels, return_counts=True)\n",
    "        for label, count in zip(unique, counts):\n",
    "            mod_name = '8PSK' if label == 0 else '16QAM'\n",
    "            print(f\"   {mod_name}: {count} samples\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        feature1 = torch.FloatTensor(self.feature1[idx])\n",
    "        feature2 = torch.FloatTensor(self.feature2[idx])\n",
    "        label = torch.LongTensor([self.labels[idx]])[0]\n",
    "        snr = self.snrs[idx]\n",
    "        \n",
    "        return feature1, feature2, label, snr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c1f5e0-0ec3-4281-8f60-2f3c260ae510",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stopping utility\"\"\"\n",
    "    def __init__(self, patience=7, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "\n",
    "    def __call__(self, val_score):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = val_score\n",
    "        elif val_score < self.best_score + self.min_delta:\n",
    "            self.counter += 1\n",
    "        else:\n",
    "            self.best_score = val_score\n",
    "            self.counter = 0\n",
    "        \n",
    "        return self.counter >= self.patience"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95151dfe-8647-4da3-ab86-9906bffead0a",
   "metadata": {},
   "source": [
    "## DATA LOADER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d93b13-4466-4865-a80e-d784031af124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loaders():\n",
    "    \"\"\"Create train and validation data loaders\"\"\"\n",
    "    train_path = os.path.join(DATA_DIR, f'train_{FEATURE_METHOD}.h5')\n",
    "    valid_path = os.path.join(DATA_DIR, f'valid_{FEATURE_METHOD}.h5')\n",
    "    \n",
    "    # Check file existence\n",
    "    if not os.path.exists(train_path):\n",
    "        raise FileNotFoundError(f\"Training data not found: {train_path}\")\n",
    "    if not os.path.exists(valid_path):\n",
    "        raise FileNotFoundError(f\"Validation data not found: {valid_path}\")\n",
    "    \n",
    "    # Create datasets and loaders\n",
    "    train_dataset = RadioMLDataset(train_path)\n",
    "    valid_dataset = RadioMLDataset(valid_path)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=True, \n",
    "        num_workers=4,\n",
    "        pin_memory=True if DEVICE.type == 'cuda' else False\n",
    "    )\n",
    "    \n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=False, \n",
    "        num_workers=4,\n",
    "        pin_memory=True if DEVICE.type == 'cuda' else False\n",
    "    )\n",
    "    \n",
    "    return train_loader, valid_loader, train_dataset.feature_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b31cea5-63a6-4984-8662-d9ae8cacc929",
   "metadata": {},
   "source": [
    "## TRAINING AND VALIDATION FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f1d3e1-363a-4a59-afbf-3053818610f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, optimizer, criterion, device):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=\"Training\")\n",
    "    for feature1, feature2, labels, snrs in pbar:\n",
    "        feature1 = feature1.to(device)\n",
    "        feature2 = feature2.to(device) \n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(feature1, feature2)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            'Loss': f'{loss.item():.4f}',\n",
    "            'Acc': f'{100.*correct/total:.2f}%'\n",
    "        })\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = 100. * correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def validate_epoch(model, valid_loader, criterion, device):\n",
    "    \"\"\"Validate for one epoch\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_snrs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(valid_loader, desc=\"Validation\")\n",
    "        for feature1, feature2, labels, snrs in pbar:\n",
    "            feature1 = feature1.to(device)\n",
    "            feature2 = feature2.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(feature1, feature2)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_snrs.extend(snrs.numpy())\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                'Loss': f'{loss.item():.4f}',\n",
    "                'Acc': f'{100.*correct/total:.2f}%'\n",
    "            })\n",
    "    \n",
    "    avg_loss = total_loss / len(valid_loader)\n",
    "    accuracy = 100. * correct / total\n",
    "    return avg_loss, accuracy, all_predictions, all_labels, all_snrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427a2f47-c7f1-48ef-bb5b-fded3031e40e",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaa0ea1-7d85-4f9c-9019-40e67b691290",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def train_model():\n",
    "    \"\"\"Main training function\"\"\"\n",
    "    print(\"üéØ Starting Focused Training: 8PSK vs 16QAM\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader, valid_loader, feature_length = create_data_loaders()\n",
    "    \n",
    "    # Initialize model\n",
    "    model = DiagramIQModel1D(\n",
    "        input_size=feature_length,\n",
    "        num_classes=NUM_CLASSES,\n",
    "        dropout_rate=DROPOUT_RATE\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    # Print model info\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"üß† Model: DiagramIQModel1D\")\n",
    "    print(f\"   Total parameters: {total_params:,}\")\n",
    "    print(f\"   Feature length: {feature_length}\")\n",
    "    print(f\"   Classes: {NUM_CLASSES}\")\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.2)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=5e-3)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=8\n",
    "    )\n",
    "    \n",
    "    # Early stopping\n",
    "    early_stopping = EarlyStopping(patience=PATIENCE, min_delta=MIN_DELTA)\n",
    "    \n",
    "    # Training history\n",
    "    history = defaultdict(list)\n",
    "    best_val_acc = 0\n",
    "    best_epoch = 0\n",
    "    \n",
    "    print(f\"\\nüöÄ Training started...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print(f\"\\nüìà Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Training\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, DEVICE)\n",
    "        \n",
    "        # Validation  \n",
    "        val_loss, val_acc, val_preds, val_labels, val_snrs = validate_epoch(\n",
    "            model, valid_loader, criterion, DEVICE\n",
    "        )\n",
    "        \n",
    "        # Learning rate scheduling\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Store history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['lr'].append(optimizer.param_groups[0]['lr'])\n",
    "        \n",
    "        # Print epoch results\n",
    "        print(f\"Train - Loss: {train_loss:.4f}, Acc: {train_acc:.2f}%\")\n",
    "        print(f\"Valid - Loss: {val_loss:.4f}, Acc: {val_acc:.2f}%\")\n",
    "        print(f\"Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_epoch = epoch + 1\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'train_loss': train_loss,\n",
    "                'val_loss': val_loss,\n",
    "                'val_acc': val_acc,\n",
    "                'feature_method': FEATURE_METHOD\n",
    "            }, MODEL_SAVE_PATH)\n",
    "            print(f\"üíæ New best model saved! (Acc: {val_acc:.2f}%)\")\n",
    "        \n",
    "        # Early stopping check\n",
    "        if early_stopping(val_acc):\n",
    "            print(f\"‚èπÔ∏è Early stopping triggered at epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\n‚úÖ Training completed!\")\n",
    "    print(f\"   Total time: {total_time/60:.1f} minutes\")\n",
    "    print(f\"   Best validation accuracy: {best_val_acc:.2f}% (epoch {best_epoch})\")\n",
    "    \n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b110246f-0167-43c5-8a54-8f49d0bbb4b4",
   "metadata": {},
   "source": [
    "# Evaluation & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413371e5-7e26-4747-a740-a8b16298db34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model():\n",
    "    \"\"\"Evaluate the trained model and create visualizations\"\"\"\n",
    "    print(\"\\nüîç Evaluating trained model...\")\n",
    "    \n",
    "    # Load data\n",
    "    train_loader, valid_loader, feature_length = create_data_loaders()\n",
    "    \n",
    "    # Load best model\n",
    "    model = DiagramIQModel1D(\n",
    "        input_size=feature_length,\n",
    "        num_classes=NUM_CLASSES,\n",
    "        dropout_rate=DROPOUT_RATE\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    checkpoint = torch.load(MODEL_SAVE_PATH, map_location=DEVICE)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"üìÅ Loaded model from epoch {checkpoint['epoch']+1}\")\n",
    "    \n",
    "    # Evaluate\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    val_loss, val_acc, val_preds, val_labels, val_snrs = validate_epoch(\n",
    "        model, valid_loader, criterion, DEVICE\n",
    "    )\n",
    "    \n",
    "    # Calculate metrics\n",
    "    f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "    \n",
    "    print(f\"üìä Final Results:\")\n",
    "    print(f\"   Accuracy: {val_acc:.2f}%\")\n",
    "    print(f\"   F1-Score: {f1:.4f}\")\n",
    "    print(f\"   Loss: {val_loss:.4f}\")\n",
    "    \n",
    "    # Classification report\n",
    "    class_names = ['8PSK', '16QAM']\n",
    "    print(f\"\\nüìã Classification Report:\")\n",
    "    print(classification_report(val_labels, val_preds, target_names=class_names))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(val_labels, val_preds)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig(os.path.join(PLOTS_DIR, 'confusion_matrix.png'), dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Performance by SNR\n",
    "    snr_results = {}\n",
    "    for snr in np.unique(val_snrs):\n",
    "        mask = np.array(val_snrs) == snr\n",
    "        snr_acc = accuracy_score(np.array(val_labels)[mask], np.array(val_preds)[mask])\n",
    "        snr_results[snr] = snr_acc * 100\n",
    "        print(f\"   SNR {snr:2.0f}dB: {snr_acc*100:.2f}%\")\n",
    "    \n",
    "    # Plot SNR performance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    snrs = sorted(snr_results.keys())\n",
    "    accs = [snr_results[snr] for snr in snrs]\n",
    "    \n",
    "    plt.plot(snrs, accs, 'bo-', linewidth=2, markersize=8)\n",
    "    plt.xlabel('SNR (dB)')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title('Classification Accuracy vs SNR')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.ylim([0, 100])\n",
    "    \n",
    "    for snr, acc in zip(snrs, accs):\n",
    "        plt.annotate(f'{acc:.1f}%', (snr, acc), textcoords=\"offset points\", \n",
    "                    xytext=(0,10), ha='center')\n",
    "    \n",
    "    plt.savefig(os.path.join(PLOTS_DIR, 'accuracy_vs_snr.png'), dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return val_acc, f1\n",
    "\n",
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training history\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Loss plot\n",
    "    axes[0, 0].plot(history['train_loss'], label='Train Loss', color='blue')\n",
    "    axes[0, 0].plot(history['val_loss'], label='Validation Loss', color='red')\n",
    "    axes[0, 0].set_title('Training and Validation Loss')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Accuracy plot\n",
    "    axes[0, 1].plot(history['train_acc'], label='Train Accuracy', color='blue')\n",
    "    axes[0, 1].plot(history['val_acc'], label='Validation Accuracy', color='red')\n",
    "    axes[0, 1].set_title('Training and Validation Accuracy')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Accuracy (%)')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Learning rate plot\n",
    "    axes[1, 0].plot(history['lr'], color='green')\n",
    "    axes[1, 0].set_title('Learning Rate Schedule')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Learning Rate')\n",
    "    axes[1, 0].set_yscale('log')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Best accuracy highlight\n",
    "    best_val_idx = np.argmax(history['val_acc'])\n",
    "    best_val_acc = history['val_acc'][best_val_idx]\n",
    "    \n",
    "    axes[1, 1].plot(history['val_acc'], color='red', linewidth=2)\n",
    "    axes[1, 1].scatter(best_val_idx, best_val_acc, color='gold', s=100, zorder=5)\n",
    "    axes[1, 1].set_title(f'Best Validation Accuracy: {best_val_acc:.2f}%')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Validation Accuracy (%)')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(PLOTS_DIR, 'training_history.png'), dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f4ca1d-e34b-4b85-aa81-772fca3207d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "history, model = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4037a3-34fd-4d0d-9696-deb683960dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9981bcf-50da-4216-99d2-b91fddbc43a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc, f1 = evaluate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d004ffcb-328a-40c3-a034-990686b5815a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44a3393-b1bc-4b3d-9182-a4202ffa7eb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
