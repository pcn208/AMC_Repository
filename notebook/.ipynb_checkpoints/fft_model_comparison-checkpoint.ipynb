{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d13d1c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torchinfo import summary\n",
    "from typing import Tuple, Optional\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tqdm import tqdm, trange\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import time \n",
    "import time\n",
    "import warnings\n",
    "from collections import deque\n",
    "import psutil\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba269b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2107bea0",
   "metadata": {},
   "source": [
    "### **CONFIGURATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54ffca92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Training Parameters:\n",
      "  Batch size: 512\n",
      "  Epochs: 100\n"
     ]
    }
   ],
   "source": [
    "FILE_PATH = \"C:\\\\workarea\\\\CNN model\\\\dataset\\\\radioml2018\\\\versions\\\\2\\\\GOLD_XYZ_OSC.0001_1024.hdf5\"\n",
    "JSON_PATH = 'C:\\\\workarea\\\\CNN model\\\\dataset\\\\radioml2018\\\\versions\\\\2\\\\classes-fixed.json' \n",
    "\n",
    "TARGET_MODULATIONS = [\n",
    "                    #   'OOK',\n",
    "                      '4ASK',\n",
    "                      '8ASK',\n",
    "                    #   'BPSK', \n",
    "                      'QPSK', \n",
    "                      '8PSK', \n",
    "                      '16QAM',\n",
    "                      '64QAM',\n",
    "                    #   'OQPSK'\n",
    "                     ]\n",
    "#TARGET_MODULATIONS = ['OOK','4ASK','BPSK', 'QPSK', '8PSK','16QAM','GMSK']\n",
    "BATCH_SIZE = 512 # adjust to my laptop \n",
    "#LEARNING_RATE = 0.003 \n",
    "NUM_EPOCHS = 100 \n",
    "NUM_WORKERS = 0 #Temporary check it  \n",
    "\n",
    "INPUT_CHANNELS = 2 \n",
    "SEQUENCE_LENGTH = 1024 \n",
    "NUM_CLASSES = len(TARGET_MODULATIONS) # adjust this to \n",
    "\n",
    "patience = 25\n",
    "# TRAIN_RATIO = 0.7 \n",
    "# VALID_RATIO = 0.2 \n",
    "# TEST_RATIO = 0.1 \n",
    "\n",
    "nf_train = int(BATCH_SIZE * 0.7)\n",
    "nf_valid = int(BATCH_SIZE * 0.3)\n",
    "nf_test  = BATCH_SIZE - nf_train - nf_valid\n",
    "\n",
    "print(\"üìã Training Parameters:\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "#print(f\"  Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"  Epochs: {NUM_EPOCHS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3b08915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_split(data,\n",
    "                  modulations_classes,\n",
    "                  modulations,\n",
    "                  snrs,\n",
    "                  target_modulations,\n",
    "                  mode,\n",
    "                  target_snrs,\n",
    "                  train_proportion=0.7, # training 70 %\n",
    "                  valid_proportion=0.3, # validation 20 %\n",
    "                  test_proportion=0.0, # testing 10 % \n",
    "                  seed=48):\n",
    "    np.random.seed(seed)\n",
    "    X_output = []\n",
    "    Y_output = []\n",
    "    Z_output = []                                   \n",
    "\n",
    "    target_modulation_indices = [modulations_classes.index(modu) for modu in target_modulations]\n",
    "\n",
    "    for modu in target_modulation_indices:\n",
    "        for snr in target_snrs:\n",
    "            snr_modu_indices = np.where((modulations == modu) & (snrs == snr))[0]\n",
    "\n",
    "            np.random.shuffle(snr_modu_indices)\n",
    "            num_samples = len(snr_modu_indices)\n",
    "            train_end = int(train_proportion * num_samples)\n",
    "            valid_end = int((train_proportion + valid_proportion) * num_samples)\n",
    "\n",
    "            if mode == 'train':\n",
    "                indices = snr_modu_indices[:train_end]\n",
    "            elif mode == 'valid':\n",
    "                indices = snr_modu_indices[train_end:valid_end]\n",
    "            elif mode == 'test':\n",
    "                indices = snr_modu_indices[valid_end:]\n",
    "            else:\n",
    "                raise ValueError(f'unknown mode: {mode}. Valid modes are train, valid and test')\n",
    "\n",
    "            X_output.append(data[np.sort(indices)])\n",
    "            Y_output.append(modulations[np.sort(indices)])\n",
    "            Z_output.append(snrs[np.sort(indices)])\n",
    "\n",
    "    X_array = np.vstack(X_output)\n",
    "    Y_array = np.concatenate(Y_output)\n",
    "    Z_array = np.concatenate(Z_output)\n",
    "    for index, value in enumerate(np.unique(np.copy(Y_array))):\n",
    "        Y_array[Y_array == value] = index\n",
    "    return X_array, Y_array, Z_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c909c667",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RadioMLIQDataset(Dataset):\n",
    "    \"\"\"Dataset class for RadioML18 data formatted for CNNIQModel dual-branch architecture.\n",
    "    \n",
    "    Loads RadioML18 HDF5 data and returns separate I and Q tensors in 2D format\n",
    "    suitable for CNNIQModel's separate branch processing.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, mode: str, use_fft: bool = False, seed: int = 48, target_snrs: list = [-6, 6, 16]):\n",
    "        \"\"\"Initialize RadioMLIQDataset.\n",
    "        \n",
    "        Args:\n",
    "            mode: Dataset split mode ('train', 'valid', or 'test').\n",
    "            use_fft: Whether to apply FFT transformation to signals.\n",
    "            seed: Random seed for dataset splitting.\n",
    "            target_snrs: List of SNR levels to include in training (default: [-6, 6, 16])\n",
    "            \n",
    "        Raises:\n",
    "            FileNotFoundError: If HDF5 or JSON files cannot be found.\n",
    "            ValueError: If mode is not valid or data dimensions are incompatible.\n",
    "        \"\"\"\n",
    "        super(RadioMLIQDataset, self).__init__()\n",
    "        \n",
    "        # Configuration (you'll need to define these constants)\n",
    "        self.file_path = FILE_PATH \n",
    "        self.json_path = JSON_PATH \n",
    "        self.target_modulations = TARGET_MODULATIONS\n",
    "        self.use_fft = use_fft\n",
    "        self.mode = mode\n",
    "        \n",
    "        # Validate mode\n",
    "        if mode not in ['train', 'valid', 'test']:\n",
    "            raise ValueError(f\"Mode must be 'train', 'valid', or 'test', got '{mode}'\")\n",
    "        \n",
    "        # Load data files\n",
    "        try:\n",
    "            self.hdf5_file = h5py.File(self.file_path, 'r')\n",
    "            self.modulation_classes = json.load(open(self.json_path, 'r'))\n",
    "        except FileNotFoundError as e:\n",
    "            raise FileNotFoundError(f\"Error loading data files: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading file: {e}\")\n",
    "            raise e\n",
    "        \n",
    "        # Load raw data\n",
    "        self.X = self.hdf5_file['X']\n",
    "        self.Y = np.argmax(self.hdf5_file['Y'], axis=1)\n",
    "        self.Z = self.hdf5_file['Z'][:, 0]\n",
    "        \n",
    "        # Set target SNR levels - MODIFIED FOR SPECIFIC SNR LEVELS\n",
    "        self.target_snrs = np.array(target_snrs)  # [-6, 6, 16] dB\n",
    "        print(f\"üéØ Training on SNR levels: {self.target_snrs} dB\")\n",
    "        \n",
    "        # Check if target SNRs exist in dataset\n",
    "        available_snrs = np.unique(self.Z)\n",
    "        missing_snrs = [snr for snr in self.target_snrs if snr not in available_snrs]\n",
    "        if missing_snrs:\n",
    "            print(f\"‚ö†Ô∏è Warning: SNR levels {missing_snrs} not found in dataset\")\n",
    "            print(f\"Available SNR levels: {available_snrs}\")\n",
    "            # Filter to only include available SNRs\n",
    "            self.target_snrs = np.array([snr for snr in self.target_snrs if snr in available_snrs])\n",
    "            print(f\"üîß Adjusted target SNRs to: {self.target_snrs}\")\n",
    "        \n",
    "        # Calculate proportions based on ACTUAL number of SNRs and modulations\n",
    "        num_mods = len(self.target_modulations)   \n",
    "        num_snrs = len(self.target_snrs)  # CHANGED: Use actual target SNRs count\n",
    "        \n",
    "        print(f\"üìä Dataset composition: {num_mods} modulations √ó {num_snrs} SNR levels\")\n",
    "        \n",
    "        # Calculate expected samples per split\n",
    "        expected_samples_per_mod_snr = nf_train + nf_valid + nf_test  # This should equal BATCH_SIZE\n",
    "        total_expected_samples = num_mods * num_snrs * expected_samples_per_mod_snr\n",
    "        \n",
    "        train_proportion = (num_mods * num_snrs * nf_train) / total_expected_samples\n",
    "        valid_proportion = (num_mods * num_snrs * nf_valid) / total_expected_samples  \n",
    "        test_proportion  = (num_mods * num_snrs * nf_test ) / total_expected_samples\n",
    "        \n",
    "        print(f\"üìà Split proportions - Train: {train_proportion:.3f}, Valid: {valid_proportion:.3f}, Test: {test_proportion:.3f}\")\n",
    "        \n",
    "        # Split dataset\n",
    "        self.X_data, self.Y_data, self.Z_data = dataset_split(\n",
    "            data=self.X,\n",
    "            modulations_classes=self.modulation_classes,\n",
    "            modulations=self.Y,\n",
    "            snrs=self.Z,\n",
    "            mode=mode,\n",
    "            train_proportion=train_proportion,\n",
    "            valid_proportion=valid_proportion,\n",
    "            test_proportion=test_proportion,\n",
    "            target_modulations=self.target_modulations,\n",
    "            target_snrs=self.target_snrs,  # Use filtered SNR levels\n",
    "            seed=seed\n",
    "        )\n",
    "        \n",
    "        # Apply I/Q swap correction for AMC compatibility\n",
    "        self.X_data = self.X_data[:, :, [0, 1]]\n",
    "        \n",
    "        # Validate signal length for 2D reshaping\n",
    "        signal_length = self.X_data.shape[1]\n",
    "        if signal_length != 1024:\n",
    "            raise ValueError(f\"Expected signal length 1024 for 32x32 reshape, got {signal_length}\")\n",
    "\n",
    "        import math\n",
    "        \n",
    "        L = signal_length\n",
    "        H = int(math.floor(math.sqrt(L)))\n",
    "        while L % H != 0:\n",
    "            H -= 1\n",
    "        W = L // H\n",
    "        \n",
    "        self.H, self.W = H, W\n",
    "        print(f\"üîß Signals will be reshaped to ({H}, {W}) for sequence length {L}\")\n",
    "        print(f\"‚úÖ Aspect ratio: {W/H:.2f}, Total elements preserved: {H*W} = {L}\")\n",
    "        \n",
    "        if self.use_fft:\n",
    "            print(\"Dataset configured to use FFT as input\")\n",
    "        \n",
    "        # Store dataset statistics\n",
    "        self.num_data = self.X_data.shape[0]\n",
    "        self.num_lbl = len(self.target_modulations)\n",
    "        self.num_snr = len(self.target_snrs)  # CHANGED: Use actual target SNRs count\n",
    "        \n",
    "        print(f\"üì¶ RadioMLIQDataset {mode}: {self.num_data} samples, \"\n",
    "              f\"{self.num_lbl} classes, {self.num_snr} SNR levels\")\n",
    "        print(f\"üéØ SNR distribution in {mode} set:\")\n",
    "        unique_snrs_in_data, counts = np.unique(self.Z_data, return_counts=True)\n",
    "        for snr, count in zip(unique_snrs_in_data, counts):\n",
    "            print(f\"   SNR {snr:3.0f} dB: {count:4d} samples\")\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Return the number of samples in the dataset.\n",
    "        \n",
    "        Returns:\n",
    "            Number of samples.\n",
    "        \"\"\"\n",
    "        return self.X_data.shape[0]\n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        if idx < 0 or idx >= self.num_data:\n",
    "            raise IndexError(f\"Index {idx} out of range for dataset of size {self.num_data}\")\n",
    "\n",
    "        x_raw = self.X_data[idx]       # shape: (L, 2)\n",
    "        y     = int(self.Y_data[idx])\n",
    "        z     = float(self.Z_data[idx])\n",
    "\n",
    "        # Convert to tensor\n",
    "        x = torch.from_numpy(x_raw).float().transpose(0, 1)  # shape: (2, L)\n",
    "\n",
    "        if self.use_fft:\n",
    "            # Option 1: Magnitude and Phase Spectrum\n",
    "            complex_sig = torch.complex(x[0], x[1])\n",
    "            fft_res = torch.fft.fft(complex_sig)\n",
    "            \n",
    "            # Use magnitude\n",
    "            magnitude = torch.abs(fft_res)\n",
    "            phase = torch.angle(fft_res)\n",
    "            \n",
    "            # Optional: Use log magnitude for better dynamic range\n",
    "            log_magnitude = torch.log1p(magnitude)  # log(1 + magnitude) to avoid log(0)\n",
    "            \n",
    "            # Normalize\n",
    "            log_magnitude = (log_magnitude - log_magnitude.mean()) / (log_magnitude.std() + 1e-8)\n",
    "            phase = (phase - phase.mean()) / (phase.std() + 1e-8)\n",
    "            # Reshape\n",
    "            mag_2d = log_magnitude.view(1, self.H, self.W)\n",
    "            phase_2d = phase.view(1, self.H, self.W)\n",
    "            \n",
    "            return mag_2d, phase_2d, y, z\n",
    "\n",
    "        else:\n",
    "            # Non-FFT path (amplitude/phase domain)\n",
    "            i_signal = x[0]  # shape: (L,)\n",
    "            q_signal = x[1]\n",
    "\n",
    "            amplitude = torch.sqrt(i_signal**2 + q_signal**2)\n",
    "            phase     = torch.atan2(q_signal, i_signal)\n",
    "\n",
    "            i_2d = amplitude.view(1, self.H, self.W)\n",
    "            q_2d = phase.view(1, self.H, self.W)\n",
    "\n",
    "            return i_2d, q_2d, y, z\n",
    "\n",
    "    def get_signal_stats(self):\n",
    "        \"\"\"Compute basic stats over a sample of signals.\"\"\"\n",
    "        sample_indices = np.random.choice(self.num_data, min(1000, self.num_data), replace=False)\n",
    "        i_vals, q_vals = [], []\n",
    "        for idx in sample_indices:\n",
    "            i2d, q2d, _, _ = self[idx]\n",
    "            i_vals.append(i2d.flatten())\n",
    "            q_vals.append(q2d.flatten())\n",
    "        i_all = torch.cat(i_vals)\n",
    "        q_all = torch.cat(q_vals)\n",
    "        return {\n",
    "            'i_mean': i_all.mean().item(),\n",
    "            'i_std':  i_all.std().item(),\n",
    "            'q_mean': q_all.mean().item(),\n",
    "            'q_std':  q_all.std().item(),\n",
    "            'shape':  (1, self.H, self.W),\n",
    "            'num_samples': self.num_data\n",
    "        }\n",
    "\n",
    "    def close(self):\n",
    "        if hasattr(self, 'hdf5_file'):\n",
    "            self.hdf5_file.close()\n",
    "\n",
    "    def __del__(self):\n",
    "        self.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a8e1d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully built Standard CNN-LSTM Model\n",
      "‚úÖ Successfully built Parallel CNN-LSTM Model\n"
     ]
    }
   ],
   "source": [
    "# Model 1: Standard CNN-LSTM\n",
    "try:\n",
    "    from models.CNN_LSTM_IQ import create_enhanced_CNNLSTMIQModel\n",
    "    model_standard = create_enhanced_CNNLSTMIQModel(n_labels=NUM_CLASSES, dropout_rate=0.3).to(device)\n",
    "    print(\"‚úÖ Successfully built Standard CNN-LSTM Model\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Could not build Standard Model: {e}\")\n",
    "\n",
    "# Model 2: Parallel CNN-LSTM\n",
    "try:\n",
    "    from models.CNN_LSTM_IQ_Parallel import create_fixed_parallel_model\n",
    "    model_parallel = create_fixed_parallel_model(num_classes=2, dropout_rate=0.5, use_alternative=True).to(device)\n",
    "    print(\"‚úÖ Successfully built Parallel CNN-LSTM Model\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Could not build Parallel Model: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53cf4c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary model Serial :\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "CNNLSTMIQModel                           --\n",
      "‚îú‚îÄCNNLSTMBranch: 1-1                     --\n",
      "‚îÇ    ‚îî‚îÄConv2d: 2-1                       640\n",
      "‚îÇ    ‚îî‚îÄBatchNorm2d: 2-2                  128\n",
      "‚îÇ    ‚îî‚îÄConv2d: 2-3                       36,928\n",
      "‚îÇ    ‚îî‚îÄBatchNorm2d: 2-4                  128\n",
      "‚îÇ    ‚îî‚îÄConv2d: 2-5                       73,856\n",
      "‚îÇ    ‚îî‚îÄBatchNorm2d: 2-6                  256\n",
      "‚îÇ    ‚îî‚îÄConv2d: 2-7                       147,584\n",
      "‚îÇ    ‚îî‚îÄBatchNorm2d: 2-8                  256\n",
      "‚îÇ    ‚îî‚îÄMaxPool2d: 2-9                    --\n",
      "‚îÇ    ‚îî‚îÄLeakyReLU: 2-10                   --\n",
      "‚îÇ    ‚îî‚îÄDropout2d: 2-11                   --\n",
      "‚îÇ    ‚îî‚îÄLSTM: 2-12                        92,000\n",
      "‚îÇ    ‚îî‚îÄLSTM: 2-13                        30,400\n",
      "‚îÇ    ‚îî‚îÄDropout: 2-14                     --\n",
      "‚îÇ    ‚îî‚îÄLinear: 2-15                      51\n",
      "‚îÇ    ‚îî‚îÄAdaptiveAvgPool2d: 2-16           --\n",
      "‚îú‚îÄCNNLSTMBranch: 1-2                     --\n",
      "‚îÇ    ‚îî‚îÄConv2d: 2-17                      640\n",
      "‚îÇ    ‚îî‚îÄBatchNorm2d: 2-18                 128\n",
      "‚îÇ    ‚îî‚îÄConv2d: 2-19                      36,928\n",
      "‚îÇ    ‚îî‚îÄBatchNorm2d: 2-20                 128\n",
      "‚îÇ    ‚îî‚îÄConv2d: 2-21                      73,856\n",
      "‚îÇ    ‚îî‚îÄBatchNorm2d: 2-22                 256\n",
      "‚îÇ    ‚îî‚îÄConv2d: 2-23                      147,584\n",
      "‚îÇ    ‚îî‚îÄBatchNorm2d: 2-24                 256\n",
      "‚îÇ    ‚îî‚îÄMaxPool2d: 2-25                   --\n",
      "‚îÇ    ‚îî‚îÄLeakyReLU: 2-26                   --\n",
      "‚îÇ    ‚îî‚îÄDropout2d: 2-27                   --\n",
      "‚îÇ    ‚îî‚îÄLSTM: 2-28                        92,000\n",
      "‚îÇ    ‚îî‚îÄLSTM: 2-29                        30,400\n",
      "‚îÇ    ‚îî‚îÄDropout: 2-30                     --\n",
      "‚îÇ    ‚îî‚îÄLinear: 2-31                      51\n",
      "‚îÇ    ‚îî‚îÄAdaptiveAvgPool2d: 2-32           --\n",
      "‚îú‚îÄSequential: 1-3                        --\n",
      "‚îÇ    ‚îî‚îÄLinear: 2-33                      13,056\n",
      "‚îÇ    ‚îî‚îÄBatchNorm1d: 2-34                 512\n",
      "‚îÇ    ‚îî‚îÄLeakyReLU: 2-35                   --\n",
      "‚îÇ    ‚îî‚îÄDropout: 2-36                     --\n",
      "‚îÇ    ‚îî‚îÄLinear: 2-37                      32,896\n",
      "‚îÇ    ‚îî‚îÄBatchNorm1d: 2-38                 256\n",
      "‚îÇ    ‚îî‚îÄLeakyReLU: 2-39                   --\n",
      "‚îÇ    ‚îî‚îÄDropout: 2-40                     --\n",
      "‚îÇ    ‚îî‚îÄLinear: 2-41                      8,256\n",
      "‚îÇ    ‚îî‚îÄLeakyReLU: 2-42                   --\n",
      "‚îÇ    ‚îî‚îÄDropout: 2-43                     --\n",
      "‚îÇ    ‚îî‚îÄLinear: 2-44                      390\n",
      "=================================================================\n",
      "Total params: 819,820\n",
      "Trainable params: 819,820\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "Summary model Parallel :\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "AlternativeParallelModel                 --\n",
      "‚îú‚îÄImprovedParallelBranch: 1-1            --\n",
      "‚îÇ    ‚îî‚îÄCNN_1: 2-1                        --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-1                  320\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-2             64\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-3                  18,496\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-4             128\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄMaxPool2d: 3-5               --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄLeakyReLU: 3-6               --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄDropout2d: 3-7               --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄAdaptiveAvgPool2d: 3-8       --\n",
      "‚îÇ    ‚îî‚îÄCNN_2: 2-2                        --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-9                  320\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-10            64\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-11                 18,496\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-12            128\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄMaxPool2d: 3-13              --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-14                 73,856\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-15            256\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-16                 147,584\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-17            256\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄMaxPool2d: 3-18              --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄLeakyReLU: 3-19              --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄDropout2d: 3-20              --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄAdaptiveAvgPool2d: 3-21      --\n",
      "‚îÇ    ‚îî‚îÄSequential: 2-3                   --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 3-22                 196,864\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm1d: 3-23            512\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄLeakyReLU: 3-24              --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 3-25                --\n",
      "‚îÇ    ‚îî‚îÄLinear: 2-4                       16,448\n",
      "‚îÇ    ‚îî‚îÄLSTM: 2-5                         66,560\n",
      "‚îÇ    ‚îî‚îÄDropout: 2-6                      --\n",
      "‚îÇ    ‚îî‚îÄLinear: 2-7                       129\n",
      "‚îú‚îÄImprovedParallelBranch: 1-2            --\n",
      "‚îÇ    ‚îî‚îÄCNN_1: 2-8                        --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-26                 320\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-27            64\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-28                 18,496\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-29            128\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄMaxPool2d: 3-30              --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄLeakyReLU: 3-31              --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄDropout2d: 3-32              --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄAdaptiveAvgPool2d: 3-33      --\n",
      "‚îÇ    ‚îî‚îÄCNN_2: 2-9                        --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-34                 320\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-35            64\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-36                 18,496\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-37            128\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄMaxPool2d: 3-38              --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-39                 73,856\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-40            256\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-41                 147,584\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-42            256\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄMaxPool2d: 3-43              --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄLeakyReLU: 3-44              --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄDropout2d: 3-45              --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄAdaptiveAvgPool2d: 3-46      --\n",
      "‚îÇ    ‚îî‚îÄSequential: 2-10                  --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 3-47                 196,864\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm1d: 3-48            512\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄLeakyReLU: 3-49              --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 3-50                --\n",
      "‚îÇ    ‚îî‚îÄLinear: 2-11                      16,448\n",
      "‚îÇ    ‚îî‚îÄLSTM: 2-12                        66,560\n",
      "‚îÇ    ‚îî‚îÄDropout: 2-13                     --\n",
      "‚îÇ    ‚îî‚îÄLinear: 2-14                      129\n",
      "‚îú‚îÄSequential: 1-3                        --\n",
      "‚îÇ    ‚îî‚îÄLinear: 2-15                      16,448\n",
      "‚îÇ    ‚îî‚îÄTanh: 2-16                        --\n",
      "‚îÇ    ‚îî‚îÄLinear: 2-17                      130\n",
      "‚îÇ    ‚îî‚îÄSoftmax: 2-18                     --\n",
      "‚îú‚îÄSequential: 1-4                        --\n",
      "‚îÇ    ‚îî‚îÄLinear: 2-19                      8,256\n",
      "‚îÇ    ‚îî‚îÄBatchNorm1d: 2-20                 128\n",
      "‚îÇ    ‚îî‚îÄReLU: 2-21                        --\n",
      "‚îÇ    ‚îî‚îÄDropout: 2-22                     --\n",
      "‚îÇ    ‚îî‚îÄLinear: 2-23                      130\n",
      "=================================================================\n",
      "Total params: 1,106,054\n",
      "Trainable params: 1,106,054\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "from torchinfo import summary \n",
    "print(f\"Summary model Serial :\\n{summary(model_standard)}\") \n",
    "print(f\"Summary model Parallel :\\n{summary(model_parallel)}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26d09856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count parameters for both models\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "standard_params = count_parameters(model_standard)\n",
    "parallel_params = count_parameters(model_parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c826203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers for both models\n",
    "optimizer_standard = optim.AdamW(\n",
    "    model_standard.parameters(), \n",
    "    lr=0.0015,\n",
    "    weight_decay=5e-3,\n",
    "    betas=(0.9, 0.999)\n",
    ")\n",
    "\n",
    "optimizer_parallel = optim.AdamW(\n",
    "    model_parallel.parameters(), \n",
    "    lr=0.0015,\n",
    "    weight_decay=5e-3,\n",
    "    betas=(0.9, 0.999)\n",
    ")\n",
    "\n",
    "# scheduler_standard = optim.lr_scheduler.MultiStepLR(\n",
    "#     optimizer_standard, \n",
    "#     milestones=[50, 100, 150], \n",
    "#     gamma=0.5\n",
    "# )\n",
    "# scheduler_parallel = optim.lr_scheduler.MultiStepLR(\n",
    "#     optimizer_parallel, \n",
    "#     milestones=[50, 100, 150], \n",
    "#     gamma=0.5\n",
    "# )\n",
    "# Schedulers for both models\n",
    "scheduler_standard = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer_standard, T_0=20, T_mult=2, eta_min=1e-6\n",
    ")\n",
    "\n",
    "scheduler_parallel = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer_parallel, T_0=20, T_mult=2, eta_min=1e-6\n",
    ")\n",
    "\n",
    "# Scalers for mixed precision\n",
    "scaler_standard = GradScaler()\n",
    "scaler_parallel = GradScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63fa2f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shared training components\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.2).to(device)\n",
    "\n",
    "# Optimizers for both models\n",
    "optimizer_standard = optim.AdamW(\n",
    "    model_standard.parameters(), \n",
    "    lr=0.0015,\n",
    "    weight_decay=5e-3,\n",
    "    betas=(0.9, 0.999)\n",
    ")\n",
    "\n",
    "optimizer_parallel = optim.AdamW(\n",
    "    model_parallel.parameters(), \n",
    "    lr=0.0015,\n",
    "    weight_decay=5e-3,\n",
    "    betas=(0.9, 0.999)\n",
    ")\n",
    "\n",
    "# scheduler_standard = optim.lr_scheduler.MultiStepLR(\n",
    "#     optimizer_standard, \n",
    "#     milestones=[50, 100, 150], \n",
    "#     gamma=0.5\n",
    "# )\n",
    "# scheduler_parallel = optim.lr_scheduler.MultiStepLR(\n",
    "#     optimizer_parallel, \n",
    "#     milestones=[50, 100, 150], \n",
    "#     gamma=0.5\n",
    "# )\n",
    "# Schedulers for both models\n",
    "scheduler_standard = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer_standard, T_0=20, T_mult=2, eta_min=1e-6\n",
    ")\n",
    "\n",
    "scheduler_parallel = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer_parallel, T_0=20, T_mult=2, eta_min=1e-6\n",
    ")\n",
    "\n",
    "# Scalers for mixed precision\n",
    "scaler_standard = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19406fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Loading datasets...\n",
      "üéØ Training on SNR levels: [-6  6 16] dB\n",
      "üìä Dataset composition: 6 modulations √ó 3 SNR levels\n",
      "üìà Split proportions - Train: 0.699, Valid: 0.299, Test: 0.002\n",
      "üîß Signals will be reshaped to (32, 32) for sequence length 1024\n",
      "‚úÖ Aspect ratio: 1.00, Total elements preserved: 1024 = 1024\n",
      "Dataset configured to use FFT as input\n",
      "üì¶ RadioMLIQDataset train: 51552 samples, 6 classes, 3 SNR levels\n",
      "üéØ SNR distribution in train set:\n",
      "   SNR  -6 dB: 17184 samples\n",
      "   SNR   6 dB: 17184 samples\n",
      "   SNR  16 dB: 17184 samples\n",
      "üéØ Training on SNR levels: [-6  6 16] dB\n",
      "üìä Dataset composition: 6 modulations √ó 3 SNR levels\n",
      "üìà Split proportions - Train: 0.699, Valid: 0.299, Test: 0.002\n",
      "üîß Signals will be reshaped to (32, 32) for sequence length 1024\n",
      "‚úÖ Aspect ratio: 1.00, Total elements preserved: 1024 = 1024\n",
      "Dataset configured to use FFT as input\n",
      "üì¶ RadioMLIQDataset valid: 22032 samples, 6 classes, 3 SNR levels\n",
      "üéØ SNR distribution in valid set:\n",
      "   SNR  -6 dB: 7344 samples\n",
      "   SNR   6 dB: 7344 samples\n",
      "   SNR  16 dB: 7344 samples\n",
      "Train dataset size: 51552\n",
      "Validation dataset size: 22032\n"
     ]
    }
   ],
   "source": [
    "# --- Data Loaders ---\n",
    "print(\"\\nüìÇ Loading datasets...\")\n",
    "train_dataset = RadioMLIQDataset('train', use_fft=True)\n",
    "valid_dataset = RadioMLIQDataset('valid', use_fft=True)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True, \n",
    "    pin_memory=True, num_workers=0, persistent_workers=False\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset, batch_size=BATCH_SIZE, shuffle=False, \n",
    "    pin_memory=True, num_workers=0, persistent_workers=False\n",
    ")\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(valid_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a905ffd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training Metrics Storage ---\n",
    "metrics = {\n",
    "    'standard': {\n",
    "        'train_losses': [], 'valid_losses': [], \n",
    "        'train_accuracies': [], 'valid_accuracies': [],\n",
    "        'training_times': [], 'best_accuracy': 0.0,\n",
    "        'final_predictions': [], 'final_true_labels': []\n",
    "    },\n",
    "    'parallel': {\n",
    "        'train_losses': [], 'valid_losses': [], \n",
    "        'train_accuracies': [], 'valid_accuracies': [],\n",
    "        'training_times': [], 'best_accuracy': 0.0,\n",
    "        'final_predictions': [], 'final_true_labels': []\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d8901b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping\n",
    "patience_counters = {'standard': 0, 'parallel': 0}\n",
    "best_models = {'standard': None, 'parallel': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b1b52bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, optimizer, criterion, scaler, device):\n",
    "    \"\"\"Train one epoch and return metrics\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i_inputs, q_inputs, labels, _ in train_loader:\n",
    "        i_inputs, q_inputs = i_inputs.to(device), q_inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with autocast():\n",
    "            outputs = model(i_inputs, q_inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        running_loss += loss.item() * i_inputs.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_time = time.time() - start_time\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_accuracy = 100. * correct / total\n",
    "    print(f\"Unique labels in this batch: {torch.unique(labels)}\") \n",
    "    return epoch_loss, epoch_accuracy, epoch_time\n",
    "\n",
    "def validate_epoch(model, valid_loader, criterion, device):\n",
    "    \"\"\"Validate one epoch and return metrics\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i_inputs, q_inputs, labels, _ in valid_loader:\n",
    "            i_inputs, q_inputs = i_inputs.to(device), q_inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(i_inputs, q_inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * i_inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    epoch_loss = running_loss / len(valid_loader.dataset)\n",
    "    epoch_accuracy = 100. * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_accuracy, predictions, true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "278f0a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Starting comparative training for FFt apply...\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m epoch_start = time.time()\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Train both models\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m train_loss_std, train_acc_std, train_time_std = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_standard\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_standard\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler_standard\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m train_loss_par, train_acc_par, train_time_par = train_epoch(\n\u001b[32m     14\u001b[39m     model_parallel, train_loader, optimizer_parallel, criterion, scaler_parallel, device\n\u001b[32m     15\u001b[39m )\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Validate both models\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, train_loader, optimizer, criterion, scaler, device)\u001b[39m\n\u001b[32m      6\u001b[39m total = \u001b[32m0\u001b[39m\n\u001b[32m      7\u001b[39m start_time = time.time()\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mi_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq_inputs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mi_inputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq_inputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\N208\\.conda\\envs\\amc_env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\N208\\.conda\\envs\\amc_env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:791\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    789\u001b[39m data = \u001b[38;5;28mself\u001b[39m._dataset_fetcher.fetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m--> \u001b[39m\u001b[32m791\u001b[39m     data = \u001b[43m_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pin_memory_device\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\N208\\.conda\\envs\\amc_env\\Lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py:100\u001b[39m, in \u001b[36mpin_memory\u001b[39m\u001b[34m(data, device)\u001b[39m\n\u001b[32m     98\u001b[39m     clone = copy.copy(data)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m     99\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data):\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m         clone[i] = \u001b[43mpin_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m clone\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(data)([pin_memory(sample, device) \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m data])  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\N208\\.conda\\envs\\amc_env\\Lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py:66\u001b[39m, in \u001b[36mpin_memory\u001b[39m\u001b[34m(data, device)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpin_memory\u001b[39m(data, device=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, torch.Tensor):\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m)):\n\u001b[32m     68\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# --- Training Loop ---\n",
    "print(\"\\nüéØ Starting comparative training for FFt apply...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for epoch in tqdm(range(NUM_EPOCHS), desc=\"Training Progress\"):\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    # Train both models\n",
    "    train_loss_std, train_acc_std, train_time_std = train_epoch(\n",
    "        model_standard, train_loader, optimizer_standard, criterion, scaler_standard, device\n",
    "    )\n",
    "    \n",
    "    train_loss_par, train_acc_par, train_time_par = train_epoch(\n",
    "        model_parallel, train_loader, optimizer_parallel, criterion, scaler_parallel, device\n",
    "    )\n",
    "    \n",
    "    # Validate both models\n",
    "    valid_loss_std, valid_acc_std, pred_std, true_std = validate_epoch(\n",
    "        model_standard, valid_loader, criterion, device\n",
    "    )\n",
    "    \n",
    "    valid_loss_par, valid_acc_par, pred_par, true_par = validate_epoch(\n",
    "        model_parallel, valid_loader, criterion, device\n",
    "    )\n",
    "    \n",
    "    # Update metrics\n",
    "    metrics['standard']['train_losses'].append(train_loss_std)\n",
    "    metrics['standard']['train_accuracies'].append(train_acc_std)\n",
    "    metrics['standard']['valid_losses'].append(valid_loss_std)\n",
    "    metrics['standard']['valid_accuracies'].append(valid_acc_std)\n",
    "    metrics['standard']['training_times'].append(train_time_std)\n",
    "    \n",
    "    metrics['parallel']['train_losses'].append(train_loss_par)\n",
    "    metrics['parallel']['train_accuracies'].append(train_acc_par)\n",
    "    metrics['parallel']['valid_losses'].append(valid_loss_par)\n",
    "    metrics['parallel']['valid_accuracies'].append(valid_acc_par)\n",
    "    metrics['parallel']['training_times'].append(train_time_par)\n",
    "    \n",
    "    # Update schedulers\n",
    "    scheduler_standard.step()\n",
    "    scheduler_parallel.step()\n",
    "    \n",
    "    # Check for best models and early stopping\n",
    "    if valid_acc_std > metrics['standard']['best_accuracy']:\n",
    "        metrics['standard']['best_accuracy'] = valid_acc_std\n",
    "        metrics['standard']['final_predictions'] = pred_std\n",
    "        metrics['standard']['final_true_labels'] = true_std\n",
    "        best_models['standard'] = model_standard.state_dict().copy()\n",
    "        patience_counters['standard'] = 0\n",
    "    else:\n",
    "        patience_counters['standard'] += 1\n",
    "    \n",
    "    if valid_acc_par > metrics['parallel']['best_accuracy']:\n",
    "        metrics['parallel']['best_accuracy'] = valid_acc_par\n",
    "        metrics['parallel']['final_predictions'] = pred_par\n",
    "        metrics['parallel']['final_true_labels'] = true_par\n",
    "        best_models['parallel'] = model_parallel.state_dict().copy()\n",
    "        patience_counters['parallel'] = 0\n",
    "    else:\n",
    "        patience_counters['parallel'] += 1\n",
    "    \n",
    "    # Print epoch results\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}:\")\n",
    "        print(f\"Standard  - Train: {train_acc_std:.2f}% | Valid: {valid_acc_std:.2f}% | Time: {train_time_std:.2f}s\")\n",
    "        print(f\"Parallel  - Train: {train_acc_par:.2f}% | Valid: {valid_acc_par:.2f}% | Time: {train_time_par:.2f}s\")\n",
    "        \n",
    "    # Early stopping check\n",
    "    if min(patience_counters.values()) >= patience:\n",
    "        print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "print(\"\\nüéâ Training Complete!\")\n",
    "print(f\"Standard Model Best Accuracy: {metrics['standard']['best_accuracy']:.2f}%\")\n",
    "print(f\"Parallel Model Best Accuracy: {metrics['parallel']['best_accuracy']:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b985502d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10), dpi=100)\n",
    "epochs = range(1, len(metrics['standard']['train_losses']) + 1)\n",
    "plt.plot(epochs, metrics['standard']['train_losses'], 'b-', label='Standard Train', linewidth=2,marker = 'o', color = 'blue')\n",
    "plt.plot(epochs, metrics['standard']['valid_losses'], 'b--', label='Standard Valid', linewidth=2, marker = 'o', color = 'red')\n",
    "plt.plot(epochs, metrics['parallel']['train_losses'], 'r-', label='Parallel Train', linewidth=2, marker = '^', color = 'green')\n",
    "plt.plot(epochs, metrics['parallel']['valid_losses'], 'r--', label='Parallel Valid', linewidth=2,marker = '^', color = 'gold')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training & Validation Loss Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8466ea87",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8), dpi=100)\n",
    "plt.plot(epochs, metrics['standard']['train_accuracies'], 'b-', label='Standard Train', linewidth=2,color = 'red',marker = 'o')\n",
    "plt.plot(epochs, metrics['standard']['valid_accuracies'], 'b--', label='Standard Valid', linewidth=2,color = 'blue', marker = 'o')\n",
    "plt.plot(epochs, metrics['parallel']['train_accuracies'], 'r-', label='Parallel Train', linewidth=2,color = 'green', marker = '^')\n",
    "plt.plot(epochs, metrics['parallel']['valid_accuracies'], 'r--', label='Parallel Valid', linewidth=2, color = 'gold', marker = '^')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Training & Validation Accuracy Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd232be",
   "metadata": {},
   "outputs": [],
   "source": [
    "    cm_std = confusion_matrix(metrics['standard']['final_true_labels'], \n",
    "                             metrics['standard']['final_predictions'])\n",
    "    sns.heatmap(cm_std, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.title(f'Serial Model Confusion Matrix\\nAccuracy: {metrics[\"standard\"][\"best_accuracy\"]:.2f}%')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0de336",
   "metadata": {},
   "outputs": [],
   "source": [
    "    cm_par = confusion_matrix(metrics['parallel']['final_true_labels'], \n",
    "                             metrics['parallel']['final_predictions'])\n",
    "    sns.heatmap(cm_par, annot=True, fmt='d', cmap='Reds', cbar=False)\n",
    "    plt.title(f'Parallel Model Confusion Matrix\\nAccuracy: {metrics[\"parallel\"][\"best_accuracy\"]:.2f}%')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf980bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Per-Modulation Accuracy Heatmap for 2 Models ---\n",
    "def plot_modulation_snr_accuracy_heatmap_comparison(model1, model2, model1_name, model2_name, dataloader, device, target_modulations):\n",
    "    \n",
    "    models = {model1_name: model1, model2_name: model2}\n",
    "    \n",
    "    # Create figure with 2 subplots\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(20, 8))\n",
    "    \n",
    "    for idx, (model_name, model) in enumerate(models.items()):\n",
    "        model.eval()\n",
    "        all_predictions = []\n",
    "        all_true_labels = []\n",
    "        all_snrs = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i_inputs, q_inputs, labels, snrs in dataloader:\n",
    "                i_inputs, q_inputs = i_inputs.to(device), q_inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                outputs = model(i_inputs, q_inputs)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                \n",
    "                all_predictions.extend(predicted.cpu().numpy())\n",
    "                all_true_labels.extend(labels.cpu().numpy())\n",
    "                all_snrs.extend(snrs.numpy())\n",
    "        \n",
    "        predictions_df = pd.DataFrame({\n",
    "            'true_label': all_true_labels,\n",
    "            'predicted_label': all_predictions,\n",
    "            'snr': all_snrs\n",
    "        })\n",
    "        \n",
    "        unique_snrs = sorted(predictions_df['snr'].unique())\n",
    "        accuracy_matrix = np.zeros((len(target_modulations), len(unique_snrs)))\n",
    "        \n",
    "        for i, mod in enumerate(target_modulations):\n",
    "            for j, snr in enumerate(unique_snrs):\n",
    "                subset = predictions_df[(predictions_df['true_label'] == i) & (predictions_df['snr'] == snr)]\n",
    "                if len(subset) > 0:\n",
    "                    accuracy = (subset['true_label'] == subset['predicted_label']).mean()\n",
    "                    accuracy_matrix[i, j] = accuracy * 100\n",
    "        \n",
    "        # Calculate overall accuracy for title\n",
    "        overall_accuracy = (np.array(all_true_labels) == np.array(all_predictions)).mean() * 100\n",
    "        \n",
    "        # Create heatmap for current model\n",
    "        sns.heatmap(accuracy_matrix, \n",
    "                    xticklabels=[f'{snr}dB' for snr in unique_snrs],\n",
    "                    yticklabels=target_modulations,\n",
    "                    annot=True, \n",
    "                    fmt='.1f', \n",
    "                    cmap='RdYlGn',\n",
    "                    vmin=0, \n",
    "                    vmax=100,\n",
    "                    cbar_kws={'label': 'Accuracy (%)'},\n",
    "                    ax=axes[idx])\n",
    "        \n",
    "        axes[idx].set_title(f'{model_name} CNN+LSTM\\nModulation Classification Accuracy by SNR Level\\nOverall Accuracy')\n",
    "        axes[idx].set_xlabel('SNR Level')\n",
    "        axes[idx].set_ylabel('Modulation Type')\n",
    "        axes[idx].tick_params(axis='x', rotation=45)\n",
    "        axes[idx].tick_params(axis='y', rotation=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('modulation_snr_accuracy_heatmap_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with your 2 models\n",
    "plot_modulation_snr_accuracy_heatmap_comparison(\n",
    "    model_standard, \n",
    "    model_parallel, \n",
    "    'Standard', \n",
    "    'Parallel', \n",
    "    valid_loader, \n",
    "    device, \n",
    "    TARGET_MODULATIONS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f087231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Per-Modulation Accuracy Line Plot for 2 Models ---\n",
    "def plot_modulation_snr_accuracy_lines_comparison(model1, model2, model1_name, model2_name, dataloader, device, target_modulations):\n",
    "    \n",
    "    models = {model1_name: model1, model2_name: model2}\n",
    "    \n",
    "    # Create figure with 2 subplots side by side\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "    \n",
    "    # Color palette for different modulations\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(target_modulations)))\n",
    "    \n",
    "    for idx, (model_name, model) in enumerate(models.items()):\n",
    "        model.eval()\n",
    "        all_predictions = []\n",
    "        all_true_labels = []\n",
    "        all_snrs = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i_inputs, q_inputs, labels, snrs in dataloader:\n",
    "                i_inputs, q_inputs = i_inputs.to(device), q_inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                outputs = model(i_inputs, q_inputs)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                \n",
    "                all_predictions.extend(predicted.cpu().numpy())\n",
    "                all_true_labels.extend(labels.cpu().numpy())\n",
    "                all_snrs.extend(snrs.numpy())\n",
    "        \n",
    "        predictions_df = pd.DataFrame({\n",
    "            'true_label': all_true_labels,\n",
    "            'predicted_label': all_predictions,\n",
    "            'snr': all_snrs\n",
    "        })\n",
    "        \n",
    "        unique_snrs = sorted(predictions_df['snr'].unique())\n",
    "        \n",
    "        # Plot line for each modulation type\n",
    "        for i, mod in enumerate(target_modulations):\n",
    "            accuracies = []\n",
    "            for snr in unique_snrs:\n",
    "                subset = predictions_df[(predictions_df['true_label'] == i) & (predictions_df['snr'] == snr)]\n",
    "                if len(subset) > 0:\n",
    "                    accuracy = (subset['true_label'] == subset['predicted_label']).mean()\n",
    "                    accuracies.append(accuracy * 100)\n",
    "                else:\n",
    "                    accuracies.append(0)\n",
    "            \n",
    "            # Plot line for this modulation\n",
    "            axes[idx].plot(unique_snrs, accuracies, \n",
    "                          marker='o', linewidth=2, markersize=6,\n",
    "                          color=colors[i], label=mod)\n",
    "        \n",
    "        # Calculate overall accuracy for title\n",
    "        overall_accuracy = (np.array(all_true_labels) == np.array(all_predictions)).mean() * 100\n",
    "        \n",
    "        # Customize subplot\n",
    "        axes[idx].set_title(f'{model_name} CNN+LSTM\\nModulation Classification Accuracy by SNR Level', \n",
    "                           fontsize=12, fontweight='bold')\n",
    "        axes[idx].set_xlabel('SNR Level (dB)', fontsize=11)\n",
    "        axes[idx].set_ylabel('Accuracy (%)', fontsize=11)\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "        axes[idx].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        axes[idx].set_ylim(0, 100)\n",
    "        \n",
    "        # Set x-axis ticks\n",
    "        axes[idx].set_xticks(unique_snrs)\n",
    "        axes[idx].set_xticklabels([f'{snr}' for snr in unique_snrs])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('modulation_snr_accuracy_lines_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Alternative version: Overlay both models in single plot\n",
    "def plot_modulation_snr_accuracy_lines_overlay(model1, model2, model1_name, model2_name, dataloader, device, target_modulations):\n",
    "    \n",
    "    models = {model1_name: model1, model2_name: model2}\n",
    "    model_data = {}\n",
    "    \n",
    "    # Create single figure\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
    "    \n",
    "    # Color palette for different modulations\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(target_modulations)))\n",
    "    \n",
    "    # Process data for both models\n",
    "    for model_name, model in models.items():\n",
    "        model.eval()\n",
    "        all_predictions = []\n",
    "        all_true_labels = []\n",
    "        all_snrs = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i_inputs, q_inputs, labels, snrs in dataloader:\n",
    "                i_inputs, q_inputs = i_inputs.to(device), q_inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                outputs = model(i_inputs, q_inputs)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                \n",
    "                all_predictions.extend(predicted.cpu().numpy())\n",
    "                all_true_labels.extend(labels.cpu().numpy())\n",
    "                all_snrs.extend(snrs.numpy())\n",
    "        \n",
    "        predictions_df = pd.DataFrame({\n",
    "            'true_label': all_true_labels,\n",
    "            'predicted_label': all_predictions,\n",
    "            'snr': all_snrs\n",
    "        })\n",
    "        \n",
    "        model_data[model_name] = {\n",
    "            'predictions_df': predictions_df,\n",
    "            'overall_accuracy': (np.array(all_true_labels) == np.array(all_predictions)).mean() * 100\n",
    "        }\n",
    "    \n",
    "    unique_snrs = sorted(model_data[model1_name]['predictions_df']['snr'].unique())\n",
    "    \n",
    "    # Plot lines for each modulation and model\n",
    "    for i, mod in enumerate(target_modulations):\n",
    "        for j, (model_name, data) in enumerate(model_data.items()):\n",
    "            predictions_df = data['predictions_df']\n",
    "            accuracies = []\n",
    "            \n",
    "            for snr in unique_snrs:\n",
    "                subset = predictions_df[(predictions_df['true_label'] == i) & (predictions_df['snr'] == snr)]\n",
    "                if len(subset) > 0:\n",
    "                    accuracy = (subset['true_label'] == subset['predicted_label']).mean()\n",
    "                    accuracies.append(accuracy * 100)\n",
    "                else:\n",
    "                    accuracies.append(0)\n",
    "            \n",
    "            # Different line styles for different models\n",
    "            linestyle = '-' if j == 0 else '--'\n",
    "            marker = 'o' if j == 0 else 's'\n",
    "            \n",
    "            # Plot line for this modulation and model\n",
    "            ax.plot(unique_snrs, accuracies, \n",
    "                   marker=marker, linewidth=2, markersize=6,\n",
    "                   color=colors[i], linestyle=linestyle,\n",
    "                   label=f'{mod} ({model_name})')\n",
    "    \n",
    "    # Customize plot\n",
    "    ax.set_title('Modulation Classification Accuracy by SNR Level\\nComparison Between Models', \n",
    "                fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('SNR Level (dB)', fontsize=12)\n",
    "    ax.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    ax.set_ylim(0, 100)\n",
    "    \n",
    "    # Set x-axis ticks\n",
    "    ax.set_xticks(unique_snrs)\n",
    "    ax.set_xticklabels([f'{snr}' for snr in unique_snrs])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('modulation_snr_accuracy_lines_overlay.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "plot_modulation_snr_accuracy_lines_comparison(\n",
    "    model_standard, \n",
    "    model_parallel, \n",
    "    'Standard', \n",
    "    'Parallel', \n",
    "    valid_loader, \n",
    "    device, \n",
    "    TARGET_MODULATIONS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6bcd4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
