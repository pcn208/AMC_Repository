{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d13d1c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torchinfo import summary\n",
    "from typing import Tuple, Optional\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tqdm import tqdm, trange\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import time \n",
    "import time\n",
    "import warnings\n",
    "from collections import deque\n",
    "import psutil\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba269b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2107bea0",
   "metadata": {},
   "source": [
    "### **CONFIGURATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54ffca92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Training Parameters:\n",
      "  Batch size: 512\n",
      "  Epochs: 100\n"
     ]
    }
   ],
   "source": [
    "FILE_PATH = \"C:\\\\workarea\\\\CNN model\\\\dataset\\\\radioml2018\\\\versions\\\\2\\\\GOLD_XYZ_OSC.0001_1024.hdf5\"\n",
    "JSON_PATH = 'C:\\\\workarea\\\\CNN model\\\\dataset\\\\radioml2018\\\\versions\\\\2\\\\classes-fixed.json' \n",
    "\n",
    "TARGET_MODULATIONS = ['OOK','4ASK','8ASK','BPSK', \n",
    "                      'QPSK', '8PSK', '16QAM',\n",
    "                     '64QAM','OQPSK'\n",
    "                     ]\n",
    "#TARGET_MODULATIONS = ['OOK','4ASK','BPSK', 'QPSK', '8PSK','16QAM','GMSK']\n",
    "BATCH_SIZE = 512 # adjust to my laptop \n",
    "#LEARNING_RATE = 0.003 \n",
    "NUM_EPOCHS = 100\n",
    "NUM_WORKERS = 0 #Temporary check it  \n",
    "\n",
    "INPUT_CHANNELS = 2 \n",
    "SEQUENCE_LENGTH = 1024 \n",
    "NUM_CLASSES = len(TARGET_MODULATIONS) # adjust this to \n",
    "\n",
    "patience = 15\n",
    "# TRAIN_RATIO = 0.7 \n",
    "# VALID_RATIO = 0.2 \n",
    "# TEST_RATIO = 0.1 \n",
    "\n",
    "nf_train = int(BATCH_SIZE * 0.7)\n",
    "nf_valid = int(BATCH_SIZE * 0.15)\n",
    "nf_test  = BATCH_SIZE - nf_train - nf_valid\n",
    "\n",
    "print(\"üìã Training Parameters:\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "#print(f\"  Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"  Epochs: {NUM_EPOCHS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3b08915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_split(data,\n",
    "                  modulations_classes,\n",
    "                  modulations,\n",
    "                  snrs,\n",
    "                  target_modulations,\n",
    "                  mode,\n",
    "                  target_snrs,\n",
    "                  train_proportion=0.7, # training 70 %\n",
    "                  valid_proportion=0.15, # validation 20 %\n",
    "                  test_proportion=0.15, # testing 10 % \n",
    "                  seed=48):\n",
    "    np.random.seed(seed)\n",
    "    X_output = []\n",
    "    Y_output = []\n",
    "    Z_output = []                                   \n",
    "\n",
    "    target_modulation_indices = [modulations_classes.index(modu) for modu in target_modulations]\n",
    "\n",
    "    for modu in target_modulation_indices:\n",
    "        for snr in target_snrs:\n",
    "            snr_modu_indices = np.where((modulations == modu) & (snrs == snr))[0]\n",
    "\n",
    "            np.random.shuffle(snr_modu_indices)\n",
    "            num_samples = len(snr_modu_indices)\n",
    "            train_end = int(train_proportion * num_samples)\n",
    "            valid_end = int((train_proportion + valid_proportion) * num_samples)\n",
    "\n",
    "            if mode == 'train':\n",
    "                indices = snr_modu_indices[:train_end]\n",
    "            elif mode == 'valid':\n",
    "                indices = snr_modu_indices[train_end:valid_end]\n",
    "            elif mode == 'test':\n",
    "                indices = snr_modu_indices[valid_end:]\n",
    "            else:\n",
    "                raise ValueError(f'unknown mode: {mode}. Valid modes are train, valid and test')\n",
    "\n",
    "            X_output.append(data[np.sort(indices)])\n",
    "            Y_output.append(modulations[np.sort(indices)])\n",
    "            Z_output.append(snrs[np.sort(indices)])\n",
    "\n",
    "    X_array = np.vstack(X_output)\n",
    "    Y_array = np.concatenate(Y_output)\n",
    "    Z_array = np.concatenate(Z_output)\n",
    "    for index, value in enumerate(np.unique(np.copy(Y_array))):\n",
    "        Y_array[Y_array == value] = index\n",
    "    return X_array, Y_array, Z_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c909c667",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RadioMLIQDataset(Dataset):\n",
    "    \"\"\"Dataset class for RadioML18 data formatted for CNNIQModel dual-branch architecture.\n",
    "    \n",
    "    Loads RadioML18 HDF5 data and returns separate I and Q tensors in 2D format\n",
    "    suitable for CNNIQModel's separate branch processing.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, mode: str, use_fft: bool = False, seed: int = 48, target_snrs: list = [-6, 6, 16]):\n",
    "        \"\"\"Initialize RadioMLIQDataset.\n",
    "        \n",
    "        Args:\n",
    "            mode: Dataset split mode ('train', 'valid', or 'test').\n",
    "            use_fft: Whether to apply FFT transformation to signals.\n",
    "            seed: Random seed for dataset splitting.\n",
    "            target_snrs: List of SNR levels to include in training (default: [-6, 6, 16])\n",
    "            \n",
    "        Raises:\n",
    "            FileNotFoundError: If HDF5 or JSON files cannot be found.\n",
    "            ValueError: If mode is not valid or data dimensions are incompatible.\n",
    "        \"\"\"\n",
    "        super(RadioMLIQDataset, self).__init__()\n",
    "        \n",
    "        # Configuration (you'll need to define these constants)\n",
    "        self.file_path = FILE_PATH \n",
    "        self.json_path = JSON_PATH \n",
    "        self.target_modulations = TARGET_MODULATIONS\n",
    "        self.use_fft = use_fft\n",
    "        self.mode = mode\n",
    "        \n",
    "        # Validate mode\n",
    "        if mode not in ['train', 'valid', 'test']:\n",
    "            raise ValueError(f\"Mode must be 'train', 'valid', or 'test', got '{mode}'\")\n",
    "        \n",
    "        # Load data files\n",
    "        try:\n",
    "            self.hdf5_file = h5py.File(self.file_path, 'r')\n",
    "            self.modulation_classes = json.load(open(self.json_path, 'r'))\n",
    "        except FileNotFoundError as e:\n",
    "            raise FileNotFoundError(f\"Error loading data files: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading file: {e}\")\n",
    "            raise e\n",
    "        \n",
    "        # Load raw data\n",
    "        self.X = self.hdf5_file['X']\n",
    "        self.Y = np.argmax(self.hdf5_file['Y'], axis=1)\n",
    "        self.Z = self.hdf5_file['Z'][:, 0]\n",
    "        \n",
    "        # Set target SNR levels - MODIFIED FOR SPECIFIC SNR LEVELS\n",
    "        self.target_snrs = np.array(target_snrs)  # [-6, 6, 16] dB\n",
    "        print(f\"üéØ Training on SNR levels: {self.target_snrs} dB\")\n",
    "        \n",
    "        # Check if target SNRs exist in dataset\n",
    "        available_snrs = np.unique(self.Z)\n",
    "        missing_snrs = [snr for snr in self.target_snrs if snr not in available_snrs]\n",
    "        if missing_snrs:\n",
    "            print(f\"‚ö†Ô∏è Warning: SNR levels {missing_snrs} not found in dataset\")\n",
    "            print(f\"Available SNR levels: {available_snrs}\")\n",
    "            # Filter to only include available SNRs\n",
    "            self.target_snrs = np.array([snr for snr in self.target_snrs if snr in available_snrs])\n",
    "            print(f\"üîß Adjusted target SNRs to: {self.target_snrs}\")\n",
    "        \n",
    "        # Calculate proportions based on ACTUAL number of SNRs and modulations\n",
    "        num_mods = len(self.target_modulations)   \n",
    "        num_snrs = len(self.target_snrs)  # CHANGED: Use actual target SNRs count\n",
    "        \n",
    "        print(f\"üìä Dataset composition: {num_mods} modulations √ó {num_snrs} SNR levels\")\n",
    "        \n",
    "        # Calculate expected samples per split\n",
    "        expected_samples_per_mod_snr = nf_train + nf_valid + nf_test  # This should equal BATCH_SIZE\n",
    "        total_expected_samples = num_mods * num_snrs * expected_samples_per_mod_snr\n",
    "        \n",
    "        train_proportion = (num_mods * num_snrs * nf_train) / total_expected_samples\n",
    "        valid_proportion = (num_mods * num_snrs * nf_valid) / total_expected_samples  \n",
    "        test_proportion  = (num_mods * num_snrs * nf_test ) / total_expected_samples\n",
    "        \n",
    "        print(f\"üìà Split proportions - Train: {train_proportion:.3f}, Valid: {valid_proportion:.3f}, Test: {test_proportion:.3f}\")\n",
    "        \n",
    "        # Split dataset\n",
    "        self.X_data, self.Y_data, self.Z_data = dataset_split(\n",
    "            data=self.X,\n",
    "            modulations_classes=self.modulation_classes,\n",
    "            modulations=self.Y,\n",
    "            snrs=self.Z,\n",
    "            mode=mode,\n",
    "            train_proportion=train_proportion,\n",
    "            valid_proportion=valid_proportion,\n",
    "            test_proportion=test_proportion,\n",
    "            target_modulations=self.target_modulations,\n",
    "            target_snrs=self.target_snrs,  # Use filtered SNR levels\n",
    "            seed=seed\n",
    "        )\n",
    "        \n",
    "        # Apply I/Q swap correction for AMC compatibility\n",
    "        self.X_data = self.X_data[:, :, [0, 1]]\n",
    "        \n",
    "        # Validate signal length for 2D reshaping\n",
    "        signal_length = self.X_data.shape[1]\n",
    "        if signal_length != 1024:\n",
    "            raise ValueError(f\"Expected signal length 1024 for 32x32 reshape, got {signal_length}\")\n",
    "\n",
    "        import math\n",
    "        \n",
    "        L = signal_length\n",
    "        H = int(math.floor(math.sqrt(L)))\n",
    "        while L % H != 0:\n",
    "            H -= 1\n",
    "        W = L // H\n",
    "        \n",
    "        self.H, self.W = H, W\n",
    "        print(f\"üîß Signals will be reshaped to ({H}, {W}) for sequence length {L}\")\n",
    "        print(f\"‚úÖ Aspect ratio: {W/H:.2f}, Total elements preserved: {H*W} = {L}\")\n",
    "        \n",
    "        if self.use_fft:\n",
    "            print(\"Dataset configured to use FFT as input\")\n",
    "        \n",
    "        # Store dataset statistics\n",
    "        self.num_data = self.X_data.shape[0]\n",
    "        self.num_lbl = len(self.target_modulations)\n",
    "        self.num_snr = len(self.target_snrs)  # CHANGED: Use actual target SNRs count\n",
    "        \n",
    "        print(f\"üì¶ RadioMLIQDataset {mode}: {self.num_data} samples, \"\n",
    "              f\"{self.num_lbl} classes, {self.num_snr} SNR levels\")\n",
    "        print(f\"üéØ SNR distribution in {mode} set:\")\n",
    "        unique_snrs_in_data, counts = np.unique(self.Z_data, return_counts=True)\n",
    "        for snr, count in zip(unique_snrs_in_data, counts):\n",
    "            print(f\"   SNR {snr:3.0f} dB: {count:4d} samples\")\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Return the number of samples in the dataset.\n",
    "        \n",
    "        Returns:\n",
    "            Number of samples.\n",
    "        \"\"\"\n",
    "        return self.X_data.shape[0]\n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        if idx < 0 or idx >= self.num_data:\n",
    "            raise IndexError(f\"Index {idx} out of range for dataset of size {self.num_data}\")\n",
    "\n",
    "        x_raw = self.X_data[idx]       # shape: (L, 2)\n",
    "        y     = int(self.Y_data[idx])\n",
    "        z     = float(self.Z_data[idx])\n",
    "\n",
    "        # Convert to tensor\n",
    "        x = torch.from_numpy(x_raw).float().transpose(0, 1)  # shape: (2, L)\n",
    "\n",
    "        if self.use_fft:\n",
    "            # Combine to complex signal\n",
    "            complex_sig = torch.complex(x[0], x[1])  # shape: (L,)\n",
    "            fft_res     = torch.fft.fft(complex_sig)  # shape: (L,)\n",
    "\n",
    "            # Convert to real-valued 2D (L √ó 2) matrix: real | imag\n",
    "            x_fft = torch.stack([torch.real(fft_res), torch.imag(fft_res)], dim=1)  # shape: (L, 2)\n",
    "\n",
    "            # Reshape to 2D: (1, H, W) each for real and imag\n",
    "            x_real_2d = x_fft[:, 0].view(1, self.H, self.W)\n",
    "            x_imag_2d = x_fft[:, 1].view(1, self.H, self.W)\n",
    "\n",
    "            return x_real_2d, x_imag_2d, y, z\n",
    "\n",
    "        else:\n",
    "            # Non-FFT path (amplitude/phase domain)\n",
    "            i_signal = x[0]  # shape: (L,)\n",
    "            q_signal = x[1]\n",
    "\n",
    "            amplitude = torch.sqrt(i_signal**2 + q_signal**2)\n",
    "            phase     = torch.atan2(q_signal, i_signal)\n",
    "\n",
    "            i_2d = amplitude.view(1, self.H, self.W)\n",
    "            q_2d = phase.view(1, self.H, self.W)\n",
    "\n",
    "            return i_2d, q_2d, y, z\n",
    "\n",
    "    def get_signal_stats(self):\n",
    "        \"\"\"Compute basic stats over a sample of signals.\"\"\"\n",
    "        sample_indices = np.random.choice(self.num_data, min(1000, self.num_data), replace=False)\n",
    "        i_vals, q_vals = [], []\n",
    "        for idx in sample_indices:\n",
    "            i2d, q2d, _, _ = self[idx]\n",
    "            i_vals.append(i2d.flatten())\n",
    "            q_vals.append(q2d.flatten())\n",
    "        i_all = torch.cat(i_vals)\n",
    "        q_all = torch.cat(q_vals)\n",
    "        return {\n",
    "            'i_mean': i_all.mean().item(),\n",
    "            'i_std':  i_all.std().item(),\n",
    "            'q_mean': q_all.mean().item(),\n",
    "            'q_std':  q_all.std().item(),\n",
    "            'shape':  (1, self.H, self.W),\n",
    "            'num_samples': self.num_data\n",
    "        }\n",
    "\n",
    "    def close(self):\n",
    "        if hasattr(self, 'hdf5_file'):\n",
    "            self.hdf5_file.close()\n",
    "\n",
    "    def __del__(self):\n",
    "        self.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8e1d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully built Standard CNN-LSTM Model\n",
      "‚úÖ Successfully built Parallel CNN-LSTM Model\n"
     ]
    }
   ],
   "source": [
    "# Model 1: Standard CNN-LSTM\n",
    "try:\n",
    "    from models.CNN_LSTM_IQ import create_enhanced_CNNLSTMIQModel\n",
    "    model_standard = create_enhanced_CNNLSTMIQModel(n_labels=NUM_CLASSES, dropout_rate=0.3).to(device)\n",
    "    print(\"‚úÖ Successfully built Standard CNN-LSTM Model\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Could not build Standard Model: {e}\")\n",
    "\n",
    "# Model 2: Parallel CNN-LSTM\n",
    "try:\n",
    "    from models.CNN_LSTM_IQ_Parallel import create_fixed_parallel_model\n",
    "    model_parallel = create_fixed_parallel_model(num_classes=2, dropout_rate=0.5, use_alternative=True).to(device)\n",
    "    print(\"‚úÖ Successfully built Parallel CNN-LSTM Model\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Could not build Parallel Model: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cf4c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary model Serial :\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "CNNLSTMIQModel                           --\n",
      "‚îú‚îÄCNNLSTMBranch: 1-1                     --\n",
      "‚îÇ    ‚îî‚îÄConv2d: 2-1                       640\n",
      "‚îÇ    ‚îî‚îÄBatchNorm2d: 2-2                  128\n",
      "‚îÇ    ‚îî‚îÄConv2d: 2-3                       36,928\n",
      "‚îÇ    ‚îî‚îÄBatchNorm2d: 2-4                  128\n",
      "‚îÇ    ‚îî‚îÄConv2d: 2-5                       73,856\n",
      "‚îÇ    ‚îî‚îÄBatchNorm2d: 2-6                  256\n",
      "‚îÇ    ‚îî‚îÄConv2d: 2-7                       147,584\n",
      "‚îÇ    ‚îî‚îÄBatchNorm2d: 2-8                  256\n",
      "‚îÇ    ‚îî‚îÄMaxPool2d: 2-9                    --\n",
      "‚îÇ    ‚îî‚îÄLeakyReLU: 2-10                   --\n",
      "‚îÇ    ‚îî‚îÄDropout2d: 2-11                   --\n",
      "‚îÇ    ‚îî‚îÄLSTM: 2-12                        92,000\n",
      "‚îÇ    ‚îî‚îÄLSTM: 2-13                        30,400\n",
      "‚îÇ    ‚îî‚îÄDropout: 2-14                     --\n",
      "‚îÇ    ‚îî‚îÄLinear: 2-15                      51\n",
      "‚îÇ    ‚îî‚îÄAdaptiveAvgPool2d: 2-16           --\n",
      "‚îú‚îÄCNNLSTMBranch: 1-2                     --\n",
      "‚îÇ    ‚îî‚îÄConv2d: 2-17                      640\n",
      "‚îÇ    ‚îî‚îÄBatchNorm2d: 2-18                 128\n",
      "‚îÇ    ‚îî‚îÄConv2d: 2-19                      36,928\n",
      "‚îÇ    ‚îî‚îÄBatchNorm2d: 2-20                 128\n",
      "‚îÇ    ‚îî‚îÄConv2d: 2-21                      73,856\n",
      "‚îÇ    ‚îî‚îÄBatchNorm2d: 2-22                 256\n",
      "‚îÇ    ‚îî‚îÄConv2d: 2-23                      147,584\n",
      "‚îÇ    ‚îî‚îÄBatchNorm2d: 2-24                 256\n",
      "‚îÇ    ‚îî‚îÄMaxPool2d: 2-25                   --\n",
      "‚îÇ    ‚îî‚îÄLeakyReLU: 2-26                   --\n",
      "‚îÇ    ‚îî‚îÄDropout2d: 2-27                   --\n",
      "‚îÇ    ‚îî‚îÄLSTM: 2-28                        92,000\n",
      "‚îÇ    ‚îî‚îÄLSTM: 2-29                        30,400\n",
      "‚îÇ    ‚îî‚îÄDropout: 2-30                     --\n",
      "‚îÇ    ‚îî‚îÄLinear: 2-31                      51\n",
      "‚îÇ    ‚îî‚îÄAdaptiveAvgPool2d: 2-32           --\n",
      "‚îú‚îÄSequential: 1-3                        --\n",
      "‚îÇ    ‚îî‚îÄLinear: 2-33                      13,056\n",
      "‚îÇ    ‚îî‚îÄBatchNorm1d: 2-34                 512\n",
      "‚îÇ    ‚îî‚îÄLeakyReLU: 2-35                   --\n",
      "‚îÇ    ‚îî‚îÄDropout: 2-36                     --\n",
      "‚îÇ    ‚îî‚îÄLinear: 2-37                      32,896\n",
      "‚îÇ    ‚îî‚îÄBatchNorm1d: 2-38                 256\n",
      "‚îÇ    ‚îî‚îÄLeakyReLU: 2-39                   --\n",
      "‚îÇ    ‚îî‚îÄDropout: 2-40                     --\n",
      "‚îÇ    ‚îî‚îÄLinear: 2-41                      8,256\n",
      "‚îÇ    ‚îî‚îÄLeakyReLU: 2-42                   --\n",
      "‚îÇ    ‚îî‚îÄDropout: 2-43                     --\n",
      "‚îÇ    ‚îî‚îÄLinear: 2-44                      585\n",
      "=================================================================\n",
      "Total params: 820,015\n",
      "Trainable params: 820,015\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "Summary model Parallel :\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "AlternativeParallelModel                 --\n",
      "‚îú‚îÄImprovedParallelBranch: 1-1            --\n",
      "‚îÇ    ‚îî‚îÄCNN_1: 2-1                        --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-1                  320\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-2             64\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-3                  18,496\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-4             128\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄMaxPool2d: 3-5               --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄLeakyReLU: 3-6               --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄDropout2d: 3-7               --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄAdaptiveAvgPool2d: 3-8       --\n",
      "‚îÇ    ‚îî‚îÄCNN_2: 2-2                        --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-9                  320\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-10            64\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-11                 18,496\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-12            128\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄMaxPool2d: 3-13              --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-14                 73,856\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-15            256\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-16                 147,584\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-17            256\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄMaxPool2d: 3-18              --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄLeakyReLU: 3-19              --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄDropout2d: 3-20              --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄAdaptiveAvgPool2d: 3-21      --\n",
      "‚îÇ    ‚îî‚îÄSequential: 2-3                   --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 3-22                 196,864\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm1d: 3-23            512\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄLeakyReLU: 3-24              --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 3-25                --\n",
      "‚îÇ    ‚îî‚îÄLinear: 2-4                       16,448\n",
      "‚îÇ    ‚îî‚îÄLSTM: 2-5                         66,560\n",
      "‚îÇ    ‚îî‚îÄDropout: 2-6                      --\n",
      "‚îÇ    ‚îî‚îÄLinear: 2-7                       129\n",
      "‚îú‚îÄImprovedParallelBranch: 1-2            --\n",
      "‚îÇ    ‚îî‚îÄCNN_1: 2-8                        --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-26                 320\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-27            64\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-28                 18,496\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-29            128\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄMaxPool2d: 3-30              --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄLeakyReLU: 3-31              --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄDropout2d: 3-32              --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄAdaptiveAvgPool2d: 3-33      --\n",
      "‚îÇ    ‚îî‚îÄCNN_2: 2-9                        --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-34                 320\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-35            64\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-36                 18,496\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-37            128\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄMaxPool2d: 3-38              --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-39                 73,856\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-40            256\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-41                 147,584\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-42            256\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄMaxPool2d: 3-43              --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄLeakyReLU: 3-44              --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄDropout2d: 3-45              --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄAdaptiveAvgPool2d: 3-46      --\n",
      "‚îÇ    ‚îî‚îÄSequential: 2-10                  --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 3-47                 196,864\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm1d: 3-48            512\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄLeakyReLU: 3-49              --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 3-50                --\n",
      "‚îÇ    ‚îî‚îÄLinear: 2-11                      16,448\n",
      "‚îÇ    ‚îî‚îÄLSTM: 2-12                        66,560\n",
      "‚îÇ    ‚îî‚îÄDropout: 2-13                     --\n",
      "‚îÇ    ‚îî‚îÄLinear: 2-14                      129\n",
      "‚îú‚îÄSequential: 1-3                        --\n",
      "‚îÇ    ‚îî‚îÄLinear: 2-15                      16,448\n",
      "‚îÇ    ‚îî‚îÄTanh: 2-16                        --\n",
      "‚îÇ    ‚îî‚îÄLinear: 2-17                      130\n",
      "‚îÇ    ‚îî‚îÄSoftmax: 2-18                     --\n",
      "‚îú‚îÄSequential: 1-4                        --\n",
      "‚îÇ    ‚îî‚îÄLinear: 2-19                      8,256\n",
      "‚îÇ    ‚îî‚îÄBatchNorm1d: 2-20                 128\n",
      "‚îÇ    ‚îî‚îÄReLU: 2-21                        --\n",
      "‚îÇ    ‚îî‚îÄDropout: 2-22                     --\n",
      "‚îÇ    ‚îî‚îÄLinear: 2-23                      130\n",
      "=================================================================\n",
      "Total params: 1,106,054\n",
      "Trainable params: 1,106,054\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "from torchinfo import summary \n",
    "print(f\"Summary model Serial :\\n{summary(model_standard)}\") \n",
    "print(f\"Summary model Parallel :\\n{summary(model_parallel)}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d09856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count parameters for both models\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "standard_params = count_parameters(model_standard)\n",
    "parallel_params = count_parameters(model_parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c826203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers for both models\n",
    "optimizer_standard = optim.AdamW(\n",
    "    model_standard.parameters(), \n",
    "    lr=0.0015,\n",
    "    weight_decay=5e-3,\n",
    "    betas=(0.9, 0.999)\n",
    ")\n",
    "\n",
    "optimizer_parallel = optim.AdamW(\n",
    "    model_parallel.parameters(), \n",
    "    lr=0.0015,\n",
    "    weight_decay=5e-3,\n",
    "    betas=(0.9, 0.999)\n",
    ")\n",
    "\n",
    "# scheduler_standard = optim.lr_scheduler.MultiStepLR(\n",
    "#     optimizer_standard, \n",
    "#     milestones=[50, 100, 150], \n",
    "#     gamma=0.5\n",
    "# )\n",
    "# scheduler_parallel = optim.lr_scheduler.MultiStepLR(\n",
    "#     optimizer_parallel, \n",
    "#     milestones=[50, 100, 150], \n",
    "#     gamma=0.5\n",
    "# )\n",
    "# Schedulers for both models\n",
    "scheduler_standard = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer_standard, T_0=20, T_mult=2, eta_min=1e-6\n",
    ")\n",
    "\n",
    "scheduler_parallel = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer_parallel, T_0=20, T_mult=2, eta_min=1e-6\n",
    ")\n",
    "\n",
    "# Scalers for mixed precision\n",
    "scaler_standard = GradScaler()\n",
    "scaler_parallel = GradScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fa2f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shared training components\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.2).to(device)\n",
    "\n",
    "# Optimizers for both models\n",
    "optimizer_standard = optim.AdamW(\n",
    "    model_standard.parameters(), \n",
    "    lr=0.0015,\n",
    "    weight_decay=5e-3,\n",
    "    betas=(0.9, 0.999)\n",
    ")\n",
    "\n",
    "optimizer_parallel = optim.AdamW(\n",
    "    model_parallel.parameters(), \n",
    "    lr=0.0015,\n",
    "    weight_decay=5e-3,\n",
    "    betas=(0.9, 0.999)\n",
    ")\n",
    "\n",
    "# scheduler_standard = optim.lr_scheduler.MultiStepLR(\n",
    "#     optimizer_standard, \n",
    "#     milestones=[50, 100, 150], \n",
    "#     gamma=0.5\n",
    "# )\n",
    "# scheduler_parallel = optim.lr_scheduler.MultiStepLR(\n",
    "#     optimizer_parallel, \n",
    "#     milestones=[50, 100, 150], \n",
    "#     gamma=0.5\n",
    "# )\n",
    "# Schedulers for both models\n",
    "scheduler_standard = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer_standard, T_0=20, T_mult=2, eta_min=1e-6\n",
    ")\n",
    "\n",
    "scheduler_parallel = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer_parallel, T_0=20, T_mult=2, eta_min=1e-6\n",
    ")\n",
    "\n",
    "# Scalers for mixed precision\n",
    "scaler_standard = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19406fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Loading datasets...\n",
      "üéØ Training on SNR levels: [-6  6 16] dB\n",
      "üìä Dataset composition: 9 modulations √ó 3 SNR levels\n",
      "üìà Split proportions - Train: 0.699, Valid: 0.148, Test: 0.152\n",
      "üîß Signals will be reshaped to (32, 32) for sequence length 1024\n",
      "‚úÖ Aspect ratio: 1.00, Total elements preserved: 1024 = 1024\n",
      "Dataset configured to use FFT as input\n",
      "üì¶ RadioMLIQDataset train: 77328 samples, 9 classes, 3 SNR levels\n",
      "üéØ SNR distribution in train set:\n",
      "   SNR  -6 dB: 25776 samples\n",
      "   SNR   6 dB: 25776 samples\n",
      "   SNR  16 dB: 25776 samples\n",
      "üéØ Training on SNR levels: [-6  6 16] dB\n",
      "üìä Dataset composition: 9 modulations √ó 3 SNR levels\n",
      "üìà Split proportions - Train: 0.699, Valid: 0.148, Test: 0.152\n",
      "üîß Signals will be reshaped to (32, 32) for sequence length 1024\n",
      "‚úÖ Aspect ratio: 1.00, Total elements preserved: 1024 = 1024\n",
      "Dataset configured to use FFT as input\n",
      "üì¶ RadioMLIQDataset valid: 16416 samples, 9 classes, 3 SNR levels\n",
      "üéØ SNR distribution in valid set:\n",
      "   SNR  -6 dB: 5472 samples\n",
      "   SNR   6 dB: 5472 samples\n",
      "   SNR  16 dB: 5472 samples\n",
      "üéØ Training on SNR levels: [-6  6 16] dB\n",
      "üìä Dataset composition: 9 modulations √ó 3 SNR levels\n",
      "üìà Split proportions - Train: 0.699, Valid: 0.148, Test: 0.152\n",
      "üîß Signals will be reshaped to (32, 32) for sequence length 1024\n",
      "‚úÖ Aspect ratio: 1.00, Total elements preserved: 1024 = 1024\n",
      "Dataset configured to use FFT as input\n",
      "üì¶ RadioMLIQDataset test: 16848 samples, 9 classes, 3 SNR levels\n",
      "üéØ SNR distribution in test set:\n",
      "   SNR  -6 dB: 5616 samples\n",
      "   SNR   6 dB: 5616 samples\n",
      "   SNR  16 dB: 5616 samples\n",
      "Train dataset size: 77328\n",
      "Validation dataset size: 16416\n",
      "Test dataset size: 16848\n"
     ]
    }
   ],
   "source": [
    "# --- Data Loaders ---\n",
    "print(\"\\nüìÇ Loading datasets...\")\n",
    "train_dataset = RadioMLIQDataset('train', use_fft=True)\n",
    "valid_dataset = RadioMLIQDataset('valid', use_fft=True)\n",
    "test_dataset = RadioMLIQDataset('test', use_fft=True)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True, \n",
    "    pin_memory=True, num_workers=0, persistent_workers=False\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset, batch_size=BATCH_SIZE, shuffle=False, \n",
    "    pin_memory=True, num_workers=0, persistent_workers=False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, shuffle=False, \n",
    "    pin_memory=True, num_workers=0, persistent_workers=False\n",
    ")\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(valid_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a905ffd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training Metrics Storage ---\n",
    "metrics = {\n",
    "    'standard': {\n",
    "        'train_losses': [], 'valid_losses': [], \n",
    "        'train_accuracies': [], 'valid_accuracies': [],\n",
    "        'training_times': [], 'best_accuracy': 0.0,\n",
    "        'final_predictions': [], 'final_true_labels': []\n",
    "    },\n",
    "    'parallel': {\n",
    "        'train_losses': [], 'valid_losses': [], \n",
    "        'train_accuracies': [], 'valid_accuracies': [],\n",
    "        'training_times': [], 'best_accuracy': 0.0,\n",
    "        'final_predictions': [], 'final_true_labels': []\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8901b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping\n",
    "patience_counters = {'standard': 0, 'parallel': 0}\n",
    "best_models = {'standard': None, 'parallel': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1b52bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, optimizer, criterion, scaler, device):\n",
    "    \"\"\"Train one epoch and return metrics\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i_inputs, q_inputs, labels, _ in train_loader:\n",
    "        i_inputs, q_inputs = i_inputs.to(device), q_inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with autocast():\n",
    "            outputs = model(i_inputs, q_inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        running_loss += loss.item() * i_inputs.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_time = time.time() - start_time\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_accuracy = 100. * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_accuracy, epoch_time\n",
    "\n",
    "def validate_epoch(model, valid_loader, criterion, device):\n",
    "    \"\"\"Validate one epoch and return metrics\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i_inputs, q_inputs, labels, _ in valid_loader:\n",
    "            i_inputs, q_inputs = i_inputs.to(device), q_inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(i_inputs, q_inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * i_inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    epoch_loss = running_loss / len(valid_loader.dataset)\n",
    "    epoch_accuracy = 100. * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_accuracy, predictions, true_labels\n",
    "\n",
    "def test_epoch(model, test_loader, criterion, device):\n",
    "    \"\"\"Test one epoch and return metrics\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i_inputs, q_inputs, labels, _ in test_loader:\n",
    "            i_inputs, q_inputs = i_inputs.to(device), q_inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(i_inputs, q_inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * i_inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy()) \n",
    "    \n",
    "    epoch_loss = running_loss / len(test_loader.dataset)\n",
    "    epoch_accuracy = 100. * correct / total\n",
    "\n",
    "    return epoch_loss, epoch_accuracy, predictions, true_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "278f0a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Starting comparative training...\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 0/100 [00:14<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Train both models\u001b[39;00m\n\u001b[32m     11\u001b[39m train_loss_std, train_acc_std, train_time_std = train_epoch(\n\u001b[32m     12\u001b[39m     model_standard, train_loader, optimizer_standard, criterion, scaler_standard, device\n\u001b[32m     13\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m train_loss_par, train_acc_par, train_time_par = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_parallel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_parallel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler_parallel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Validate both models\u001b[39;00m\n\u001b[32m     20\u001b[39m valid_loss_std, valid_acc_std, pred_std, true_std = validate_epoch(\n\u001b[32m     21\u001b[39m     model_standard, valid_loader, criterion, device\n\u001b[32m     22\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, train_loader, optimizer, criterion, scaler, device)\u001b[39m\n\u001b[32m     16\u001b[39m     outputs = model(i_inputs, q_inputs)\n\u001b[32m     17\u001b[39m     loss = criterion(outputs, labels)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m scaler.unscale_(optimizer)\n\u001b[32m     21\u001b[39m torch.nn.utils.clip_grad_norm_(model.parameters(), \u001b[32m1.0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\N208\\.conda\\envs\\amc_env\\Lib\\site-packages\\torch\\_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\N208\\.conda\\envs\\amc_env\\Lib\\site-packages\\torch\\autograd\\__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\N208\\.conda\\envs\\amc_env\\Lib\\site-packages\\torch\\autograd\\graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# --- Training Loop ---\n",
    "import copy\n",
    "\n",
    "print(\"\\nüéØ Starting comparative training...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for epoch in tqdm(range(NUM_EPOCHS), desc=\"Training Progress\"):\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    # Train both models\n",
    "    train_loss_std, train_acc_std, train_time_std = train_epoch(\n",
    "        model_standard, train_loader, optimizer_standard, criterion, scaler_standard, device\n",
    "    )\n",
    "    \n",
    "    train_loss_par, train_acc_par, train_time_par = train_epoch(\n",
    "        model_parallel, train_loader, optimizer_parallel, criterion, scaler_parallel, device\n",
    "    )\n",
    "    \n",
    "    # Validate both models\n",
    "    valid_loss_std, valid_acc_std, pred_std, true_std = validate_epoch(\n",
    "        model_standard, valid_loader, criterion, device\n",
    "    )\n",
    "    \n",
    "    valid_loss_par, valid_acc_par, pred_par, true_par = validate_epoch(\n",
    "        model_parallel, valid_loader, criterion, device\n",
    "    )\n",
    "    \n",
    "    # Update metrics\n",
    "    metrics['standard']['train_losses'].append(train_loss_std)\n",
    "    metrics['standard']['train_accuracies'].append(train_acc_std)\n",
    "    metrics['standard']['valid_losses'].append(valid_loss_std)\n",
    "    metrics['standard']['valid_accuracies'].append(valid_acc_std)\n",
    "    metrics['standard']['training_times'].append(train_time_std)\n",
    "    \n",
    "    metrics['parallel']['train_losses'].append(train_loss_par)\n",
    "    metrics['parallel']['train_accuracies'].append(train_acc_par)\n",
    "    metrics['parallel']['valid_losses'].append(valid_loss_par)\n",
    "    metrics['parallel']['valid_accuracies'].append(valid_acc_par)\n",
    "    metrics['parallel']['training_times'].append(train_time_par)\n",
    "    \n",
    "    # Update schedulers\n",
    "    scheduler_standard.step()\n",
    "    scheduler_parallel.step()\n",
    "    \n",
    "    # Check for best models and early stopping\n",
    "    if valid_acc_std > metrics['standard']['best_accuracy']:\n",
    "        metrics['standard']['best_accuracy'] = valid_acc_std\n",
    "        metrics['standard']['final_predictions'] = pred_std.cpu().numpy() if hasattr(pred_std, 'cpu') else pred_std\n",
    "        metrics['standard']['final_true_labels'] = true_std.cpu().numpy() if hasattr(true_std, 'cpu') else true_std\n",
    "        best_models['standard'] = copy.deepcopy(model_standard.state_dict())\n",
    "        patience_counters['standard'] = 0\n",
    "    else:\n",
    "        patience_counters['standard'] += 1\n",
    "    \n",
    "    if valid_acc_par > metrics['parallel']['best_accuracy']:\n",
    "        metrics['parallel']['best_accuracy'] = valid_acc_par\n",
    "        metrics['parallel']['final_predictions'] = pred_par.cpu().numpy() if hasattr(pred_par, 'cpu') else pred_par\n",
    "        metrics['parallel']['final_true_labels'] = true_par.cpu().numpy() if hasattr(true_par, 'cpu') else true_par\n",
    "        best_models['parallel'] = copy.deepcopy(model_parallel.state_dict())\n",
    "        patience_counters['parallel'] = 0\n",
    "    else:\n",
    "        patience_counters['parallel'] += 1\n",
    "    \n",
    "    # Print epoch results\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}:\")\n",
    "        print(f\"Standard  - Train: {train_acc_std:.2f}% | Valid: {valid_acc_std:.2f}% | Time: {train_time_std:.2f}s\")\n",
    "        print(f\"Parallel  - Train: {train_acc_par:.2f}% | Valid: {valid_acc_par:.2f}% | Time: {train_time_par:.2f}s\")\n",
    "    \n",
    "    # Early stopping check - stop when BOTH models haven't improved\n",
    "    if patience_counters['standard'] >= patience and patience_counters['parallel'] >= patience:\n",
    "        print(f\"\\nEarly stopping at epoch {epoch+1} - Both models stopped improving\")\n",
    "        break\n",
    "\n",
    "print(\"\\nüéâ Training Complete!\")\n",
    "print(f\"Standard Model Best Accuracy: {metrics['standard']['best_accuracy']:.2f}%\")\n",
    "print(f\"Parallel Model Best Accuracy: {metrics['parallel']['best_accuracy']:.2f}%\")\n",
    "\n",
    "# --- Final Testing on Test Set (if test_loader exists) ---\n",
    "if 'test_loader' in locals() or 'test_loader' in globals():\n",
    "    print(\"\\nüîç Final testing on test set...\")\n",
    "    \n",
    "    # Load best models\n",
    "    model_standard.load_state_dict(best_models['standard'])\n",
    "    model_parallel.load_state_dict(best_models['parallel'])\n",
    "    \n",
    "    # Test both models\n",
    "    test_loss_std, test_acc_std, pred_test_std, true_test_std = validate_epoch(\n",
    "        model_standard, test_loader, criterion, device\n",
    "    )\n",
    "    \n",
    "    test_loss_par, test_acc_par, pred_test_par, true_test_par = validate_epoch(\n",
    "        model_parallel, test_loader, criterion, device\n",
    "    )\n",
    "    \n",
    "    # Store test results\n",
    "    metrics['standard']['test_accuracy'] = test_acc_std\n",
    "    metrics['standard']['test_loss'] = test_loss_std\n",
    "    metrics['standard']['test_predictions'] = pred_test_std.cpu().numpy() if hasattr(pred_test_std, 'cpu') else pred_test_std\n",
    "    metrics['standard']['test_true_labels'] = true_test_std.cpu().numpy() if hasattr(true_test_std, 'cpu') else true_test_std\n",
    "    \n",
    "    metrics['parallel']['test_accuracy'] = test_acc_par\n",
    "    metrics['parallel']['test_loss'] = test_loss_par\n",
    "    metrics['parallel']['test_predictions'] = pred_test_par.cpu().numpy() if hasattr(pred_test_par, 'cpu') else pred_test_par\n",
    "    metrics['parallel']['test_true_labels'] = true_test_par.cpu().numpy() if hasattr(true_test_par, 'cpu') else true_test_par\n",
    "    \n",
    "    print(f\"Standard Model Test Accuracy: {test_acc_std:.2f}%\")\n",
    "    print(f\"Parallel Model Test Accuracy: {test_acc_par:.2f}%\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No test_loader found - skipping final testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b985502d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10), dpi=100)\n",
    "epochs = range(1, len(metrics['standard']['train_losses']) + 1)\n",
    "plt.plot(epochs, metrics['standard']['train_losses'], 'b-', label='Standard Train', linewidth=2,marker = 'o', color = 'blue')\n",
    "plt.plot(epochs, metrics['standard']['valid_losses'], 'b--', label='Standard Valid', linewidth=2, marker = 'o', color = 'red')\n",
    "plt.plot(epochs, metrics['parallel']['train_losses'], 'r-', label='Parallel Train', linewidth=2, marker = '^', color = 'green')\n",
    "plt.plot(epochs, metrics['parallel']['valid_losses'], 'r--', label='Parallel Valid', linewidth=2,marker = '^', color = 'gold')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training & Validation Loss Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8466ea87",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8), dpi=100)\n",
    "plt.plot(epochs, metrics['standard']['train_accuracies'], 'b-', label='Standard Train', linewidth=2,color = 'red',marker = 'o')\n",
    "plt.plot(epochs, metrics['standard']['valid_accuracies'], 'b--', label='Standard Valid', linewidth=2,color = 'blue', marker = 'o')\n",
    "plt.plot(epochs, metrics['parallel']['train_accuracies'], 'r-', label='Parallel Train', linewidth=2,color = 'green', marker = '^')\n",
    "plt.plot(epochs, metrics['parallel']['valid_accuracies'], 'r--', label='Parallel Valid', linewidth=2, color = 'gold', marker = '^')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Training & Validation Accuracy Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd232be",
   "metadata": {},
   "outputs": [],
   "source": [
    "    cm_std = confusion_matrix(metrics['standard']['final_true_labels'], \n",
    "                             metrics['standard']['final_predictions'])\n",
    "    sns.heatmap(cm_std, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.title(f'Serial Model Confusion Matrix\\nAccuracy: {metrics[\"standard\"][\"best_accuracy\"]:.2f}%')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0de336",
   "metadata": {},
   "outputs": [],
   "source": [
    "    cm_par = confusion_matrix(metrics['parallel']['final_true_labels'], \n",
    "                             metrics['parallel']['final_predictions'])\n",
    "    sns.heatmap(cm_par, annot=True, fmt='d', cmap='Reds', cbar=False)\n",
    "    plt.title(f'Parallel Model Confusion Matrix\\nAccuracy: {metrics[\"parallel\"][\"best_accuracy\"]:.2f}%')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf980bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Per-Modulation Accuracy Heatmap for 2 Models ---\n",
    "def plot_modulation_snr_accuracy_heatmap_comparison(model1, model2, model1_name, model2_name, dataloader, device, target_modulations):\n",
    "    \"\"\"\n",
    "    Plot accuracy heatmaps comparing two models across modulations and SNR levels\n",
    "    \n",
    "    Args:\n",
    "        model1, model2: PyTorch models to compare\n",
    "        model1_name, model2_name: Names for the models\n",
    "        dataloader: DataLoader containing test data\n",
    "        device: Device to run inference on\n",
    "        target_modulations: List of modulation names\n",
    "    \"\"\"\n",
    "    \n",
    "    models = {model1_name: model1, model2_name: model2}\n",
    "    \n",
    "    # Create figure with 2 subplots\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(20, 12))\n",
    "    \n",
    "    for idx, (model_name, model) in enumerate(models.items()):\n",
    "        model.eval()\n",
    "        all_predictions = []\n",
    "        all_true_labels = []\n",
    "        all_snrs = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader:\n",
    "                # Handle different dataloader formats\n",
    "                if len(batch) == 4:  # (i_inputs, q_inputs, labels, snrs)\n",
    "                    i_inputs, q_inputs, labels, snrs = batch\n",
    "                    i_inputs, q_inputs = i_inputs.to(device), q_inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    \n",
    "                    # Combine I/Q inputs if model expects single input\n",
    "                    if hasattr(model, 'forward'):\n",
    "                        # Try to determine model input format\n",
    "                        try:\n",
    "                            outputs = model(i_inputs, q_inputs)  # Two separate inputs\n",
    "                        except:\n",
    "                            # Concatenate I and Q channels\n",
    "                            combined_inputs = torch.cat([i_inputs.unsqueeze(1), q_inputs.unsqueeze(1)], dim=1)\n",
    "                            outputs = model(combined_inputs)  # Single combined input\n",
    "                    else:\n",
    "                        combined_inputs = torch.cat([i_inputs.unsqueeze(1), q_inputs.unsqueeze(1)], dim=1)\n",
    "                        outputs = model(combined_inputs)\n",
    "                        \n",
    "                elif len(batch) == 3:  # (data, labels, snrs)\n",
    "                    data, labels, snrs = batch\n",
    "                    data = data.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    outputs = model(data)\n",
    "                    \n",
    "                elif len(batch) == 2:  # (data, labels) - need to extract SNR from dataset\n",
    "                    data, labels = batch\n",
    "                    data = data.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    outputs = model(data)\n",
    "                    # SNRs need to be extracted differently - this is a limitation\n",
    "                    snrs = torch.zeros(len(labels))  # Placeholder - you'll need to modify this\n",
    "                    print(\"‚ö†Ô∏è Warning: SNR information not available in dataloader\")\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                \n",
    "                all_predictions.extend(predicted.cpu().numpy())\n",
    "                all_true_labels.extend(labels.cpu().numpy())\n",
    "                all_snrs.extend(snrs.numpy() if hasattr(snrs, 'numpy') else snrs)\n",
    "        \n",
    "        # Create DataFrame for analysis\n",
    "        predictions_df = pd.DataFrame({\n",
    "            'true_label': all_true_labels,\n",
    "            'predicted_label': all_predictions,\n",
    "            'snr': all_snrs\n",
    "        })\n",
    "        \n",
    "        # Get unique SNR values and sort them\n",
    "        unique_snrs = sorted(predictions_df['snr'].unique())\n",
    "        accuracy_matrix = np.zeros((len(target_modulations), len(unique_snrs)))\n",
    "        \n",
    "        # Calculate accuracy for each modulation at each SNR\n",
    "        for i, mod in enumerate(target_modulations):\n",
    "            for j, snr in enumerate(unique_snrs):\n",
    "                subset = predictions_df[(predictions_df['true_label'] == i) & (predictions_df['snr'] == snr)]\n",
    "                if len(subset) > 0:\n",
    "                    accuracy = (subset['true_label'] == subset['predicted_label']).mean()\n",
    "                    accuracy_matrix[i, j] = accuracy * 100\n",
    "                else:\n",
    "                    accuracy_matrix[i, j] = 0  # No samples for this combination\n",
    "        \n",
    "        # Calculate overall accuracy for title\n",
    "        overall_accuracy = (np.array(all_true_labels) == np.array(all_predictions)).mean() * 100\n",
    "        \n",
    "        # Create heatmap for current model\n",
    "        sns.heatmap(accuracy_matrix, \n",
    "                    xticklabels=[f'{int(snr)}dB' for snr in unique_snrs],\n",
    "                    yticklabels=target_modulations,\n",
    "                    annot=True, \n",
    "                    fmt='.1f', \n",
    "                    cmap='RdYlGn',\n",
    "                    vmin=0, \n",
    "                    vmax=100,\n",
    "                    cbar_kws={'label': 'Accuracy (%)'},\n",
    "                    ax=axes[idx])\n",
    "        \n",
    "        axes[idx].set_title(f'{model_name} Model - Modulation Classification Accuracy by SNR Level\\n'\n",
    "                           f'Overall Test Accuracy: {overall_accuracy:.2f}%', \n",
    "                           fontsize=14, fontweight='bold')\n",
    "        axes[idx].set_xlabel('SNR Level', fontsize=12)\n",
    "        axes[idx].set_ylabel('Modulation Type', fontsize=12)\n",
    "        axes[idx].tick_params(axis='x', rotation=45)\n",
    "        axes[idx].tick_params(axis='y', rotation=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('modulation_snr_accuracy_heatmap_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "plot_modulation_snr_accuracy_heatmap_comparison(\n",
    "    model_standard, \n",
    "    model_parallel, \n",
    "    'Standard', \n",
    "    'Parallel', \n",
    "    test_loader, \n",
    "    device, \n",
    "    TARGET_MODULATIONS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f087231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Per-Modulation Accuracy Line Plot for 2 Models ---\n",
    "def plot_modulation_snr_accuracy_lines_comparison(model1, model2, model1_name, model2_name, dataloader, device, target_modulations):\n",
    "    \n",
    "    models = {model1_name: model1, model2_name: model2}\n",
    "    \n",
    "    # Create figure with 2 subplots side by side\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "    \n",
    "    # Color palette for different modulations\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(target_modulations)))\n",
    "    \n",
    "    for idx, (model_name, model) in enumerate(models.items()):\n",
    "        model.eval()\n",
    "        all_predictions = []\n",
    "        all_true_labels = []\n",
    "        all_snrs = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i_inputs, q_inputs, labels, snrs in dataloader:\n",
    "                i_inputs, q_inputs = i_inputs.to(device), q_inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                outputs = model(i_inputs, q_inputs)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                \n",
    "                all_predictions.extend(predicted.cpu().numpy())\n",
    "                all_true_labels.extend(labels.cpu().numpy())\n",
    "                all_snrs.extend(snrs.numpy())\n",
    "        \n",
    "        predictions_df = pd.DataFrame({\n",
    "            'true_label': all_true_labels,\n",
    "            'predicted_label': all_predictions,\n",
    "            'snr': all_snrs\n",
    "        })\n",
    "        \n",
    "        unique_snrs = sorted(predictions_df['snr'].unique())\n",
    "        \n",
    "        # Plot line for each modulation type\n",
    "        for i, mod in enumerate(target_modulations):\n",
    "            accuracies = []\n",
    "            for snr in unique_snrs:\n",
    "                subset = predictions_df[(predictions_df['true_label'] == i) & (predictions_df['snr'] == snr)]\n",
    "                if len(subset) > 0:\n",
    "                    accuracy = (subset['true_label'] == subset['predicted_label']).mean()\n",
    "                    accuracies.append(accuracy * 100)\n",
    "                else:\n",
    "                    accuracies.append(0)\n",
    "            \n",
    "            # Plot line for this modulation\n",
    "            axes[idx].plot(unique_snrs, accuracies, \n",
    "                          marker='o', linewidth=2, markersize=6,\n",
    "                          color=colors[i], label=mod)\n",
    "        \n",
    "        # Calculate overall accuracy for title\n",
    "        overall_accuracy = (np.array(all_true_labels) == np.array(all_predictions)).mean() * 100\n",
    "        \n",
    "        # Customize subplot\n",
    "        axes[idx].set_title(f'{model_name} CNN+LSTM\\nModulation Classification Accuracy by SNR Level', \n",
    "                           fontsize=12, fontweight='bold')\n",
    "        axes[idx].set_xlabel('SNR Level (dB)', fontsize=11)\n",
    "        axes[idx].set_ylabel('Accuracy (%)', fontsize=11)\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "        axes[idx].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        axes[idx].set_ylim(0, 100)\n",
    "        \n",
    "        # Set x-axis ticks\n",
    "        axes[idx].set_xticks(unique_snrs)\n",
    "        axes[idx].set_xticklabels([f'{snr}' for snr in unique_snrs])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('modulation_snr_accuracy_lines_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Alternative version: Overlay both models in single plot\n",
    "def plot_modulation_snr_accuracy_lines_overlay(model1, model2, model1_name, model2_name, dataloader, device, target_modulations):\n",
    "    \n",
    "    models = {model1_name: model1, model2_name: model2}\n",
    "    model_data = {}\n",
    "    \n",
    "    # Create single figure\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
    "    \n",
    "    # Color palette for different modulations\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(target_modulations)))\n",
    "    \n",
    "    # Process data for both models\n",
    "    for model_name, model in models.items():\n",
    "        model.eval()\n",
    "        all_predictions = []\n",
    "        all_true_labels = []\n",
    "        all_snrs = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i_inputs, q_inputs, labels, snrs in dataloader:\n",
    "                i_inputs, q_inputs = i_inputs.to(device), q_inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                outputs = model(i_inputs, q_inputs)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                \n",
    "                all_predictions.extend(predicted.cpu().numpy())\n",
    "                all_true_labels.extend(labels.cpu().numpy())\n",
    "                all_snrs.extend(snrs.numpy())\n",
    "        \n",
    "        predictions_df = pd.DataFrame({\n",
    "            'true_label': all_true_labels,\n",
    "            'predicted_label': all_predictions,\n",
    "            'snr': all_snrs\n",
    "        })\n",
    "        \n",
    "        model_data[model_name] = {\n",
    "            'predictions_df': predictions_df,\n",
    "            'overall_accuracy': (np.array(all_true_labels) == np.array(all_predictions)).mean() * 100\n",
    "        }\n",
    "    \n",
    "    unique_snrs = sorted(model_data[model1_name]['predictions_df']['snr'].unique())\n",
    "    \n",
    "    # Plot lines for each modulation and model\n",
    "    for i, mod in enumerate(target_modulations):\n",
    "        for j, (model_name, data) in enumerate(model_data.items()):\n",
    "            predictions_df = data['predictions_df']\n",
    "            accuracies = []\n",
    "            \n",
    "            for snr in unique_snrs:\n",
    "                subset = predictions_df[(predictions_df['true_label'] == i) & (predictions_df['snr'] == snr)]\n",
    "                if len(subset) > 0:\n",
    "                    accuracy = (subset['true_label'] == subset['predicted_label']).mean()\n",
    "                    accuracies.append(accuracy * 100)\n",
    "                else:\n",
    "                    accuracies.append(0)\n",
    "            \n",
    "            # Different line styles for different models\n",
    "            linestyle = '-' if j == 0 else '--'\n",
    "            marker = 'o' if j == 0 else 's'\n",
    "            \n",
    "            # Plot line for this modulation and model\n",
    "            ax.plot(unique_snrs, accuracies, \n",
    "                   marker=marker, linewidth=2, markersize=6,\n",
    "                   color=colors[i], linestyle=linestyle,\n",
    "                   label=f'{mod} ({model_name})')\n",
    "    \n",
    "    # Customize plot\n",
    "    ax.set_title('Modulation Classification Accuracy by SNR Level\\nComparison Between Models', \n",
    "                fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('SNR Level (dB)', fontsize=12)\n",
    "    ax.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    ax.set_ylim(0, 100)\n",
    "    \n",
    "    # Set x-axis ticks\n",
    "    ax.set_xticks(unique_snrs)\n",
    "    ax.set_xticklabels([f'{snr}' for snr in unique_snrs])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('modulation_snr_accuracy_lines_overlay.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "plot_modulation_snr_accuracy_lines_comparison(\n",
    "    model_standard, \n",
    "    model_parallel, \n",
    "    'Standard', \n",
    "    'Parallel', \n",
    "    valid_loader, \n",
    "    device, \n",
    "    TARGET_MODULATIONS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6bcd4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
