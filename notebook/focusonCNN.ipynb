{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "603ccd01-b9df-4bc8-8d8a-f2fd1ebf6e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torchinfo import summary\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tqdm import tqdm, trange\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import time\n",
    "import warnings\n",
    "from collections import deque\n",
    "import psutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "853a7445-7cb3-48f4-9e85-eaec040baf3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c436018-d79d-4ec2-90cd-5614fac7f30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‹ Training Parameters:\n",
      "  Batch size: 32\n",
      "  Learning rate: 0.003\n",
      "  Epochs: 100\n"
     ]
    }
   ],
   "source": [
    "FILE_PATH = '/mnt/sda3/dataset_AMC /radioml2018/versions/2/GOLD_XYZ_OSC.0001_1024.hdf5'\n",
    "JSON_PATH = '/mnt/sda3/dataset_AMC /radioml2018/versions/2/classes-fixed.json'\n",
    "\n",
    "TARGET_MODULATIONS = [\n",
    "    'OOK', '4ASK', '8ASK', 'BPSK', 'QPSK', '8PSK', '16PSK', '32PSK'\n",
    "]\n",
    "\n",
    "BATCH_SIZE = 32 # adjust to my laptop \n",
    "#LEARNING_RATE = 0.003 \n",
    "NUM_EPOCHS = 100 \n",
    "NUM_WORKERS = 0 #Temporary check it  \n",
    "\n",
    "INPUT_CHANNELS = 2 \n",
    "SEQUENCE_LENGTH = 1024 \n",
    "NUM_CLASSES = 8  # adjust this to \n",
    "\n",
    "TRAIN_RATIO = 0.7 \n",
    "VALID_RATIO = 0.2 \n",
    "TEST_RATIO = 0.1 \n",
    "\n",
    "nf_train = int(BATCH_SIZE * 0.7)\n",
    "nf_valid = int(BATCH_SIZE * 0.2)\n",
    "nf_test  = BATCH_SIZE - nf_train - nf_valid\n",
    "\n",
    "print(\"ðŸ“‹ Training Parameters:\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"  Epochs: {NUM_EPOCHS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f370570-711a-498e-aa9a-cc7033975b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_split(data,\n",
    "                  modulations_classes,\n",
    "                  modulations,\n",
    "                  snrs,\n",
    "                  target_modulations,\n",
    "                  mode,\n",
    "                  target_snrs,\n",
    "                  train_proportion=0.7, # training 70 %\n",
    "                  valid_proportion=0.2, # validation 20 %\n",
    "                  test_proportion=0.1, # testing 10 % \n",
    "                  seed=48):\n",
    "    np.random.seed(seed)\n",
    "    X_output = []\n",
    "    Y_output = []\n",
    "    Z_output = []                                   \n",
    "\n",
    "    target_modulation_indices = [modulations_classes.index(modu) for modu in target_modulations]\n",
    "\n",
    "    for modu in target_modulation_indices:\n",
    "        for snr in target_snrs:\n",
    "            snr_modu_indices = np.where((modulations == modu) & (snrs == snr))[0]\n",
    "\n",
    "            np.random.shuffle(snr_modu_indices)\n",
    "            num_samples = len(snr_modu_indices)\n",
    "            train_end = int(train_proportion * num_samples)\n",
    "            valid_end = int((train_proportion + valid_proportion) * num_samples)\n",
    "\n",
    "            if mode == 'train':\n",
    "                indices = snr_modu_indices[:train_end]\n",
    "            elif mode == 'valid':\n",
    "                indices = snr_modu_indices[train_end:valid_end]\n",
    "            elif mode == 'test':\n",
    "                indices = snr_modu_indices[valid_end:]\n",
    "            else:\n",
    "                raise ValueError(f'unknown mode: {mode}. Valid modes are train, valid and test')\n",
    "\n",
    "            X_output.append(data[np.sort(indices)])\n",
    "            Y_output.append(modulations[np.sort(indices)])\n",
    "            Z_output.append(snrs[np.sort(indices)])\n",
    "\n",
    "    X_array = np.vstack(X_output)\n",
    "    Y_array = np.concatenate(Y_output)\n",
    "    Z_array = np.concatenate(Z_output)\n",
    "    for index, value in enumerate(np.unique(np.copy(Y_array))):\n",
    "        Y_array[Y_array == value] = index\n",
    "    return X_array, Y_array, Z_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c55dcab-669d-4f15-8c87-96c472f0d9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RadioML18Dataset(Dataset):\n",
    "    def __init__(self, mode: str, seed=48,):\n",
    "        super(RadioML18Dataset, self).__init__()\n",
    "\n",
    "        self.file_path = FILE_PATH \n",
    "        self.json_path = JSON_PATH \n",
    "        self.target_modulations = TARGET_MODULATIONS\n",
    "        \n",
    "        try:\n",
    "            hdf5_file = h5py.File(self.file_path, 'r') #Escaped backslashes \n",
    "            self.modulation_classes = json.load(open(self.json_path, 'r'))\n",
    "        except Exception as e: \n",
    "            print(f\"Error loading file : {e}\")\n",
    "            raise e \n",
    "        \n",
    "        self.X = hdf5_file['X']\n",
    "        self.Y = np.argmax(hdf5_file['Y'], axis=1)\n",
    "        self.Z = hdf5_file['Z'][:, 0]\n",
    "\n",
    "        train_proportion=(10*26*nf_train)/self.X.shape[0]\n",
    "        valid_proportion=(10*26*nf_valid)/self.X.shape[0]\n",
    "        test_proportion=(10*26*nf_test)/self.X.shape[0]\n",
    "\n",
    "        self.target_snrs = np.unique(self.Z)\n",
    "\n",
    "        self.X_data, self.Y_data, self.Z_data = dataset_split(\n",
    "                                                                  data = self.X,\n",
    "                                                                  modulations_classes = self.modulation_classes,\n",
    "                                                                  modulations = self.Y,\n",
    "                                                                  snrs = self.Z,\n",
    "                                                                  mode = mode,\n",
    "                                                                  train_proportion = train_proportion,\n",
    "                                                                  valid_proportion = valid_proportion,\n",
    "                                                                  test_proportion = test_proportion,\n",
    "                                                                  target_modulations = self.target_modulations,\n",
    "                                                                  target_snrs  = self.target_snrs,\n",
    "                                                                  seed=48\n",
    "                                                                 )\n",
    "\n",
    "        # *** CRITICAL FIX: Apply I/Q swap correction for AMC compatibility ***\n",
    "        print(f\"ðŸ”§ Applying I/Q swap fix to {mode} dataset...\")\n",
    "        X_corrected = np.zeros_like(self.X_data)\n",
    "        X_corrected[:, :, 0] = self.X_data[:, :, 0]  # not swapped I \n",
    "        X_corrected[:, :, 1] = self.X_data[:, :, 1]  # not swapped Q \n",
    "        self.X_data = X_corrected\n",
    "        print(f\"âœ… I/Q channels corrected for real-world compatibility\")\n",
    "\n",
    "        # store statistic of whole dataset (unchanged)\n",
    "        self.num_data = self.X_data.shape[0]\n",
    "        self.num_lbl = len(self.target_modulations)\n",
    "        self.num_snr = self.target_snrs.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X_data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x,y,z = self.X_data[idx], self.Y_data[idx], self.Z_data[idx]\n",
    "        x,y,z = torch.Tensor(x).transpose(0, 1) , y , z\n",
    "        return x,y,z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bafe7b-3282-4e51-8b0e-5e976ac2b952",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = RadioML18Dataset(mode='test')\n",
    "data_len = ds.num_data\n",
    "n_labels=ds.num_lbl\n",
    "n_snrs = ds.num_snr\n",
    "frame_size=ds.X.shape[1]\n",
    "\n",
    "print(data_len)\n",
    "print(n_labels)\n",
    "print(n_snrs)\n",
    "print(frame_size)\n",
    "del ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e139093f-39d8-47f6-b5ca-31d761b7d120",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignalAugmentation:\n",
    "    \"\"\"\n",
    "    Comprehensive augmentation suite for I/Q signal processing\n",
    "    Specifically designed for modulation classification\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config=None):\n",
    "        # Default augmentation configuration\n",
    "        self.config = config or {\n",
    "            'noise_std_range': (0.01, 0.05),           # AWGN noise\n",
    "            'snr_range': (-10, 30),                     # SNR variation\n",
    "            'phase_shift_range': (-np.pi, np.pi),      # Phase rotation\n",
    "            'amplitude_scale_range': (0.7, 1.3),       # Amplitude scaling\n",
    "            'frequency_shift_range': (-0.1, 0.1),      # Frequency offset\n",
    "            'time_shift_range': (-50, 50),             # Time shifting\n",
    "            'iq_imbalance_range': (0.9, 1.1),          # I/Q imbalance\n",
    "            'dc_offset_range': (-0.1, 0.1),            # DC offset\n",
    "            'multipath_delay_range': (1, 10),          # Multipath fading\n",
    "            'dropout_prob_range': (0.0, 0.02),         # Sample dropout\n",
    "        }\n",
    "    \n",
    "    def add_awgn_noise(self, signal, probability=0.8):\n",
    "        \"\"\"Add Additive White Gaussian Noise\"\"\"\n",
    "        if torch.rand(1).item() < probability:\n",
    "            std_min, std_max = self.config['noise_std_range']\n",
    "            noise_std = torch.uniform(std_min, std_max, (1,)).item()\n",
    "            \n",
    "            # Add complex noise to both I and Q channels\n",
    "            noise = torch.randn_like(signal) * noise_std\n",
    "            return signal + noise\n",
    "        return signal\n",
    "    \n",
    "    def snr_variation(self, signal, probability=0.6):\n",
    "        \"\"\"Simulate different SNR conditions\"\"\"\n",
    "        if torch.rand(1).item() < probability:\n",
    "            snr_min, snr_max = self.config['snr_range']\n",
    "            target_snr_db = torch.uniform(snr_min, snr_max, (1,)).item()\n",
    "            \n",
    "            # Calculate current signal power\n",
    "            signal_power = torch.mean(signal ** 2)\n",
    "            \n",
    "            # Calculate required noise power for target SNR\n",
    "            snr_linear = 10 ** (target_snr_db / 10)\n",
    "            noise_power = signal_power / snr_linear\n",
    "            \n",
    "            # Add noise\n",
    "            noise = torch.randn_like(signal) * torch.sqrt(noise_power)\n",
    "            return signal + noise\n",
    "        return signal\n",
    "    \n",
    "    def phase_rotation(self, signal, probability=0.7):\n",
    "        \"\"\"Apply random phase rotation (common in RF systems)\"\"\"\n",
    "        if torch.rand(1).item() < probability and signal.size(0) == 2:\n",
    "            phase_min, phase_max = self.config['phase_shift_range']\n",
    "            phase_shift = torch.uniform(phase_min, phase_max, (1,)).item()\n",
    "            \n",
    "            # Apply rotation matrix to I/Q\n",
    "            cos_phi = np.cos(phase_shift)\n",
    "            sin_phi = np.sin(phase_shift)\n",
    "            \n",
    "            i_rotated = signal[0] * cos_phi - signal[1] * sin_phi\n",
    "            q_rotated = signal[0] * sin_phi + signal[1] * cos_phi\n",
    "            \n",
    "            return torch.stack([i_rotated, q_rotated], dim=0)\n",
    "        return signal\n",
    "    \n",
    "    def amplitude_scaling(self, signal, probability=0.6):\n",
    "        \"\"\"Apply random amplitude scaling (AGC effects)\"\"\"\n",
    "        if torch.rand(1).item() < probability:\n",
    "            scale_min, scale_max = self.config['amplitude_scale_range']\n",
    "            scale_factor = torch.uniform(scale_min, scale_max, (1,)).item()\n",
    "            return signal * scale_factor\n",
    "        return signal\n",
    "    \n",
    "    def frequency_offset(self, signal, probability=0.5):\n",
    "        \"\"\"Simulate carrier frequency offset\"\"\"\n",
    "        if torch.rand(1).item() < probability and signal.size(0) == 2:\n",
    "            freq_min, freq_max = self.config['frequency_shift_range']\n",
    "            freq_offset = torch.uniform(freq_min, freq_max, (1,)).item()\n",
    "            \n",
    "            # Create time vector\n",
    "            seq_len = signal.size(1)\n",
    "            t = torch.arange(seq_len, dtype=torch.float32) / seq_len\n",
    "            \n",
    "            # Apply frequency offset\n",
    "            complex_offset = torch.exp(1j * 2 * np.pi * freq_offset * t)\n",
    "            \n",
    "            # Convert to I/Q and apply\n",
    "            cos_offset = torch.real(complex_offset)\n",
    "            sin_offset = torch.imag(complex_offset)\n",
    "            \n",
    "            i_shifted = signal[0] * cos_offset - signal[1] * sin_offset\n",
    "            q_shifted = signal[0] * sin_offset + signal[1] * cos_offset\n",
    "            \n",
    "            return torch.stack([i_shifted, q_shifted], dim=0)\n",
    "        return signal\n",
    "    \n",
    "    def time_shifting(self, signal, probability=0.4):\n",
    "        \"\"\"Apply random time shifts (timing offset)\"\"\"\n",
    "        if torch.rand(1).item() < probability:\n",
    "            shift_min, shift_max = self.config['time_shift_range']\n",
    "            shift = torch.randint(shift_min, shift_max + 1, (1,)).item()\n",
    "            \n",
    "            if shift != 0:\n",
    "                # Circular shift\n",
    "                return torch.roll(signal, shifts=shift, dims=1)\n",
    "        return signal\n",
    "    \n",
    "    def iq_imbalance(self, signal, probability=0.3):\n",
    "        \"\"\"Simulate I/Q imbalance (hardware imperfection)\"\"\"\n",
    "        if torch.rand(1).item() < probability and signal.size(0) == 2:\n",
    "            imb_min, imb_max = self.config['iq_imbalance_range']\n",
    "            \n",
    "            # Different scaling for I and Q channels\n",
    "            i_scale = torch.uniform(imb_min, imb_max, (1,)).item()\n",
    "            q_scale = torch.uniform(imb_min, imb_max, (1,)).item()\n",
    "            \n",
    "            signal_aug = signal.clone()\n",
    "            signal_aug[0] *= i_scale  # I channel\n",
    "            signal_aug[1] *= q_scale  # Q channel\n",
    "            \n",
    "            return signal_aug\n",
    "        return signal\n",
    "    \n",
    "    def dc_offset(self, signal, probability=0.3):\n",
    "        \"\"\"Add DC offset (hardware bias)\"\"\"\n",
    "        if torch.rand(1).item() < probability:\n",
    "            offset_min, offset_max = self.config['dc_offset_range']\n",
    "            \n",
    "            # Different DC offset for each channel\n",
    "            dc_i = torch.uniform(offset_min, offset_max, (1,)).item()\n",
    "            dc_q = torch.uniform(offset_min, offset_max, (1,)).item()\n",
    "            \n",
    "            signal_aug = signal.clone()\n",
    "            signal_aug[0] += dc_i\n",
    "            signal_aug[1] += dc_q\n",
    "            \n",
    "            return signal_aug\n",
    "        return signal\n",
    "    \n",
    "    def multipath_fading(self, signal, probability=0.2):\n",
    "        \"\"\"Simulate simple multipath fading\"\"\"\n",
    "        if torch.rand(1).item() < probability:\n",
    "            delay_min, delay_max = self.config['multipath_delay_range']\n",
    "            delay = torch.randint(delay_min, delay_max + 1, (1,)).item()\n",
    "            \n",
    "            # Create delayed and attenuated copy\n",
    "            attenuation = torch.uniform(0.1, 0.4, (1,)).item()\n",
    "            delayed_signal = torch.roll(signal, shifts=delay, dims=1) * attenuation\n",
    "            \n",
    "            return signal + delayed_signal\n",
    "        return signal\n",
    "    \n",
    "    def sample_dropout(self, signal, probability=0.1):\n",
    "        \"\"\"Randomly drop some samples (simulate packet loss)\"\"\"\n",
    "        if torch.rand(1).item() < probability:\n",
    "            dropout_min, dropout_max = self.config['dropout_prob_range']\n",
    "            dropout_prob = torch.uniform(dropout_min, dropout_max, (1,)).item()\n",
    "            \n",
    "            # Create dropout mask\n",
    "            mask = torch.rand(signal.size()) > dropout_prob\n",
    "            return signal * mask\n",
    "        return signal\n",
    "    \n",
    "    def spectral_inversion(self, signal, probability=0.2):\n",
    "        \"\"\"Apply spectral inversion (Q channel sign flip)\"\"\"\n",
    "        if torch.rand(1).item() < probability and signal.size(0) == 2:\n",
    "            signal_aug = signal.clone()\n",
    "            signal_aug[1] *= -1  # Flip Q channel\n",
    "            return signal_aug\n",
    "        return signal\n",
    "    \n",
    "    def __call__(self, signal, augmentation_strength=1.0):\n",
    "        \"\"\"\n",
    "        Apply random combination of augmentations\n",
    "        \n",
    "        Args:\n",
    "            signal: Input I/Q signal tensor (2, seq_len)\n",
    "            augmentation_strength: Float 0-1, controls how aggressive augmentation is\n",
    "        \"\"\"\n",
    "        \n",
    "        # Adjust probabilities based on strength\n",
    "        strength_factor = min(max(augmentation_strength, 0.0), 1.0)\n",
    "        \n",
    "        # Apply augmentations in logical order\n",
    "        augmented = signal.clone()\n",
    "        \n",
    "        # Hardware imperfections (apply early)\n",
    "        augmented = self.dc_offset(augmented, probability=0.3 * strength_factor)\n",
    "        augmented = self.iq_imbalance(augmented, probability=0.3 * strength_factor)\n",
    "        \n",
    "        # Channel effects\n",
    "        augmented = self.phase_rotation(augmented, probability=0.7 * strength_factor)\n",
    "        augmented = self.frequency_offset(augmented, probability=0.5 * strength_factor)\n",
    "        augmented = self.amplitude_scaling(augmented, probability=0.6 * strength_factor)\n",
    "        \n",
    "        # Noise and interference\n",
    "        augmented = self.add_awgn_noise(augmented, probability=0.8 * strength_factor)\n",
    "        augmented = self.multipath_fading(augmented, probability=0.2 * strength_factor)\n",
    "        \n",
    "        # Timing effects\n",
    "        augmented = self.time_shifting(augmented, probability=0.4 * strength_factor)\n",
    "        \n",
    "        # Digital effects\n",
    "        augmented = self.sample_dropout(augmented, probability=0.1 * strength_factor)\n",
    "        augmented = self.spectral_inversion(augmented, probability=0.2 * strength_factor)\n",
    "        \n",
    "        return augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef029fd-73bc-4c74-9efe-7bb668dd33b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_augmentation_presets():\n",
    "    \"\"\"\n",
    "    Get predefined augmentation configurations for different scenarios\n",
    "    \"\"\"\n",
    "    \n",
    "    presets = {\n",
    "        'conservative': {\n",
    "            'noise_std_range': (0.005, 0.02),\n",
    "            'snr_range': (0, 25),\n",
    "            'phase_shift_range': (-np.pi/4, np.pi/4),\n",
    "            'amplitude_scale_range': (0.8, 1.2),\n",
    "            'frequency_shift_range': (-0.05, 0.05),\n",
    "            'time_shift_range': (-20, 20),\n",
    "            'iq_imbalance_range': (0.95, 1.05),\n",
    "            'dc_offset_range': (-0.05, 0.05),\n",
    "            'multipath_delay_range': (1, 5),\n",
    "            'dropout_prob_range': (0.0, 0.01),\n",
    "        },\n",
    "        \n",
    "        'moderate': {\n",
    "            'noise_std_range': (0.01, 0.05),\n",
    "            'snr_range': (-5, 30),\n",
    "            'phase_shift_range': (-np.pi/2, np.pi/2),\n",
    "            'amplitude_scale_range': (0.7, 1.3),\n",
    "            'frequency_shift_range': (-0.1, 0.1),\n",
    "            'time_shift_range': (-50, 50),\n",
    "            'iq_imbalance_range': (0.9, 1.1),\n",
    "            'dc_offset_range': (-0.1, 0.1),\n",
    "            'multipath_delay_range': (1, 10),\n",
    "            'dropout_prob_range': (0.0, 0.02),\n",
    "        },\n",
    "        \n",
    "        'aggressive': {\n",
    "            'noise_std_range': (0.02, 0.1),\n",
    "            'snr_range': (-10, 35),\n",
    "            'phase_shift_range': (-np.pi, np.pi),\n",
    "            'amplitude_scale_range': (0.5, 1.5),\n",
    "            'frequency_shift_range': (-0.2, 0.2),\n",
    "            'time_shift_range': (-100, 100),\n",
    "            'iq_imbalance_range': (0.8, 1.2),\n",
    "            'dc_offset_range': (-0.2, 0.2),\n",
    "            'multipath_delay_range': (1, 20),\n",
    "            'dropout_prob_range': (0.0, 0.05),\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return presets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0930400-e2d4-4cb2-a6b6-e8633cd24dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseCNN_Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dropout_rate=0.4, use_residual = True):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class BaseCNN_NET(nn.Module):\n",
    "    def __init__(self, n_labels, dropout_rate=0.4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.backbone = nn.Sequential(\n",
    "            BaseCNN_Block(2, 32, dropout_rate=0.2),\n",
    "            BaseCNN_Block(32, 64, dropout_rate=0.3),\n",
    "            BaseCNN_Block(64, 128, dropout_rate=0.3),\n",
    "            nn.AdaptiveAvgPool1d(16)\n",
    "        )\n",
    "\n",
    "        # Enhanced classifier for 19-class problem\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 16, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate),\n",
    "\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate * 0.75),\n",
    "\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate * 0.5),\n",
    "\n",
    "            nn.Linear(128, n_labels)  # This will be 19 for full dataset\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "def create_improved_model(n_labels, dropout_rate=0.4):\n",
    "    \"\"\"Create improved CNN model - now works for any number of classes\"\"\"\n",
    "    return ImprovedCNN_NET(n_labels, dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17d7d9d-0e49-46e0-9f3b-f3a1fbd08892",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN32Channels(nn.Module): #32 channels \n",
    "    def __init__(self, n_labels=8, dropout_rate=0.4):\n",
    "        super(New_CNN32, self).__init__()\n",
    "       \n",
    "        # Channel progression: 2 â†’ 16 â†’ 32 â†’ 32 â†’ 24 â†’ 16 â†’ 8\n",
    "        self.features = nn.Sequential(\n",
    "            # Block 1: 2 â†’ 16 channels (large kernel for initial feature extraction)\n",
    "            nn.Conv1d(2, 16, kernel_size=9, stride=2, padding=4),    # 1024 â†’ 512\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AvgPool1d(kernel_size=2, stride=2),                   # 512 â†’ 256\n",
    "            nn.Dropout(dropout_rate * 0.3),\n",
    "           \n",
    "            # Block 2: 16 â†’ 32 channels (max)\n",
    "            nn.Conv1d(16, 32, kernel_size=7, stride=2, padding=3),   # 256 â†’ 128\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AvgPool1d(kernel_size=2, stride=2),                   # 128 â†’ 64\n",
    "            nn.Dropout(dropout_rate * 0.4),\n",
    "           \n",
    "            # Block 3: 32 â†’ 32 channels (maintain)\n",
    "            nn.Conv1d(32, 32, kernel_size=5, stride=2, padding=2),   # 64 â†’ 32\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AvgPool1d(kernel_size=2, stride=2),                   # 32 â†’ 16\n",
    "            nn.Dropout(dropout_rate * 0.4),\n",
    "           \n",
    "            # Block 4: 32 â†’ 24 channels (reduce)\n",
    "            nn.Conv1d(32, 24, kernel_size=3, stride=1, padding=1),   # 16 â†’ 16\n",
    "            nn.BatchNorm1d(24),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AvgPool1d(kernel_size=2, stride=2),                   # 16 â†’ 8\n",
    "            nn.Dropout(dropout_rate * 0.5),\n",
    "           \n",
    "            # Block 5: 24 â†’ 16 channels\n",
    "            nn.Conv1d(24, 16, kernel_size=3, stride=1, padding=1),   # 8 â†’ 8\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate * 0.5),\n",
    "           \n",
    "            # Block 6: 16 â†’ 8 channels (final) - SAFE kernel size\n",
    "            nn.Conv1d(16, 8, kernel_size=3, stride=1, padding=1),    # 8 â†’ 8\n",
    "            nn.BatchNorm1d(8),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "       \n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool1d(4)\n",
    "       \n",
    "        # Smaller classifier to prevent overfitting\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "           \n",
    "            nn.Linear(8 * 4, 128),\n",
    "\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate),\n",
    "           \n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate * 0.7),\n",
    "           \n",
    "            nn.Linear(64, n_labels)\n",
    "        )\n",
    "       \n",
    "        self._initialize_weights()\n",
    "   \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "   \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.adaptive_pool(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2884fe4-d016-4cd7-9e39-2adaa6bf83e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN64Channels(nn.Module): # 64 channels \n",
    "    def __init__(self, n_labels=8, dropout_rate=0.5):\n",
    "        super(CNN64Channels, self).__init__()\n",
    "       \n",
    "        # Channel progression: 2 â†’ 32 â†’ 64 â†’ 64 â†’ 48 â†’ 32 â†’ 16\n",
    "        self.features = nn.Sequential(\n",
    "            # Block 1: 2 â†’ 32 channels\n",
    "            nn.Conv1d(2, 32, kernel_size=9, stride=2, padding=4),    # 1024 â†’ 512\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AvgPool1d(kernel_size=2, stride=2),                   # 512 â†’ 256\n",
    "            nn.Dropout(dropout_rate * 0.3),\n",
    "           \n",
    "            # Block 2: 32 â†’ 64 channels (max)\n",
    "            nn.Conv1d(32, 64, kernel_size=7, stride=2, padding=3),   # 256 â†’ 128\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AvgPool1d(kernel_size=2, stride=2),                   # 128 â†’ 64\n",
    "            nn.Dropout(dropout_rate * 0.4),\n",
    "           \n",
    "            # Block 3: 64 â†’ 64 channels (maintain)\n",
    "            nn.Conv1d(64, 64, kernel_size=5, stride=2, padding=2),   # 64 â†’ 32\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AvgPool1d(kernel_size=2, stride=2),                   # 32 â†’ 16\n",
    "            nn.Dropout(dropout_rate * 0.5),\n",
    "           \n",
    "            # Block 4: 64 â†’ 48 channels (reduce)\n",
    "            nn.Conv1d(64, 48, kernel_size=3, stride=1, padding=1),   # 16 â†’ 16\n",
    "            nn.BatchNorm1d(48),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AvgPool1d(kernel_size=2, stride=2),                   # 16 â†’ 8\n",
    "            nn.Dropout(dropout_rate * 0.6),\n",
    "           \n",
    "            # Block 5: 48 â†’ 32 channels\n",
    "            nn.Conv1d(48, 32, kernel_size=3, stride=1, padding=1),   # 8 â†’ 8\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate * 0.6),\n",
    "           \n",
    "            # Block 6: 32 â†’ 16 channels (final)\n",
    "            nn.Conv1d(32, 16, kernel_size=3, stride=1, padding=1),   # 8 â†’ 8\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "       \n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool1d(4)\n",
    "       \n",
    "        # More robust classifier for higher capacity\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "           \n",
    "            nn.Linear(16 * 4, 256),\n",
    "\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate),\n",
    "           \n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate * 0.8),\n",
    "           \n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate * 0.6),\n",
    "           \n",
    "            nn.Linear(64, n_labels)\n",
    "        )\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "   \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.adaptive_pool(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc6adad-a012-468d-897a-61d5193dbe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexCNN_Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dropout_rate=0.4, use_residual=True):\n",
    "        super().__init__()\n",
    "        self.use_residual = use_residual and (in_channels == out_channels)\n",
    "        \n",
    "        # More complex block with 3 convolutions instead of 2\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.conv3 = nn.Conv1d(out_channels, out_channels, kernel_size=3, padding=1)  # Additional conv layer\n",
    "        self.bn3 = nn.BatchNorm1d(out_channels)\n",
    "        \n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # Residual connection adjustment\n",
    "        if self.use_residual:\n",
    "            self.residual_pool = nn.MaxPool1d(kernel_size=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        # Three convolution layers instead of two\n",
    "        out = torch.relu(self.bn1(self.conv1(x)))\n",
    "        out = torch.relu(self.bn2(self.conv2(out)))\n",
    "        out = torch.relu(self.bn3(self.conv3(out)))\n",
    "        \n",
    "        # Apply pooling\n",
    "        out = self.pool(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # Residual connection\n",
    "        if self.use_residual:\n",
    "            identity = self.residual_pool(identity)\n",
    "            if identity.shape == out.shape:\n",
    "                out = out + identity\n",
    "        \n",
    "        return out\n",
    "\n",
    "class ComplexCNN_NET(nn.Module):\n",
    "    def __init__(self, n_labels, dropout_rate=0.4):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Much more complex backbone with more blocks and channels\n",
    "        self.backbone = nn.Sequential(\n",
    "            # Block 1: 2 â†’ 32 channels\n",
    "            ComplexCNN_Block(2, 32, dropout_rate=dropout_rate*0.3, use_residual=False),\n",
    "            \n",
    "            # Block 2: 32 â†’ 64 channels  \n",
    "            ComplexCNN_Block(32, 64, dropout_rate=dropout_rate*0.4, use_residual=True),\n",
    "            \n",
    "            # Block 3: 64 â†’ 128 channels\n",
    "            ComplexCNN_Block(64, 128, dropout_rate=dropout_rate*0.4, use_residual=True),\n",
    "            \n",
    "            # Block 4: 128 â†’ 256 channels (NEW - wider network)\n",
    "            ComplexCNN_Block(128, 256, dropout_rate=dropout_rate*0.5, use_residual=True),\n",
    "            \n",
    "            # Block 5: 256 â†’ 256 channels (NEW - maintain high capacity)\n",
    "            ComplexCNN_Block(256, 256, dropout_rate=dropout_rate*0.5, use_residual=True),\n",
    "            \n",
    "            # Block 6: 256 â†’ 128 channels (NEW - gradual reduction)\n",
    "            ComplexCNN_Block(256, 128, dropout_rate=dropout_rate*0.6, use_residual=False),\n",
    "            \n",
    "            # Block 7: 128 â†’ 64 channels (NEW - further reduction)  \n",
    "            ComplexCNN_Block(128, 64, dropout_rate=dropout_rate*0.6, use_residual=True),\n",
    "            \n",
    "            # Adaptive pooling for consistent output\n",
    "            nn.AdaptiveAvgPool1d(8)  # Smaller output for deeper network\n",
    "        )\n",
    "\n",
    "        # More complex classifier with additional layers\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            \n",
    "            # First dense block\n",
    "            nn.Linear(64 * 8, 1024),  # Much larger first layer\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate),\n",
    "\n",
    "            # Second dense block  \n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate * 0.8),\n",
    "\n",
    "            # Third dense block\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate * 0.6),\n",
    "            \n",
    "            # Fourth dense block (NEW)\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate * 0.4),\n",
    "\n",
    "            # Final classification layer\n",
    "            nn.Linear(128, n_labels)\n",
    "        )\n",
    "        \n",
    "        # Initialize weights properly\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "def create_complex_model(n_labels, dropout_rate=0.4):\n",
    "    \"\"\"Create complex CNN model - same interface as your base model\"\"\"\n",
    "    return ComplexCNN_NET(n_labels, dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e016e6-8912-494b-899e-43b3a46f223e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "from collections import deque\n",
    "\n",
    "def train_model(model, train_dl, valid_dl, num_epoch=200, device='cuda', \n",
    "                accumulation_steps=1, use_amp=True, verbose=True):\n",
    "    # Initialize model and history\n",
    "    model.to(device)\n",
    "    train_loss_history, train_acc_history = [], []\n",
    "    val_loss_history, val_acc_history = [], []\n",
    "    \n",
    "    # Setup optimization\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-3, weight_decay=5e-5)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer, max_lr=2e-3, epochs=num_epoch, steps_per_epoch=len(train_dl)\n",
    "    )\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    scaler = torch.cuda.amp.GradScaler() if use_amp else None\n",
    "    \n",
    "    # Training setup\n",
    "    best_val_loss = float('inf')\n",
    "    patience, patience_counter = 25, 0\n",
    "    output_dir = r\"C:\\workarea\\CNN model\\model\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    best_model_path = os.path.join(output_dir, 'best_model.pth')\n",
    "\n",
    "    for epoch in trange(num_epoch, desc='Training'):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        total_train_loss, total_train_correct, total_train_samples = 0, 0, 0\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        for batch_idx, (x, y, _) in enumerate(train_dl):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            with torch.autocast(device_type=device, dtype=torch.float16, enabled=use_amp):\n",
    "                logits = model(x)\n",
    "                loss = criterion(logits, y) / accumulation_steps\n",
    "                \n",
    "            if use_amp:\n",
    "                scaler.scale(loss).backward()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                \n",
    "            if (batch_idx + 1) % accumulation_steps == 0:\n",
    "                if use_amp:\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "            # Update metrics\n",
    "            total_train_loss += loss.item() * accumulation_steps * x.size(0)\n",
    "            total_train_correct += (logits.argmax(1) == y).sum().item()\n",
    "            total_train_samples += x.size(0)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        total_val_loss, total_val_correct, total_val_samples = 0, 0, 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for x, y, _ in valid_dl:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                logits = model(x)\n",
    "                loss = criterion(logits, y)\n",
    "                total_val_loss += loss.item() * x.size(0)\n",
    "                total_val_correct += (logits.argmax(1) == y).sum().item()\n",
    "                total_val_samples += x.size(0)\n",
    "        \n",
    "        # Calculate epoch metrics\n",
    "        epoch_train_loss = total_train_loss / total_train_samples\n",
    "        epoch_train_acc = total_train_correct / total_train_samples\n",
    "        epoch_val_loss = total_val_loss / total_val_samples\n",
    "        epoch_val_acc = total_val_correct / total_val_samples\n",
    "        \n",
    "        # Update history\n",
    "        train_loss_history.append(epoch_train_loss)\n",
    "        train_acc_history.append(epoch_train_acc)\n",
    "        val_loss_history.append(epoch_val_loss)\n",
    "        val_acc_history.append(epoch_val_acc)\n",
    "        \n",
    "        # Checkpointing\n",
    "        if epoch_val_loss < best_val_loss:\n",
    "            best_val_loss = epoch_val_loss\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            \n",
    "        # Early stopping\n",
    "        if patience_counter >= patience:\n",
    "            if verbose: \n",
    "                print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
    "            model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "            break\n",
    "            \n",
    "        # Progress reporting\n",
    "        if verbose and (epoch % 10 == 0 or epoch == num_epoch - 1):\n",
    "            print(f\"Epoch {epoch+1}/{num_epoch} | \"\n",
    "                  f\"Train Loss: {epoch_train_loss:.4f} Acc: {epoch_train_acc * 100:.2f}% | \"\n",
    "                  f\"Val Loss: {epoch_val_loss:.4f} Acc: {epoch_val_acc * 100:.2f}%\")\n",
    "    \n",
    "    return model, {\n",
    "        'train_loss': train_loss_history,\n",
    "        'train_acc': train_acc_history,\n",
    "        'val_loss': val_loss_history,\n",
    "        'val_acc': val_acc_history,\n",
    "        'best_val_loss': best_val_loss\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42d6c05-d744-45db-9d29-3c879c7b4fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 3. IMPROVED TESTING AND ANALYSIS FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def test_model_with_improved_plots(model, device='cuda'):\n",
    "    \"\"\"\n",
    "    Enhanced testing function with better memory management and error handling\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    Y_pred_ = []  # Predictions\n",
    "    Y_true_ = []  # Ground truth\n",
    "    Z_snr_ = []   # SNR values\n",
    "\n",
    "    # Use your dataset class\n",
    "    test_dataset = RadioML18Dataset(mode='test')\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "\n",
    "    target_classes = test_dataset.target_modulations\n",
    "    target_snrs = test_dataset.target_snrs\n",
    "    \n",
    "    # Add debug\n",
    "    print(f\"Target modulations: {target_classes}\")\n",
    "    print(f\"Target SNRs: {target_snrs}\")\n",
    "    print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "    # Initialize accuracy stats DataFrame\n",
    "    accuracy_stats = pd.DataFrame(\n",
    "        0.0,\n",
    "        index=target_classes,\n",
    "        columns=target_snrs.astype('str'))\n",
    "\n",
    "    # Get predictions with tqdm progress bar\n",
    "    test_progress = tqdm(test_loader, desc=\"Testing model\", leave=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (x, y, z) in enumerate(test_progress):\n",
    "            # Move tensors to specified device\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            z = z.to(device)\n",
    "\n",
    "            # Get model predictions on device\n",
    "            logits = model(x)\n",
    "            y_pred = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            # Store results\n",
    "            Y_pred_.append(y_pred.cpu())  # Move back to CPU for storage\n",
    "            Y_true_.append(y.cpu())\n",
    "            Z_snr_.append(z.cpu())\n",
    "\n",
    "            # Update progress bar\n",
    "            if batch_idx % 10 == 0:\n",
    "                current_acc = (y_pred == y).float().mean().item()\n",
    "                test_progress.set_postfix({\"batch_acc\": f\"{current_acc:.3f}\"})\n",
    "\n",
    "            # Free up memory\n",
    "            del x, y, z, logits, y_pred\n",
    "            if device == 'cuda':\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "    # Convert to numpy for easier processing\n",
    "    Y_pred = torch.cat(Y_pred_).numpy()\n",
    "    Y_true = torch.cat(Y_true_).numpy()\n",
    "    Z_snr = torch.cat(Z_snr_).numpy()\n",
    "\n",
    "    # Clear lists to free memory\n",
    "    del Y_pred_, Y_true_, Z_snr_\n",
    "\n",
    "    # Calculate overall accuracy\n",
    "    correct_preds = (Y_pred == Y_true).sum()\n",
    "    total_samples = len(Y_true)\n",
    "    total_accuracy = round(correct_preds * 100 / total_samples, 2)\n",
    "    print(f'Overall test accuracy: {total_accuracy}%')\n",
    "\n",
    "    # Count samples for each modulation type\n",
    "    mod_counts = {}\n",
    "    for mod_idx, mod_name in enumerate(target_classes):\n",
    "        count = np.sum(Y_true == mod_idx)\n",
    "        mod_counts[mod_name] = count\n",
    "        print(f\"Modulation {mod_name}: {count} test samples\")\n",
    "\n",
    "    # Calculate accuracy per modulation and SNR with progress bar\n",
    "    mod_snr_progress = tqdm(list(enumerate(target_classes)),\n",
    "                           desc=\"Calculating per-modulation accuracies\",\n",
    "                           leave=True)\n",
    "\n",
    "    for mod_idx, mod_name in mod_snr_progress:\n",
    "        mod_snr_progress.set_postfix({\"modulation\": mod_name})\n",
    "        for snr_idx, snr in enumerate(target_snrs):\n",
    "            snr_str = str(snr)\n",
    "\n",
    "            mask = (Y_true == mod_idx) & (Z_snr == snr)\n",
    "            total_samples = mask.sum()\n",
    "            if total_samples > 0:\n",
    "                correct_samples = ((Y_pred == Y_true) & mask).sum()\n",
    "                accuracy = (correct_samples * 100 / total_samples)\n",
    "                accuracy_stats.loc[mod_name, snr_str] = round(accuracy, 2)\n",
    "            else:\n",
    "                accuracy_stats.loc[mod_name, snr_str] = np.nan\n",
    "                print(f\"Warning: no samples for {mod_name} at SNR = {snr}\")\n",
    "\n",
    "    return accuracy_stats, mod_counts, Y_true, Y_pred, target_classes\n",
    "\n",
    "def plot_confusion_matrix(Y_true, Y_pred, target_classes, save_path='/mnt/sda3/dataset_AMC /radioml2018/results/'): #change the path as we want \n",
    "    \"\"\"\n",
    "    Plot confusion matrix for better understanding of misclassifications\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(Y_true, Y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=target_classes,\n",
    "                yticklabels=target_classes)\n",
    "    plt.title('Confusion Matrix - Signal Modulation Classification')\n",
    "    plt.xlabel('Predicted Modulation')\n",
    "    plt.ylabel('True Modulation')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    plt.savefig(f'{save_path}confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # Print classification report\n",
    "    print(\"\\nDetailed Classification Report:\")\n",
    "    print(classification_report(Y_true, Y_pred, target_names=target_classes))\n",
    "\n",
    "def plot_improved_test_accuracy(model, device='cuda', save_path='/mnt/sda3/dataset_AMC /radioml2018/results/'):#change the path as we want \n",
    "    \"\"\"\n",
    "    Enhanced plotting function with confusion matrix and better analysis\n",
    "    \"\"\"\n",
    "    accuracy_df, mod_counts, Y_true, Y_pred, target_classes = test_model_with_improved_plots(model, device)\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    # 1. Plot confusion matrix first\n",
    "    plot_confusion_matrix(Y_true, Y_pred, target_classes, save_path)\n",
    "\n",
    "    # 2. Overall accuracy vs SNR plot\n",
    "    plt.figure(figsize=(14, 8))\n",
    "\n",
    "    accuracy_long = accuracy_df.reset_index().melt(\n",
    "        id_vars=['index'],\n",
    "        var_name='SNR',\n",
    "        value_name='Accuracy'\n",
    "    )\n",
    "    accuracy_long.columns = ['Modulation', 'SNR', 'Accuracy']\n",
    "\n",
    "    # Convert SNR to numeric for proper ordering\n",
    "    accuracy_long['SNR_numeric'] = accuracy_long['SNR'].astype(int)\n",
    "    accuracy_long = accuracy_long.sort_values('SNR_numeric')\n",
    "\n",
    "    sns.lineplot(\n",
    "        data=accuracy_long,\n",
    "        x='SNR_numeric',\n",
    "        y='Accuracy',\n",
    "        hue='Modulation',\n",
    "        marker='o',\n",
    "        markersize=8,\n",
    "        linewidth=2\n",
    "    )\n",
    "\n",
    "    # Highlight PSK modulations\n",
    "    psk_mods = [mod for mod in accuracy_df.index if 'PSK' in mod]\n",
    "    if psk_mods:\n",
    "        print(f\"Highlighting PSK modulations: {psk_mods}\")\n",
    "        for mod in psk_mods:\n",
    "            mod_data = accuracy_long[accuracy_long['Modulation'] == mod]\n",
    "            if not mod_data.empty:\n",
    "                plt.plot(mod_data['SNR_numeric'], mod_data['Accuracy'],\n",
    "                         linewidth=4,\n",
    "                         linestyle='--',\n",
    "                         marker='*',\n",
    "                         markersize=12,\n",
    "                         alpha=0.8)\n",
    "\n",
    "    plt.title('Classification Accuracy vs SNR for Different Modulation Types', fontsize=16)\n",
    "    plt.xlabel('Signal-to-Noise Ratio (dB)', fontsize=14)\n",
    "    plt.ylabel('Accuracy (%)', fontsize=14)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{save_path}all_modulations_accuracy.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # 3. Enhanced heatmap visualization\n",
    "    plt.figure(figsize=(16, 8))\n",
    "\n",
    "    # Reorder columns (SNRs) numerically\n",
    "    snr_columns = sorted(accuracy_df.columns, key=int)\n",
    "    accuracy_df_sorted = accuracy_df[snr_columns]\n",
    "\n",
    "    # Create heatmap with better formatting\n",
    "    mask = accuracy_df_sorted.isna()\n",
    "    sns.heatmap(accuracy_df_sorted.astype(float),\n",
    "                annot=True,\n",
    "                cmap='RdYlGn',\n",
    "                fmt='.1f',\n",
    "                mask=mask,\n",
    "                cbar_kws={'label': 'Accuracy (%)'},\n",
    "                linewidths=0.5)\n",
    "\n",
    "    plt.title('Classification Accuracy Heatmap by Modulation and SNR', fontsize=16)\n",
    "    plt.xlabel('Signal-to-Noise Ratio (dB)', fontsize=14)\n",
    "    plt.ylabel('Modulation Type', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{save_path}modulation_accuracy_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # 4. Summary statistics\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PERFORMANCE SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    overall_acc = np.nanmean(accuracy_df_sorted.values)\n",
    "    print(f\"Overall average accuracy: {overall_acc:.2f}%\")\n",
    "\n",
    "    # Best and worst performing modulations\n",
    "    mod_avg_acc = accuracy_df_sorted.mean(axis=1).sort_values(ascending=False)\n",
    "    print(f\"\\nBest performing modulation: {mod_avg_acc.index[0]} ({mod_avg_acc.iloc[0]:.2f}%)\")\n",
    "    print(f\"Worst performing modulation: {mod_avg_acc.index[-1]} ({mod_avg_acc.iloc[-1]:.2f}%)\")\n",
    "\n",
    "    return accuracy_df_sorted\n",
    "\n",
    "def plot_training_history(model_name, history, save_path='/mnt/sda3/dataset_AMC /radioml2018/results/'): #change the path as we want \n",
    "    \"\"\"\n",
    "    Enhanced training history plotting with more details\n",
    "    \"\"\"\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "\n",
    "    # Loss plot\n",
    "    ax1.plot(epochs, history['train_loss'], 'b-', label='Training Loss', linewidth=2)\n",
    "    ax1.plot(epochs, history['val_loss'], 'r-', label='Validation Loss', linewidth=2)\n",
    "    ax1.set_title('Model Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    # Accuracy plot\n",
    "    ax2.plot(epochs, [acc * 100 for acc in history['train_acc']], 'b-', label='Training Accuracy', linewidth=2)\n",
    "    ax2.plot(epochs, [acc * 100 for acc in history['val_acc']], 'r-', label='Validation Accuracy', linewidth=2)\n",
    "    ax2.set_title('Model Accuracy')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy (%)')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    # Overfitting analysis\n",
    "    train_val_gap = [abs(t - v) * 100 for t, v in zip(history['train_acc'], history['val_acc'])]\n",
    "    ax3.plot(epochs, train_val_gap, 'g-', linewidth=2)\n",
    "    ax3.set_title('Train-Validation Gap (Overfitting Indicator)')\n",
    "    ax3.set_xlabel('Epoch')\n",
    "    ax3.set_ylabel('Accuracy Gap (%)')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "\n",
    "    # Show validation loss trend\n",
    "    ax4.plot(epochs, history['val_loss'], 'purple', linewidth=2)\n",
    "    ax4.set_title('Validation Loss Trend')\n",
    "    ax4.set_xlabel('Epoch')\n",
    "    ax4.set_ylabel('Validation Loss')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.suptitle(f'Training Analysis: {model_name}', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    plt.savefig(f'{save_path}{model_name}_detailed_training_history.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # Print training summary\n",
    "    print(f\"\\nTraining Summary for {model_name}:\")\n",
    "    print(f\"Epochs trained: {len(epochs)}\")\n",
    "    print(f\"Final training accuracy: {history['train_acc'][-1]*100:.2f}%\")\n",
    "    print(f\"Final validation accuracy: {history['val_acc'][-1]*100:.2f}%\")\n",
    "    print(f\"Best validation loss: {history['best_val_loss']:.4f}\")\n",
    "\n",
    "def check_dataset_distribution(dataset_mode='test'):\n",
    "    \"\"\"\n",
    "    Enhanced dataset analysis with better statistics\n",
    "    \"\"\"\n",
    "    # Create dataset for analysis\n",
    "    dataset = RadioML18Dataset(mode=dataset_mode)\n",
    "\n",
    "    # Analyze distribution\n",
    "    mod_counts = {}\n",
    "    snr_mod_counts = {}\n",
    "\n",
    "    # Initialize counts for all modulations\n",
    "    for mod in dataset.target_modulations:\n",
    "        mod_counts[mod] = 0\n",
    "\n",
    "    # Set up progress bar\n",
    "    progress_bar = tqdm(range(len(dataset)), desc=f\"Analyzing {dataset_mode} dataset\", leave=True)\n",
    "\n",
    "    # Count occurrences of each modulation\n",
    "    for i in progress_bar:\n",
    "        _, mod_idx, snr = dataset[i]\n",
    "        mod = dataset.target_modulations[mod_idx]\n",
    "\n",
    "        # Count by modulation\n",
    "        mod_counts[mod] += 1\n",
    "\n",
    "        # Count by modulation and SNR\n",
    "        if snr not in snr_mod_counts:\n",
    "            snr_mod_counts[snr] = {}\n",
    "        if mod not in snr_mod_counts[snr]:\n",
    "            snr_mod_counts[snr][mod] = 0\n",
    "        snr_mod_counts[snr][mod] += 1\n",
    "\n",
    "        # Update progress bar less frequently for performance\n",
    "        if i % 1000 == 0:\n",
    "            progress_bar.set_postfix({\"current_mod\": mod, \"snr\": snr})\n",
    "\n",
    "    print(f\"\\n{dataset_mode.upper()} Dataset Distribution Analysis:\")\n",
    "    print(\"=\"*50)\n",
    "    total_samples = sum(mod_counts.values())\n",
    "    print(f\"Total samples: {total_samples:,}\")\n",
    "\n",
    "    print(\"\\nModulation distribution:\")\n",
    "    for mod, count in mod_counts.items():\n",
    "        percentage = (count / total_samples) * 100\n",
    "        print(f\"  {mod}: {count:,} samples ({percentage:.1f}%)\")\n",
    "\n",
    "    # Check if dataset is balanced\n",
    "    counts = list(mod_counts.values())\n",
    "    is_balanced = max(counts) - min(counts) == 0\n",
    "    print(f\"\\nDataset balance: {'Perfectly balanced' if is_balanced else 'Imbalanced'}\")\n",
    "\n",
    "    return mod_counts, snr_mod_counts\n",
    "\n",
    "# Main execution function\n",
    "def improved_train_test_plots(model, model_name, device='cuda', num_epoch=NUM_EPOCHS):\n",
    "    \"\"\"\n",
    "    Complete training and testing pipeline with enhanced analysis\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(f\"TRAINING AND EVALUATION PIPELINE: {model_name}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # First check the dataset distribution\n",
    "    print(\"\\n1. Analyzing dataset distribution...\")\n",
    "    mod_counts, snr_mod_counts = check_dataset_distribution('test')\n",
    "\n",
    "    # Create data loaders using your configuration\n",
    "    train_dataset = RadioML18Dataset(mode='train')\n",
    "    valid_dataset = RadioML18Dataset(mode='valid')\n",
    "    \n",
    "    train_dl = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "    valid_dl = DataLoader(dataset=valid_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "\n",
    "    # Train the model using your train_model function\n",
    "    print(f\"\\n2. Training {model_name}...\")\n",
    "    model, train_history = train_model(model, train_dl, valid_dl, num_epoch=num_epoch, device=device)\n",
    "\n",
    "    # Define save paths\n",
    "    output_dir = r\"C:\\workarea\\CNN model\\model\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Save the trained model\n",
    "    state_dict_path = os.path.join(output_dir, f\"{model_name}_state_dict.pth\")\n",
    "    full_model_path = os.path.join(output_dir, f\"{model_name}_full_model.pth\")\n",
    "\n",
    "    torch.save(model.state_dict(), state_dict_path)\n",
    "    torch.save(model, full_model_path)\n",
    "\n",
    "    print(f\"Model saved as:\\n  - {state_dict_path}\\n  - {full_model_path}\")\n",
    "\n",
    "    # Plot training history\n",
    "    print(\"\\n3. Plotting training history...\")\n",
    "    plot_training_history(model_name, train_history)\n",
    "\n",
    "    # Test and analyze the model\n",
    "    print(\"\\n4. Testing model and generating analysis...\")\n",
    "    accuracy_results = plot_improved_test_accuracy(model, device)\n",
    "\n",
    "    print(\"\\n5. Analysis complete!\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    return model, train_history, accuracy_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046edbe6-8f30-4603-9466-4da729e57956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_with_augmentation(model, train_dataset, valid_dataset,\n",
    "                                 augmentation_preset = 'moderate',\n",
    "                                 num_epoch = 100,\n",
    "                                 batch_size = 32, device = 'cuda'):\n",
    "    \"\"\"\n",
    "    Processes dataset through preprocessing -> augmentation -> model training\n",
    "    WITHOUT performance optimizations\n",
    "    \n",
    "    Parameters:\n",
    "    model - Model to train\n",
    "    train_dataset - Training RadioML18Dataset instance\n",
    "    valid_dataset - Validation RadioML18Dataset instance  \n",
    "    augmentation_preset - 'conservative', 'moderate', or 'aggressive'\n",
    "    num_epoch - Number of training epochs\n",
    "    batch_size - Batch size for training\n",
    "    device - Device to train on\n",
    "    \n",
    "    Returns:\n",
    "    Trained model object\n",
    "    \"\"\"\n",
    "\n",
    "    presets = get_augmentation_presets()\n",
    "    aug_config = presets[augmentation_preset] \n",
    "    augmentor = SignalAugmentation(config = aug_config) \n",
    "\n",
    "    # create a custom collate fucntion for augmentation \n",
    "    def augment_collate_fn(batch): \n",
    "        x_batch,y_batch,z_batch = [], [], []\n",
    "        for x,y,z in batch: \n",
    "            x_aug = augmentor(x, augmenation_strength = 0.8)  # apply the augmentation \n",
    "            x_batch.append(x_aug)\n",
    "            y_batch.append(y)\n",
    "            z_batch.append(z) \n",
    "        #stack it into sensor \n",
    "        x_tensor = tensor.stack(x_batch)\n",
    "        y_tensor = torch.tensor(y_batch, dtype = torch.long)\n",
    "        z_tensor = torch.tensor(z_batch, dtype = torch.float32) \n",
    "\n",
    "        return x_tensor,y_tensor,z_tensor\n",
    "    # Standard collate function for validation (no augmentation)\n",
    "    def standard_collate_fn(batch): \n",
    "        x_batch_y_batch,z_batch = [], [], [] \n",
    "\n",
    "        for x,y,z in batch: \n",
    "            x_batch.append(x) \n",
    "            y_batch.append(y)\n",
    "            z_batch.append(z)\n",
    "            \n",
    "        x_tensor = tensor.stack(x_batch)\n",
    "        y_tensor = torch.tensor(y_batch, dtype = torch.long)\n",
    "        z_tensor = torch.tensor(z_batch, dtype = torch.float32) \n",
    "\n",
    "        return x_tensor,y_tensor,z_tensor\n",
    "        \n",
    "    # create dataloader \n",
    "    train_loader = DataLoader(\n",
    "        dataset = train_dataset, \n",
    "        batch_size = batch_size, \n",
    "        shuffle = True, \n",
    "        drop_last = True, \n",
    "        collate_fn = augment_collate_fn,\n",
    "        num_worker = 0 \n",
    "    )\n",
    "\n",
    "    valid_loader = DataLoader(\n",
    "        dataset=valid_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        collate_fn=standard_collate_fn,\n",
    "        num_workers=0       \n",
    "    )\n",
    "\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr = 2e-3, weight_decay = 5e-5)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    print(f\"Training with {augmentation_preset} augmentation....\")\n",
    "\n",
    "    for epoch in range(num_epoch): \n",
    "\n",
    "        model.train()\n",
    "        train_loss = 0.0 \n",
    "        train_correct = 0 \n",
    "        train_total = 0 \n",
    "\n",
    "        for batch_idx, (x,y,z) in enumerate(train_loader): \n",
    "\n",
    "            x = x.to(device) \n",
    "            y = y.to(device)\n",
    "\n",
    "            # Forward pass \n",
    "            optimizer.zero_grad() \n",
    "            ouputs = model(x) \n",
    "            loss = criterion(outputs,y) \n",
    "\n",
    "            # backward pass \n",
    "            loss.backward()\n",
    "            opimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * x.size(0) \n",
    "            _, predicted = output.max(1) \n",
    "            train_total += y.size(0)\n",
    "            train_correct += predicted.eq(y).sum().item()\n",
    "\n",
    "        # Validation phase \n",
    "        model.eval()\n",
    "        val_loss = 0.0 \n",
    "        val_correct = 0 \n",
    "        val_total = 0 \n",
    "\n",
    "        with torch.no_grad(): \n",
    "              for x, y, z in valid_loader:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                \n",
    "                outputs = model(x)\n",
    "                loss = criterion(outputs, y)\n",
    "                \n",
    "                val_loss += loss.item() * x.size(0)\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += y.size(0)\n",
    "                val_correct += predicted.eq(y).sum().item()\n",
    "        \n",
    "        # Calculate epoch metrics\n",
    "        avg_train_loss = train_loss / train_total\n",
    "        train_acc = 100. * train_correct / train_total\n",
    "        avg_val_loss = val_loss / val_total\n",
    "        val_acc = 100. * val_correct / val_total\n",
    "        \n",
    "        # Print progress every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epoch}] '\n",
    "                  f'Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.2f}% | '\n",
    "                  f'Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "    \n",
    "    print(\"Training completed!\")\n",
    "    return model          \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4ebbec-3791-4c1d-b4dd-f8a501ec0f70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ddedae-0514-46b3-ba84-e5ec72ef1eac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed69d91-23ae-431c-8d3d-cac068d75f06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GNU Radio ai_sdr)",
   "language": "python",
   "name": "ai_sdr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
