!pip3 install pandas 
!pip3 install h5py 
!pip3 install tqdm 
!pip3 install torchinfo
!pip3 install matplotlib 
!pip3 install seaborn 
!pip3 install scikit-learn


import torch 

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(device)


import numpy as np
import pandas as pd
import h5py
import json
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torch.cuda.amp import GradScaler, autocast
from torchinfo import summary
import torch.utils.checkpoint as checkpoint
from sklearn.metrics import confusion_matrix, classification_report
from tqdm import tqdm, trange
import seaborn as sns
import gc
import time
import warnings
from collections import deque
import psutil
import os


n_channels=2
batch_size = 512      # or 128, 256, 512, etc.
frame_size = 1024    # fixed by dataset (1024 I/Q samples per frame)
n_labels = 8
nf_train = int(batch_size * 0.7)
nf_valid = int(batch_size * 0.2)
nf_test  = batch_size - nf_train - nf_valid


def dataset_split(data,
                  modulations_classes,
                  modulations,
                  snrs,
                  target_modulations,
                  mode,
                  target_snrs,
                  train_proportion=0.7, # training 70 %
                  valid_proportion=0.2, # validation 20 %
                  test_proportion=0.1, # testing 10 % 
                  seed=48):
    np.random.seed(seed)
    X_output = []
    Y_output = []
    Z_output = []                                   

    target_modulation_indices = [modulations_classes.index(modu) for modu in target_modulations]

    for modu in target_modulation_indices:
        for snr in target_snrs:
            snr_modu_indices = np.where((modulations == modu) & (snrs == snr))[0]

            np.random.shuffle(snr_modu_indices)
            num_samples = len(snr_modu_indices)
            train_end = int(train_proportion * num_samples)
            valid_end = int((train_proportion + valid_proportion) * num_samples)

            if mode == 'train':
                indices = snr_modu_indices[:train_end]
            elif mode == 'valid':
                indices = snr_modu_indices[train_end:valid_end]
            elif mode == 'test':
                indices = snr_modu_indices[valid_end:]
            else:
                raise ValueError(f'unknown mode: {mode}. Valid modes are train, valid and test')

            X_output.append(data[np.sort(indices)])
            Y_output.append(modulations[np.sort(indices)])
            Z_output.append(snrs[np.sort(indices)])

    X_array = np.vstack(X_output)
    Y_array = np.concatenate(Y_output)
    Z_array = np.concatenate(Z_output)
    for index, value in enumerate(np.unique(np.copy(Y_array))):
        Y_array[Y_array == value] = index
    return X_array, Y_array, Z_array


class RadioML18Dataset(Dataset):
    def __init__(self, mode: str, seed=48,):
        super(RadioML18Dataset, self).__init__()

        # load data
        hdf5_file = h5py.File("C:\\workarea\\CNN model\\dataset\\radioml2018\\versions\\2\\GOLD_XYZ_OSC.0001_1024.hdf5", 'r') #Escaped backslashes 
        self.modulation_classes = json.load(open("C:\\workarea\\CNN model\\dataset\\radioml2018\\versions\\2\\classes-fixed.json", 'r'))
        self.X = hdf5_file['X']
        self.Y = np.argmax(hdf5_file['Y'], axis=1)
        self.Z = hdf5_file['Z'][:, 0]

        train_proportion=(10*26*nf_train)/self.X.shape[0]
        valid_proportion=(10*26*nf_valid)/self.X.shape[0]
        test_proportion=(10*26*nf_test)/self.X.shape[0]

        """target_modulations =['OOK', '4ASK', 'BPSK', 'QPSK', '8PSK',
        '16QAM', 'AM-SSB-SC', 'AM-DSB-SC', 'FM', 'GMSK','OQPSK']target
        modulation class and snr"""

        # in this line i could change it the target modulation
        self.target_modulations = [
                    'OOK', '4ASK', '8ASK', 'BPSK', 
                    'QPSK', '8PSK', '16PSK', '32PSK','16QAM','64QAM'
                ]

        self.target_snrs = np.unique(self.Z)

        self.X_data, self.Y_data, self.Z_data = dataset_split(
                                                                  data = self.X,
                                                                  modulations_classes = self.modulation_classes,
                                                                  modulations = self.Y,
                                                                  snrs = self.Z,
                                                                  mode = mode,
                                                                  train_proportion = train_proportion,
                                                                  valid_proportion = valid_proportion,
                                                                  test_proportion = test_proportion,
                                                                  target_modulations = self.target_modulations,
                                                                  target_snrs  = self.target_snrs,
                                                                  seed=48
                                                                 )

        # *** CRITICAL FIX: Apply I/Q swap correction for AMC compatibility ***
        print(f"🔧 Applying I/Q swap fix to {mode} dataset...")
        X_corrected = np.zeros_like(self.X_data)
        X_corrected[:, :, 0] = self.X_data[:, :, 1]  # I = original Q
        X_corrected[:, :, 1] = self.X_data[:, :, 0]  # Q = original I
        self.X_data = X_corrected
        print(f"✅ I/Q channels corrected for real-world compatibility")

        # store statistic of whole dataset (unchanged)
        self.num_data = self.X_data.shape[0]
        self.num_lbl = len(self.target_modulations)
        self.num_snr = self.target_snrs.shape[0]

    def __len__(self):
        return self.X_data.shape[0]

    def __getitem__(self, idx):
        x,y,z = self.X_data[idx], self.Y_data[idx], self.Z_data[idx]
        x,y,z = torch.Tensor(x).transpose(0, 1) , y , z
        return x,y,z


ds = RadioML18Dataset(mode='test')
data_len = ds.num_data
n_labels=ds.num_lbl
n_snrs = ds.num_snr
frame_size=ds.X.shape[1]

print(data_len)
print(n_labels)
print(n_snrs)
print(frame_size)
del ds


dataset = RadioML18Dataset(mode='train')

# Print all modulation classes
print("All Modulation Classes:", dataset.modulation_classes)



import time
st = time.time()
train_dl = DataLoader(dataset=RadioML18Dataset(mode='train'),batch_size = 256, shuffle = True, drop_last = True)
valid_dl = DataLoader(dataset=RadioML18Dataset(mode='valid'),batch_size = 128, shuffle = True, drop_last = False)
test_dl = DataLoader(dataset=RadioML18Dataset(mode='test'), batch_size = 128, shuffle = True, drop_last = False)
et = time.time()
elapsed_time = et - st
print(f'Execution time : {elapsed_time} second')


class ImprovedCNN_Block(nn.Module):
    def __init__(self, in_channels, out_channels, dropout_rate=0.4, use_residual = True):
        super().__init__()
        self.block = nn.Sequential(
            nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm1d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv1d(out_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm1d(out_channels),
            nn.ReLU(inplace=True),
            nn.MaxPool1d(kernel_size=2),
            nn.Dropout(dropout_rate)
        )

    def forward(self, x):
        return self.block(x)

class ImprovedCNN_NET(nn.Module):
    def __init__(self, n_labels, dropout_rate=0.4):
        super().__init__()

        self.backbone = nn.Sequential(
            ImprovedCNN_Block(2, 32, dropout_rate=0.2),
            ImprovedCNN_Block(32, 64, dropout_rate=0.3),
            ImprovedCNN_Block(64, 128, dropout_rate=0.3),
            nn.AdaptiveAvgPool1d(16)
        )

        # Enhanced classifier for 19-class problem
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(128 * 16, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout_rate),

            nn.Linear(512, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout_rate * 0.75),

            nn.Linear(256, 128),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout_rate * 0.5),

            nn.Linear(128, n_labels)  # This will be 19 for full dataset
        )

    def forward(self, x):
        x = self.backbone(x)
        return self.classifier(x)

def create_improved_model(n_labels, dropout_rate=0.4):
    """Create improved CNN model - now works for any number of classes"""
    return ImprovedCNN_NET(n_labels, dropout_rate)


class EarlyStopping:
    def __init__(self, patience=15, min_delta=0.001, restore_best_weights=True):
        self.patience = patience
        self.min_delta = min_delta
        self.restore_best_weights = restore_best_weights
        self.best_loss = float('inf')
        self.counter = 0
        self.best_weights = None

    def __call__(self, val_loss, model):
        if val_loss < self.best_loss - self.min_delta:
            self.best_loss = val_loss
            self.counter = 0
            if self.restore_best_weights:
                self.best_weights = model.state_dict().copy()
        else:
            self.counter += 1

        if self.counter >= self.patience:
            if self.restore_best_weights and self.best_weights is not None:
                model.load_state_dict(self.best_weights)
            return True
        return False


model =ImprovedCNN_NET(n_labels).to('cuda')

# Safer: create explicit dummy input
dummy_input = torch.randn(1, n_channels, frame_size).to('cuda')

summary(model, input_data=dummy_input)


# ============================================================================
# 1. IMPROVED TRAINING FUNCTION
# ============================================================================

def train_model(model, train_dl=train_dl, valid_dl=valid_dl, verbose=True, device='cuda', num_epoch=200,
                accumulation_steps=1, use_amp=True, memory_cleanup_freq=10):
    """
    GPU memory-optimized training function for Google Colab Pro

    Args:
        model: Neural network model
        train_dl: Training dataloader
        valid_dl: Validation dataloader
        verbose: Print training progress
        device: Device to train on
        num_epoch: Maximum number of epochs
        accumulation_steps: Gradient accumulation steps (effective batch size = batch_size * accumulation_steps)
        use_amp: Use Automatic Mixed Precision (saves ~40-50% GPU memory)
        memory_cleanup_freq: How often to clean GPU memory (every N epochs)
    """

    # GPU memory check and optimization
    if device == 'cuda':
        print(f"GPU: {torch.cuda.get_device_name()}")
        print(f"Initial GPU memory: {torch.cuda.memory_allocated()/1024**3:.2f}GB / {torch.cuda.memory_reserved()/1024**3:.2f}GB")
        torch.cuda.empty_cache()

    model.to(device)

    # Use deque for memory-efficient history storage (only keep recent values)
    history_size = min(num_epoch, 1000)  # Limit history to prevent memory issues
    train_loss_history = deque(maxlen=history_size)
    train_acc_history = deque(maxlen=history_size)
    val_loss_history = deque(maxlen=history_size)
    val_acc_history = deque(maxlen=history_size)

    # Improved optimizer with memory-efficient settings
    lr = 1e-4
    optimizer = optim.AdamW(
        model.parameters(),
        lr=lr,
        weight_decay=1e-4,
        eps=1e-8,  # Slightly larger eps for numerical stability in mixed precision
        amsgrad=False  # Disable amsgrad to save memory
    )

    # Learning rate scheduler
    lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer,
        mode='min',
        factor=0.5,
        patience=10,
        #verbose=True,
        min_lr=1e-6
    )

    # setup the new path for the model 
    output_dir = r"C:\workarea\CNN model\model"
    os.makedirs(output_dir, exist_ok=True)
    
    # Label smoothing for better generalization
    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)

    # Mixed precision training setup
    scaler = GradScaler() if use_amp else None

    # Early stopping variables
    best_val_loss = float('inf')
    best_val_acc = 0.0
    patience = 20
    patience_counter = 0
    best_model_path = os.path.join(output_dir, 'best_model.pth')  # Save to disk instead of memory

    actual_epochs = 0

    try:
        for epoch in trange(num_epoch, desc='Training'):
            actual_epochs = epoch + 1

            # Memory cleanup every N epochs
            if epoch % memory_cleanup_freq == 0 and epoch > 0:
                gc.collect()
                if device == 'cuda':
                    torch.cuda.empty_cache()
                    if verbose:
                        tqdm.write(f"GPU memory after cleanup: {torch.cuda.memory_allocated()/1024**3:.2f}GB")

            # ----- Training Phase -----
            model.train()
            total_train_loss, total_train_correct, total_train_samples = 0.0, 0, 0

            # Reset gradients outside the loop
            optimizer.zero_grad()

            for batch_idx, (x, y, _) in enumerate(train_dl):
                x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)

                # Gradient accumulation context
                # FIXED: Correctly use autocast with device_type and enabled
                with autocast(enabled=use_amp):
                    # Optional: Add noise augmentation (but less frequently to save memory)
                    if torch.rand(1).item() < 0.2:  # Reduced from 30% to 20%
                        noise = torch.randn_like(x) * 0.05
                        x = x + noise

                    logits = model(x)
                    loss = criterion(logits, y)

                    # Scale loss for gradient accumulation
                    loss = loss / accumulation_steps

                # Backward pass with mixed precision
                if use_amp:
                    scaler.scale(loss).backward()
                else:
                    loss.backward()

                # Update weights every accumulation_steps
                if (batch_idx + 1) % accumulation_steps == 0:
                    if use_amp:
                        scaler.unscale_(optimizer)
                        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                        scaler.step(optimizer)
                        scaler.update()
                    else:
                        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                        optimizer.step()

                    optimizer.zero_grad()

                # Accumulate statistics (scale back the loss)
                with torch.no_grad():
                    total_train_loss += (loss.item() * accumulation_steps) * x.size(0)
                    total_train_correct += (logits.argmax(dim=1) == y).sum().item()
                    total_train_samples += x.size(0)

                # Clear intermediate tensors
                del x, y, logits, loss

            # Handle remaining gradients
            if (len(train_dl) % accumulation_steps) != 0:
                if use_amp:
                    scaler.unscale_(optimizer)
                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                    scaler.step(optimizer)
                    scaler.update()
                else:
                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                    optimizer.step()
                optimizer.zero_grad()

            epoch_train_loss = total_train_loss / total_train_samples
            epoch_train_acc = total_train_correct / total_train_samples

            train_loss_history.append(epoch_train_loss)
            train_acc_history.append(epoch_train_acc)

            # ----- Validation Phase -----
            model.eval()
            total_val_loss, total_val_correct, total_val_samples = 0.0, 0, 0

            with torch.no_grad():
                for x, y, _ in valid_dl:
                    x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)

                    # FIXED: Correctly use autocast with device_type and enabled
                    with autocast(enabled=use_amp):
                        logits = model(x)
                        loss = criterion(logits, y)

                    total_val_loss += loss.item() * x.size(0)
                    total_val_correct += (logits.argmax(dim=1) == y).sum().item()
                    total_val_samples += x.size(0)

                    # Clear tensors immediately
                    del x, y, logits, loss

            epoch_val_loss = total_val_loss / total_val_samples
            epoch_val_acc = total_val_correct / total_val_samples

            val_loss_history.append(epoch_val_loss)
            val_acc_history.append(epoch_val_acc)

            # Update learning rate
            lr_scheduler.step(epoch_val_loss)

            # Early stopping logic with disk-based model saving
            if epoch_val_loss < best_val_loss - 0.001:
                best_val_loss = epoch_val_loss
                best_val_acc = epoch_val_acc
                # Save best model to disk instead of keeping in memory
                torch.save(model.state_dict(), 'best_model.pth')
                patience_counter = 0
            else:
                patience_counter += 1

            # Check if we should stop early
            if patience_counter >= patience:
                if verbose:
                    tqdm.write(f"\nEarly stopping triggered at epoch {epoch+1}")
                    tqdm.write(f"Best validation loss: {best_val_loss:.4f}, Best validation acc: {best_val_acc:.4f}")

                # Load best model from disk
                try:
                    model.load_state_dict(torch.load(best_model_path, map_location=device))
                except:
                    tqdm.write("Warning: Could not load best model state")
                break

            # Memory-conscious verbose output
            if verbose:
                show_progress = (
                    (epoch + 1) % 10 == 0 or
                    epoch < 10 or
                    epoch_val_acc > best_val_acc or
                    patience_counter == 0
                )

                if show_progress:
                    current_lr = optimizer.param_groups[0]['lr']
                    tqdm.write(f"Epoch {epoch+1:03d} | Train Loss: {epoch_train_loss:.4f}, Acc: {epoch_train_acc:.4f}")
                    tqdm.write(f"            | Val   Loss: {epoch_val_loss:.4f}, Acc: {epoch_val_acc:.4f}")
                    tqdm.write(f"            | LR: {current_lr:.6f}, Patience: {patience_counter}/{patience}")

                    if device == 'cuda':
                        tqdm.write(f"            | GPU Memory: {torch.cuda.memory_allocated()/1024**3:.2f}GB")

                    if epoch_val_acc > best_val_acc:
                        tqdm.write(f"            | *** New best validation accuracy! ***")

            # Force memory cleanup every few epochs
            if epoch % 5 == 0:
                gc.collect()

    except RuntimeError as e:
        if "out of memory" in str(e):
            print(f"\nGPU out of memory error at epoch {epoch+1}")
            print("Try reducing batch size, enabling gradient accumulation, or using mixed precision")
            print(f"Current GPU memory: {torch.cuda.memory_allocated()/1024**3:.2f}GB")

            # Emergency cleanup
            gc.collect()
            torch.cuda.empty_cache()

        raise e

    finally:
        # Final cleanup
        gc.collect()
        if device == 'cuda':
            torch.cuda.empty_cache()

    # Convert deque to lists for compatibility
    train_history = {
        'train_loss': list(train_loss_history),
        'train_acc': list(train_acc_history),
        'val_loss': list(val_loss_history),
        'val_acc': list(val_acc_history),
        'best_val_loss': best_val_loss,
        'best_val_acc': best_val_acc,
        'epochs_trained': actual_epochs
    }

    if verbose:
        print(f"\nTraining completed!")
        print(f"Epochs trained: {actual_epochs}")
        print(f"Final validation accuracy: {val_acc_history[-1]:.4f}")
        print(f"Best validation accuracy: {best_val_acc:.4f}")
        if device == 'cuda':
            print(f"Final GPU memory: {torch.cuda.memory_allocated()/1024**3:.2f}GB")

    return model, train_history


def get_memory_usage():
    """Utility function to check current GPU memory usage"""
    if torch.cuda.is_available():
        allocated = torch.cuda.memory_allocated() / 1024**3
        reserved = torch.cuda.memory_reserved() / 1024**3
        print(f"GPU Memory - Allocated: {allocated:.2f}GB, Reserved: {reserved:.2f}GB")
        return allocated, reserved
    return 0, 0


def optimize_dataloader_for_gpu(dataset, batch_size=512, num_workers=2):
    """
    Create memory-optimized dataloader for Colab Pro
    """
    return torch.utils.data.DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,  # Reduced for Colab
        pin_memory=True,  # Faster GPU transfer
        persistent_workers=True if num_workers > 0 else False,
        prefetch_factor=2,  # Reduced prefetch
        drop_last=True  # Ensures consistent batch sizes
    )


# ============================================================================
# 2. IMPROVED MODEL ARCHITECTURE
# ============================================================================

def create_improved_model(n_labels, dropout_rate=0.4):
    """
    Create an improved CNN model with better regularization
    """
    class ImprovedCNN_Block(nn.Module):
        def __init__(self, in_channels, out_channels, dropout_rate=0.3):
            super().__init__()
            self.block = nn.Sequential(
                nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=1),
                nn.BatchNorm1d(out_channels),
                nn.ReLU(inplace=True),
                nn.Conv1d(out_channels, out_channels, kernel_size=3, padding=1),
                nn.BatchNorm1d(out_channels),
                nn.ReLU(inplace=True),
                nn.MaxPool1d(kernel_size=2),
                nn.Dropout(dropout_rate)
            )

        def forward(self, x):
            return self.block(x)

    class ImprovedCNN_NET(nn.Module):
        def __init__(self, n_labels, dropout_rate=0.4):
            super().__init__()

            self.backbone = nn.Sequential(
                ImprovedCNN_Block(2, 32, dropout_rate=0.2),
                ImprovedCNN_Block(32, 64, dropout_rate=0.3),
                ImprovedCNN_Block(64, 128, dropout_rate=0.3),
                nn.AdaptiveAvgPool1d(16)
            )

            self.classifier = nn.Sequential(
                nn.Flatten(),
                nn.Linear(128 * 16, 512),
                nn.BatchNorm1d(512),
                nn.ReLU(inplace=True),
                nn.Dropout(dropout_rate),

                nn.Linear(512, 256),
                nn.BatchNorm1d(256),
                nn.ReLU(inplace=True),
                nn.Dropout(dropout_rate * 0.75),

                nn.Linear(256, 128),
                nn.ReLU(inplace=True),
                nn.Dropout(dropout_rate * 0.5),

                nn.Linear(128, n_labels)
            )

        def forward(self, x):
            x = self.backbone(x)
            return self.classifier(x)

    return ImprovedCNN_NET(n_labels, dropout_rate)


# ============================================================================
# 3. IMPROVED TESTING AND ANALYSIS FUNCTIONS
# ============================================================================

def test_model_with_improved_plots(model, device='cuda'):
    """
    Enhanced testing function with better memory management and error handling
    """
    model.eval()
    Y_pred_ = []  # Predictions
    Y_true_ = []  # Ground truth
    Z_snr_ = []   # SNR values

    # FIXED: Use actual test dataset instead of train
    test_dataset = RadioML18Dataset(mode='test')
    test_loader = DataLoader(dataset=test_dataset, batch_size=128, shuffle=False, drop_last=False)

    target_classes = test_dataset.target_modulations
    target_snrs = test_dataset.target_snrs
    modulation_classes = test_dataset.modulation_classes

    # Add debug
    print(f"Target modulations: {target_classes}")
    print(f"Target SNRs: {target_snrs}")
    print(f"Test dataset size: {len(test_dataset)}")

    # Initialize accuracy stats DataFrame
    accuracy_stats = pd.DataFrame(
        0.0,
        index=target_classes,
        columns=target_snrs.astype('str'))

    # Get predictions with tqdm progress bar
    test_progress = tqdm(test_loader, desc="Testing model", leave=True)

    with torch.no_grad():
        for batch_idx, (x, y, z) in enumerate(test_progress):
            # Move tensors to specified device
            x = x.to(device)
            y = y.to(device)
            z = z.to(device)

            # Get model predictions on device
            logits = model(x)
            y_pred = torch.argmax(logits, dim=-1)

            # Store results
            Y_pred_.append(y_pred.cpu())  # Move back to CPU for storage
            Y_true_.append(y.cpu())
            Z_snr_.append(z.cpu())

            # Update progress bar
            if batch_idx % 10 == 0:
                current_acc = (y_pred == y).float().mean().item()
                test_progress.set_postfix({"batch_acc": f"{current_acc:.3f}"})

            # Free up memory
            del x, y, z, logits, y_pred
            if device == 'cuda':
                torch.cuda.empty_cache()

    # Convert to numpy for easier processing
    Y_pred = torch.cat(Y_pred_).numpy()
    Y_true = torch.cat(Y_true_).numpy()
    Z_snr = torch.cat(Z_snr_).numpy()

    # Clear lists to free memory
    del Y_pred_, Y_true_, Z_snr_

    # Calculate overall accuracy
    correct_preds = (Y_pred == Y_true).sum()
    total_samples = len(Y_true)
    total_accuracy = round(correct_preds * 100 / total_samples, 2)
    print(f'Overall test accuracy: {total_accuracy}%')

    # Count samples for each modulation type
    mod_counts = {}
    for mod_idx, mod_name in enumerate(target_classes):
        count = np.sum(Y_true == mod_idx)
        mod_counts[mod_name] = count
        print(f"Modulation {mod_name}: {count} test samples")

    # Calculate accuracy per modulation and SNR with progress bar
    mod_snr_progress = tqdm(list(enumerate(target_classes)),
                           desc="Calculating per-modulation accuracies",
                           leave=True)

    for mod_idx, mod_name in mod_snr_progress:
        mod_snr_progress.set_postfix({"modulation": mod_name})
        for snr_idx, snr in enumerate(target_snrs):
            snr_str = str(snr)

            mask = (Y_true == mod_idx) & (Z_snr == snr)
            total_samples = mask.sum()
            if total_samples > 0:
                correct_samples = ((Y_pred == Y_true) & mask).sum()
                accuracy = (correct_samples * 100 / total_samples)
                accuracy_stats.loc[mod_name, snr_str] = round(accuracy, 2)
            else:
                accuracy_stats.loc[mod_name, snr_str] = np.nan
                print(f"Warning: no samples for {mod_name} at SNR = {snr}")

    return accuracy_stats, mod_counts, Y_true, Y_pred, target_classes

def plot_confusion_matrix(Y_true, Y_pred, target_classes, save_name='confusion_matrix'):
    """
    Plot confusion matrix for better understanding of misclassifications
    """
    cm = confusion_matrix(Y_true, Y_pred)

    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=target_classes,
                yticklabels=target_classes)
    plt.title('Confusion Matrix - Signal Modulation Classification')
    plt.xlabel('Predicted Modulation')
    plt.ylabel('True Modulation')
    plt.xticks(rotation=45)
    plt.yticks(rotation=0)
    plt.tight_layout()
    plt.savefig(f'{save_name}.png', dpi=300, bbox_inches='tight')
    plt.show()

    # Print classification report
    print("\nDetailed Classification Report:")
    print(classification_report(Y_true, Y_pred, target_names=target_classes))

def plot_improved_test_accuracy(model, device='cuda', save_prefix='model'):
    """
    Enhanced plotting function with confusion matrix and better analysis
    """
    accuracy_df, mod_counts, Y_true, Y_pred, target_classes = test_model_with_improved_plots(model, device)

    # 1. Plot confusion matrix first
    plot_confusion_matrix(Y_true, Y_pred, target_classes, f'{save_prefix}_confusion_matrix')

    # 2. Overall accuracy vs SNR plot
    plt.figure(figsize=(14, 8))

    accuracy_long = accuracy_df.reset_index().melt(
        id_vars=['index'],
        var_name='SNR',
        value_name='Accuracy'
    )
    accuracy_long.columns = ['Modulation', 'SNR', 'Accuracy']

    # Convert SNR to numeric for proper ordering
    accuracy_long['SNR_numeric'] = accuracy_long['SNR'].astype(int)
    accuracy_long = accuracy_long.sort_values('SNR_numeric')

    sns.lineplot(
        data=accuracy_long,
        x='SNR_numeric',
        y='Accuracy',
        hue='Modulation',
        marker='o',
        markersize=8,
        linewidth=2
    )

    # Highlight PSK modulations
    psk_mods = [mod for mod in accuracy_df.index if 'PSK' in mod]
    if psk_mods:
        print(f"Highlighting PSK modulations: {psk_mods}")
        for mod in psk_mods:
            mod_data = accuracy_long[accuracy_long['Modulation'] == mod]
            if not mod_data.empty:
                plt.plot(mod_data['SNR_numeric'], mod_data['Accuracy'],
                         linewidth=4,
                         linestyle='--',
                         marker='*',
                         markersize=12,
                         alpha=0.8)

    plt.title('Classification Accuracy vs SNR for Different Modulation Types', fontsize=16)
    plt.xlabel('Signal-to-Noise Ratio (dB)', fontsize=14)
    plt.ylabel('Accuracy (%)', fontsize=14)
    plt.grid(True, alpha=0.3)
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.tight_layout()
    plt.savefig(f'{save_prefix}_all_modulations_accuracy.png', dpi=300, bbox_inches='tight')
    plt.show()

    # 3. Enhanced heatmap visualization
    plt.figure(figsize=(16, 8))

    # Reorder columns (SNRs) numerically
    snr_columns = sorted(accuracy_df.columns, key=int)
    accuracy_df_sorted = accuracy_df[snr_columns]

    # Create heatmap with better formatting
    mask = accuracy_df_sorted.isna()
    sns.heatmap(accuracy_df_sorted.astype(float),
                annot=True,
                cmap='RdYlGn',
                fmt='.1f',
                mask=mask,
                cbar_kws={'label': 'Accuracy (%)'},
                linewidths=0.5)

    plt.title('Classification Accuracy Heatmap by Modulation and SNR', fontsize=16)
    plt.xlabel('Signal-to-Noise Ratio (dB)', fontsize=14)
    plt.ylabel('Modulation Type', fontsize=14)
    plt.tight_layout()
    plt.savefig(f'{save_prefix}_modulation_accuracy_heatmap.png', dpi=300, bbox_inches='tight')
    plt.show()

    # 4. Summary statistics
    print("\n" + "="*60)
    print("PERFORMANCE SUMMARY")
    print("="*60)

    overall_acc = np.nanmean(accuracy_df_sorted.values)
    print(f"Overall average accuracy: {overall_acc:.2f}%")

    # Best and worst performing modulations
    mod_avg_acc = accuracy_df_sorted.mean(axis=1).sort_values(ascending=False)
    print(f"\nBest performing modulation: {mod_avg_acc.index[0]} ({mod_avg_acc.iloc[0]:.2f}%)")
    print(f"Worst performing modulation: {mod_avg_acc.index[-1]} ({mod_avg_acc.iloc[-1]:.2f}%)")

    return accuracy_df_sorted

def plot_training_history(model_name, history):
    """
    Enhanced training history plotting with more details
    """
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))

    epochs = range(1, len(history['train_loss']) + 1)

    # Loss plot
    ax1.plot(epochs, history['train_loss'], 'b-', label='Training Loss', linewidth=2)
    ax1.plot(epochs, history['val_loss'], 'r-', label='Validation Loss', linewidth=2)
    ax1.set_title('Model Loss')
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Loss')
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    # Accuracy plot
    ax2.plot(epochs, [acc * 100 for acc in history['train_acc']], 'b-', label='Training Accuracy', linewidth=2)
    ax2.plot(epochs, [acc * 100 for acc in history['val_acc']], 'r-', label='Validation Accuracy', linewidth=2)
    ax2.set_title('Model Accuracy')
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('Accuracy (%)')
    ax2.legend()
    ax2.grid(True, alpha=0.3)

    # Overfitting analysis
    train_val_gap = [abs(t - v) * 100 for t, v in zip(history['train_acc'], history['val_acc'])]
    ax3.plot(epochs, train_val_gap, 'g-', linewidth=2)
    ax3.set_title('Train-Validation Gap (Overfitting Indicator)')
    ax3.set_xlabel('Epoch')
    ax3.set_ylabel('Accuracy Gap (%)')
    ax3.grid(True, alpha=0.3)

    # Show validation loss trend
    ax4.plot(epochs, history['val_loss'], 'purple', linewidth=2)
    ax4.set_title('Validation Loss Trend')
    ax4.set_xlabel('Epoch')
    ax4.set_ylabel('Validation Loss')
    ax4.grid(True, alpha=0.3)

    plt.suptitle(f'Training Analysis: {model_name}', fontsize=16)
    plt.tight_layout()
    plt.savefig(f'{model_name}_detailed_training_history.png', dpi=300, bbox_inches='tight')
    plt.show()

    # Print training summary
    print(f"\nTraining Summary for {model_name}:")
    print(f"Epochs trained: {len(epochs)}")
    print(f"Final training accuracy: {history['train_acc'][-1]*100:.2f}%")
    print(f"Final validation accuracy: {history['val_acc'][-1]*100:.2f}%")
    if 'best_val_acc' in history:
        print(f"Best validation accuracy: {history['best_val_acc']*100:.2f}%")

def check_dataset_distribution(dataset_mode='test'):
    """
    Enhanced dataset analysis with better statistics
    """
    # Create dataset for analysis
    dataset = RadioML18Dataset(mode=dataset_mode)
    test_dl_analysis = DataLoader(dataset=dataset, batch_size=128, shuffle=False)

    # Analyze distribution
    mod_counts = {}
    snr_mod_counts = {}

    # Initialize counts for all modulations
    for mod in dataset.target_modulations:
        mod_counts[mod] = 0

    # Set up progress bar
    progress_bar = tqdm(range(len(dataset)), desc=f"Analyzing {dataset_mode} dataset", leave=True)

    # Count occurrences of each modulation
    for i in progress_bar:
        _, mod_idx, snr = dataset[i]
        mod = dataset.target_modulations[mod_idx]

        # Count by modulation
        mod_counts[mod] += 1

        # Count by modulation and SNR
        if snr not in snr_mod_counts:
            snr_mod_counts[snr] = {}
        if mod not in snr_mod_counts[snr]:
            snr_mod_counts[snr][mod] = 0
        snr_mod_counts[snr][mod] += 1

        # Update progress bar less frequently for performance
        if i % 1000 == 0:
            progress_bar.set_postfix({"current_mod": mod, "snr": snr})

    print(f"\n{dataset_mode.upper()} Dataset Distribution Analysis:")
    print("="*50)
    total_samples = sum(mod_counts.values())
    print(f"Total samples: {total_samples:,}")

    print("\nModulation distribution:")
    for mod, count in mod_counts.items():
        percentage = (count / total_samples) * 100
        print(f"  {mod}: {count:,} samples ({percentage:.1f}%)")

    # Check if dataset is balanced
    counts = list(mod_counts.values())
    is_balanced = max(counts) - min(counts) == 0
    print(f"\nDataset balance: {'Perfectly balanced' if is_balanced else 'Imbalanced'}")

    return mod_counts, snr_mod_counts

def improved_train_test_plots(model, model_name, verbose=True, device='cuda', num_epoch=200):
    """
    Complete training and testing pipeline with enhanced analysis
    """
    print("="*60)
    print(f"TRAINING AND EVALUATION PIPELINE: {model_name}")
    print("="*60)

    # First check the dataset distribution
    print("\n1. Analyzing dataset distribution...")
    mod_counts, snr_mod_counts = check_dataset_distribution('test')

    # Train the model
    print(f"\n2. Training {model_name}...")
    model, train_history = train_model(model, verbose=verbose, device=device, num_epoch=num_epoch)

    # Save the trained model
    # Define and create the output directory
    output_dir = r"C:\workarea\CNN model\model"
    os.makedirs(output_dir, exist_ok=True)

    # Full paths for saving
    state_dict_path = os.path.join(output_dir, f"{model_name}_state_dict.pth")
    full_model_path = os.path.join(output_dir, f"{model_name}_full_model.pth")

    # Save the models
    torch.save(model.state_dict(), 'best_model.pth')
    torch.save(model, full_model_path)

    print(f"Model saved as:\n  - {state_dict_path}\n  - {full_model_path}")

    # Plot training history
    print("\n3. Plotting training history...")
    plot_training_history(model_name, train_history)

    # Test and analyze the model
    print("\n4. Testing model and generating analysis...")
    accuracy_results = plot_improved_test_accuracy(model, device, model_name)

    print("\n5. Analysis complete!")
    print("="*60)

    return model, train_history, accuracy_results


improved_train_test_plots(
    model=ImprovedCNN_NET(n_labels=8),
    model_name='ImprovedCNN_NET',
    device='cuda',
    verbose= True,
    num_epoch=100 

)


class New_CNN32(nn.Module): #32 channels 
    def __init__(self, n_labels=8, dropout_rate=0.4):
        super(New_CNN32, self).__init__()
       
        # Channel progression: 2 → 16 → 32 → 32 → 24 → 16 → 8
        self.features = nn.Sequential(
            # Block 1: 2 → 16 channels (large kernel for initial feature extraction)
            nn.Conv1d(2, 16, kernel_size=9, stride=2, padding=4),    # 1024 → 512
            nn.BatchNorm1d(16),
            nn.ReLU(inplace=True),
            nn.AvgPool1d(kernel_size=2, stride=2),                   # 512 → 256
            nn.Dropout(dropout_rate * 0.3),
           
            # Block 2: 16 → 32 channels (max)
            nn.Conv1d(16, 32, kernel_size=7, stride=2, padding=3),   # 256 → 128
            nn.BatchNorm1d(32),
            nn.ReLU(inplace=True),
            nn.AvgPool1d(kernel_size=2, stride=2),                   # 128 → 64
            nn.Dropout(dropout_rate * 0.4),
           
            # Block 3: 32 → 32 channels (maintain)
            nn.Conv1d(32, 32, kernel_size=5, stride=2, padding=2),   # 64 → 32
            nn.BatchNorm1d(32),
            nn.ReLU(inplace=True),
            nn.AvgPool1d(kernel_size=2, stride=2),                   # 32 → 16
            nn.Dropout(dropout_rate * 0.4),
           
            # Block 4: 32 → 24 channels (reduce)
            nn.Conv1d(32, 24, kernel_size=3, stride=1, padding=1),   # 16 → 16
            nn.BatchNorm1d(24),
            nn.ReLU(inplace=True),
            nn.AvgPool1d(kernel_size=2, stride=2),                   # 16 → 8
            nn.Dropout(dropout_rate * 0.5),
           
            # Block 5: 24 → 16 channels
            nn.Conv1d(24, 16, kernel_size=3, stride=1, padding=1),   # 8 → 8
            nn.BatchNorm1d(16),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout_rate * 0.5),
           
            # Block 6: 16 → 8 channels (final) - SAFE kernel size
            nn.Conv1d(16, 8, kernel_size=3, stride=1, padding=1),    # 8 → 8
            nn.BatchNorm1d(8),
            nn.ReLU(inplace=True),
        )
       
        self.adaptive_pool = nn.AdaptiveAvgPool1d(4)
       
        # Smaller classifier to prevent overfitting
        self.classifier = nn.Sequential(
            nn.Flatten(),
           
            nn.Linear(8 * 4, 128),

            nn.BatchNorm1d(128),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout_rate),
           
            nn.Linear(128, 64),
            nn.BatchNorm1d(64),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout_rate * 0.7),
           
            nn.Linear(64, n_labels)
        )
       
        self._initialize_weights()
   
    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv1d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.BatchNorm1d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                nn.init.xavier_normal_(m.weight)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
   
    def forward(self, x):
        x = self.features(x)
        x = self.adaptive_pool(x)
        x = self.classifier(x)
        return x


class New_CNN64(nn.Module): # 64 channels 
    def __init__(self, n_labels=8, dropout_rate=0.5):
        super(New_CNN64, self).__init__()
       
        # Channel progression: 2 → 32 → 64 → 64 → 48 → 32 → 16
        self.features = nn.Sequential(
            # Block 1: 2 → 32 channels
            nn.Conv1d(2, 32, kernel_size=9, stride=2, padding=4),    # 1024 → 512
            nn.BatchNorm1d(32),
            nn.ReLU(inplace=True),
            nn.AvgPool1d(kernel_size=2, stride=2),                   # 512 → 256
            nn.Dropout(dropout_rate * 0.3),
           
            # Block 2: 32 → 64 channels (max)
            nn.Conv1d(32, 64, kernel_size=7, stride=2, padding=3),   # 256 → 128
            nn.BatchNorm1d(64),
            nn.ReLU(inplace=True),
            nn.AvgPool1d(kernel_size=2, stride=2),                   # 128 → 64
            nn.Dropout(dropout_rate * 0.4),
           
            # Block 3: 64 → 64 channels (maintain)
            nn.Conv1d(64, 64, kernel_size=5, stride=2, padding=2),   # 64 → 32
            nn.BatchNorm1d(64),
            nn.ReLU(inplace=True),
            nn.AvgPool1d(kernel_size=2, stride=2),                   # 32 → 16
            nn.Dropout(dropout_rate * 0.5),
           
            # Block 4: 64 → 48 channels (reduce)
            nn.Conv1d(64, 48, kernel_size=3, stride=1, padding=1),   # 16 → 16
            nn.BatchNorm1d(48),
            nn.ReLU(inplace=True),
            nn.AvgPool1d(kernel_size=2, stride=2),                   # 16 → 8
            nn.Dropout(dropout_rate * 0.6),
           
            # Block 5: 48 → 32 channels
            nn.Conv1d(48, 32, kernel_size=3, stride=1, padding=1),   # 8 → 8
            nn.BatchNorm1d(32),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout_rate * 0.6),
           
            # Block 6: 32 → 16 channels (final)
            nn.Conv1d(32, 16, kernel_size=3, stride=1, padding=1),   # 8 → 8
            nn.BatchNorm1d(16),
            nn.ReLU(inplace=True),
        )
       
        self.adaptive_pool = nn.AdaptiveAvgPool1d(4)
       
        # More robust classifier for higher capacity
        self.classifier = nn.Sequential(
            nn.Flatten(),
           
            nn.Linear(16 * 4, 256),

            nn.BatchNorm1d(256),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout_rate),
           
            nn.Linear(256, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout_rate * 0.8),
           
            nn.Linear(128, 64),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout_rate * 0.6),
           
            nn.Linear(64, n_labels)
        )
        self._initialize_weights()

    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv1d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.BatchNorm1d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                nn.init.xavier_normal_(m.weight)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
   
    def forward(self, x):
        x = self.features(x)
        x = self.adaptive_pool(x)
        x = self.classifier(x)
        return x


def verify_corrected_models():
    """
    Verify that the corrected models work without dimension errors
    """
    print("🔍 VERIFYING CORRECTED MODELS")
    print("="*40)
   
    models = {
        "Conservative32": New_CNN32(n_labels=8),
        "Conservative64": New_CNN64(n_labels=8)
    }
   
    input_tensor = torch.randn(1, 2, 1024)
   
    for name, model in models.items():
        print(f"\n🧪 Testing {name}:")
       
        try:
            model.eval()
            with torch.no_grad():
                output = model(input_tensor)
           
            total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
           
            print(f"   ✅ Forward pass successful!")
            print(f"   📊 Output shape: {output.shape}")
            print(f"   🔢 Parameters: {total_params:,}")
           
            # Calculate approximate memory usage
            model_size_mb = total_params * 4 / (1024**2)  # 4 bytes per parameter
            print(f"   💾 Approx model size: {model_size_mb:.1f} MB")
           
        except Exception as e:
            print(f"   ❌ Failed: {e}")
   
    return models


improved_train_test_plots(
    model=New_CNN32(n_labels=10),
    model_name='New_CNN32',
    device='cuda',
    verbose= True,
    num_epoch=100 

)


improved_train_test_plots(
    model=New_CNN64(n_labels=10),
    model_name='New_CNN64',
    device='cuda',
    verbose= True,
    num_epoch=100 

)



